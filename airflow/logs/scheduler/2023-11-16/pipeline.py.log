[2023-11-16 07:03:25,416] {processor.py:153} INFO - Started process (PID=69) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:03:25,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:03:25,419] {logging_mixin.py:115} INFO - [2023-11-16 07:03:25,419] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:03:25,634] {logging_mixin.py:115} INFO - [2023-11-16 07:03:25,605] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:03:25,641] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:03:25,691] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.282 seconds
[2023-11-16 07:03:56,701] {processor.py:153} INFO - Started process (PID=127) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:03:56,703] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:03:56,704] {logging_mixin.py:115} INFO - [2023-11-16 07:03:56,704] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:03:56,802] {logging_mixin.py:115} INFO - [2023-11-16 07:03:56,784] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:03:56,805] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:03:56,840] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.142 seconds
[2023-11-16 07:04:27,840] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:04:27,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:04:27,847] {logging_mixin.py:115} INFO - [2023-11-16 07:04:27,847] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:04:27,892] {logging_mixin.py:115} INFO - [2023-11-16 07:04:27,885] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:04:27,896] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:04:27,938] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.103 seconds
[2023-11-16 07:04:58,659] {processor.py:153} INFO - Started process (PID=251) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:04:58,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:04:58,661] {logging_mixin.py:115} INFO - [2023-11-16 07:04:58,661] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:04:58,697] {logging_mixin.py:115} INFO - [2023-11-16 07:04:58,692] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:04:58,700] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:04:58,734] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.078 seconds
[2023-11-16 07:05:29,439] {processor.py:153} INFO - Started process (PID=309) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:05:29,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:05:29,442] {logging_mixin.py:115} INFO - [2023-11-16 07:05:29,442] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:05:29,479] {logging_mixin.py:115} INFO - [2023-11-16 07:05:29,473] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:05:29,481] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:05:29,518] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.083 seconds
[2023-11-16 07:05:59,725] {processor.py:153} INFO - Started process (PID=376) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:05:59,726] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:05:59,727] {logging_mixin.py:115} INFO - [2023-11-16 07:05:59,727] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:05:59,761] {logging_mixin.py:115} INFO - [2023-11-16 07:05:59,755] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:05:59,763] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:05:59,794] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.073 seconds
[2023-11-16 07:06:29,866] {processor.py:153} INFO - Started process (PID=434) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:06:29,868] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:06:29,869] {logging_mixin.py:115} INFO - [2023-11-16 07:06:29,869] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:06:29,908] {logging_mixin.py:115} INFO - [2023-11-16 07:06:29,900] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:06:29,910] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:06:29,946] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.084 seconds
[2023-11-16 07:07:00,661] {processor.py:153} INFO - Started process (PID=501) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:07:00,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:07:00,663] {logging_mixin.py:115} INFO - [2023-11-16 07:07:00,663] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:07:00,699] {logging_mixin.py:115} INFO - [2023-11-16 07:07:00,692] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:07:00,702] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:07:00,730] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.073 seconds
[2023-11-16 07:07:31,007] {processor.py:153} INFO - Started process (PID=559) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:07:31,008] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:07:31,010] {logging_mixin.py:115} INFO - [2023-11-16 07:07:31,010] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:07:31,048] {logging_mixin.py:115} INFO - [2023-11-16 07:07:31,041] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:07:31,051] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:07:31,086] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.084 seconds
[2023-11-16 07:08:01,594] {processor.py:153} INFO - Started process (PID=626) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:08:01,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:08:01,597] {logging_mixin.py:115} INFO - [2023-11-16 07:08:01,596] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:08:01,628] {logging_mixin.py:115} INFO - [2023-11-16 07:08:01,622] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:08:01,630] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:08:01,657] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.067 seconds
[2023-11-16 07:08:31,783] {processor.py:153} INFO - Started process (PID=684) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:08:31,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:08:31,786] {logging_mixin.py:115} INFO - [2023-11-16 07:08:31,785] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:08:31,823] {logging_mixin.py:115} INFO - [2023-11-16 07:08:31,818] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:08:31,825] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:08:31,856] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.078 seconds
[2023-11-16 07:09:02,487] {processor.py:153} INFO - Started process (PID=750) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:09:02,489] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:09:02,490] {logging_mixin.py:115} INFO - [2023-11-16 07:09:02,490] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:09:02,542] {logging_mixin.py:115} INFO - [2023-11-16 07:09:02,533] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:09:02,546] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:09:02,596] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.115 seconds
[2023-11-16 07:09:32,939] {processor.py:153} INFO - Started process (PID=808) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:09:32,940] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:09:32,941] {logging_mixin.py:115} INFO - [2023-11-16 07:09:32,941] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:09:32,980] {logging_mixin.py:115} INFO - [2023-11-16 07:09:32,973] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:09:32,982] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:09:33,014] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.079 seconds
[2023-11-16 07:10:03,479] {processor.py:153} INFO - Started process (PID=875) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:10:03,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:10:03,481] {logging_mixin.py:115} INFO - [2023-11-16 07:10:03,481] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:10:03,522] {logging_mixin.py:115} INFO - [2023-11-16 07:10:03,516] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:10:03,524] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:10:03,554] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.079 seconds
[2023-11-16 07:10:33,638] {processor.py:153} INFO - Started process (PID=933) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:10:33,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:10:33,641] {logging_mixin.py:115} INFO - [2023-11-16 07:10:33,641] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:10:33,681] {logging_mixin.py:115} INFO - [2023-11-16 07:10:33,671] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:10:33,684] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:10:33,730] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.097 seconds
[2023-11-16 07:11:03,787] {processor.py:153} INFO - Started process (PID=1000) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:11:03,788] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:11:03,789] {logging_mixin.py:115} INFO - [2023-11-16 07:11:03,789] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:11:03,819] {logging_mixin.py:115} INFO - [2023-11-16 07:11:03,813] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:11:03,821] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:11:03,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.070 seconds
[2023-11-16 07:11:34,679] {processor.py:153} INFO - Started process (PID=1058) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:11:34,680] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:11:34,682] {logging_mixin.py:115} INFO - [2023-11-16 07:11:34,682] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:11:34,718] {logging_mixin.py:115} INFO - [2023-11-16 07:11:34,713] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:11:34,720] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:11:34,750] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.076 seconds
[2023-11-16 07:12:05,449] {processor.py:153} INFO - Started process (PID=1125) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:12:05,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:12:05,452] {logging_mixin.py:115} INFO - [2023-11-16 07:12:05,452] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:12:05,504] {logging_mixin.py:115} INFO - [2023-11-16 07:12:05,497] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:12:05,508] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:12:05,544] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.099 seconds
[2023-11-16 07:12:36,082] {processor.py:153} INFO - Started process (PID=1184) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:12:36,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:12:36,086] {logging_mixin.py:115} INFO - [2023-11-16 07:12:36,085] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:12:36,143] {logging_mixin.py:115} INFO - [2023-11-16 07:12:36,134] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:12:36,147] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:12:36,198] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.125 seconds
[2023-11-16 07:13:06,323] {processor.py:153} INFO - Started process (PID=1251) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:13:06,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:13:06,326] {logging_mixin.py:115} INFO - [2023-11-16 07:13:06,325] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:13:06,360] {logging_mixin.py:115} INFO - [2023-11-16 07:13:06,354] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:13:06,363] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:13:06,392] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.073 seconds
[2023-11-16 07:13:36,575] {processor.py:153} INFO - Started process (PID=1309) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:13:36,575] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:13:36,577] {logging_mixin.py:115} INFO - [2023-11-16 07:13:36,577] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:13:36,606] {logging_mixin.py:115} INFO - [2023-11-16 07:13:36,601] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:13:36,608] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:13:36,639] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.068 seconds
[2023-11-16 07:14:06,888] {processor.py:153} INFO - Started process (PID=1376) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:14:06,889] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:14:06,891] {logging_mixin.py:115} INFO - [2023-11-16 07:14:06,890] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:14:06,933] {logging_mixin.py:115} INFO - [2023-11-16 07:14:06,925] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:14:06,936] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:14:06,971] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.089 seconds
[2023-11-16 07:14:37,274] {processor.py:153} INFO - Started process (PID=1434) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:14:37,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:14:37,277] {logging_mixin.py:115} INFO - [2023-11-16 07:14:37,276] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:14:37,318] {logging_mixin.py:115} INFO - [2023-11-16 07:14:37,311] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:14:37,320] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:14:37,351] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.082 seconds
[2023-11-16 07:15:06,042] {processor.py:153} INFO - Started process (PID=1499) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:15:06,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:15:06,045] {logging_mixin.py:115} INFO - [2023-11-16 07:15:06,044] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:15:06,097] {logging_mixin.py:115} INFO - [2023-11-16 07:15:06,091] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:15:06,100] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:15:06,132] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.096 seconds
[2023-11-16 07:15:36,438] {processor.py:153} INFO - Started process (PID=1559) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:15:36,439] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:15:36,440] {logging_mixin.py:115} INFO - [2023-11-16 07:15:36,440] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:15:36,469] {logging_mixin.py:115} INFO - [2023-11-16 07:15:36,463] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:15:36,471] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:15:36,496] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.062 seconds
[2023-11-16 07:16:07,083] {processor.py:153} INFO - Started process (PID=1624) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:16:07,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:16:07,086] {logging_mixin.py:115} INFO - [2023-11-16 07:16:07,085] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:16:07,118] {logging_mixin.py:115} INFO - [2023-11-16 07:16:07,111] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:16:07,120] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:16:07,151] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.071 seconds
[2023-11-16 07:16:37,194] {processor.py:153} INFO - Started process (PID=1684) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:16:37,195] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:16:37,196] {logging_mixin.py:115} INFO - [2023-11-16 07:16:37,196] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:16:37,230] {logging_mixin.py:115} INFO - [2023-11-16 07:16:37,223] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:16:37,233] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:16:37,262] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.071 seconds
[2023-11-16 07:17:07,520] {processor.py:153} INFO - Started process (PID=1742) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:17:07,521] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:17:07,522] {logging_mixin.py:115} INFO - [2023-11-16 07:17:07,522] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:17:07,556] {logging_mixin.py:115} INFO - [2023-11-16 07:17:07,550] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:17:07,558] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:17:07,604] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.088 seconds
[2023-11-16 07:17:37,852] {processor.py:153} INFO - Started process (PID=1809) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:17:37,853] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:17:37,855] {logging_mixin.py:115} INFO - [2023-11-16 07:17:37,854] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:17:37,884] {logging_mixin.py:115} INFO - [2023-11-16 07:17:37,879] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:17:37,886] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:17:37,916] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.068 seconds
[2023-11-16 07:18:08,238] {processor.py:153} INFO - Started process (PID=1867) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:18:08,240] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:18:08,242] {logging_mixin.py:115} INFO - [2023-11-16 07:18:08,242] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:18:08,302] {logging_mixin.py:115} INFO - [2023-11-16 07:18:08,291] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:18:08,307] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:18:08,360] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.130 seconds
[2023-11-16 07:18:39,300] {processor.py:153} INFO - Started process (PID=1934) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:18:39,301] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:18:39,302] {logging_mixin.py:115} INFO - [2023-11-16 07:18:39,302] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:18:39,331] {logging_mixin.py:115} INFO - [2023-11-16 07:18:39,325] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:18:39,333] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:18:39,361] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.065 seconds
[2023-11-16 07:19:09,811] {processor.py:153} INFO - Started process (PID=1992) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:19:09,812] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:19:09,813] {logging_mixin.py:115} INFO - [2023-11-16 07:19:09,813] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:19:09,838] {logging_mixin.py:115} INFO - [2023-11-16 07:19:09,833] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:19:09,840] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:19:09,869] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.062 seconds
[2023-11-16 07:19:40,110] {processor.py:153} INFO - Started process (PID=2059) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:19:40,111] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:19:40,111] {logging_mixin.py:115} INFO - [2023-11-16 07:19:40,111] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:19:40,136] {logging_mixin.py:115} INFO - [2023-11-16 07:19:40,131] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:19:40,138] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:19:40,168] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.062 seconds
[2023-11-16 07:20:10,276] {processor.py:153} INFO - Started process (PID=2117) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:20:10,277] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:20:10,279] {logging_mixin.py:115} INFO - [2023-11-16 07:20:10,279] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:20:10,321] {logging_mixin.py:115} INFO - [2023-11-16 07:20:10,313] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:20:10,324] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:20:10,372] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.103 seconds
[2023-11-16 07:20:40,437] {processor.py:153} INFO - Started process (PID=2184) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:20:40,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:20:40,439] {logging_mixin.py:115} INFO - [2023-11-16 07:20:40,439] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:20:40,476] {logging_mixin.py:115} INFO - [2023-11-16 07:20:40,467] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:20:40,479] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:20:40,520] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.087 seconds
[2023-11-16 07:21:10,789] {processor.py:153} INFO - Started process (PID=2242) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:21:10,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:21:10,792] {logging_mixin.py:115} INFO - [2023-11-16 07:21:10,792] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:21:10,821] {logging_mixin.py:115} INFO - [2023-11-16 07:21:10,815] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:21:10,823] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:21:10,851] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.066 seconds
[2023-11-16 07:21:41,231] {processor.py:153} INFO - Started process (PID=2310) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:21:41,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:21:41,233] {logging_mixin.py:115} INFO - [2023-11-16 07:21:41,233] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:21:41,262] {logging_mixin.py:115} INFO - [2023-11-16 07:21:41,257] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:21:41,265] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:21:41,295] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.068 seconds
[2023-11-16 07:22:11,782] {processor.py:153} INFO - Started process (PID=2369) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:22:11,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:22:11,784] {logging_mixin.py:115} INFO - [2023-11-16 07:22:11,784] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:22:11,811] {logging_mixin.py:115} INFO - [2023-11-16 07:22:11,806] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:22:11,812] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:22:11,842] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.064 seconds
[2023-11-16 07:22:42,095] {processor.py:153} INFO - Started process (PID=2436) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:22:42,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:22:42,097] {logging_mixin.py:115} INFO - [2023-11-16 07:22:42,097] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:22:42,127] {logging_mixin.py:115} INFO - [2023-11-16 07:22:42,122] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:22:42,130] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:22:42,161] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.070 seconds
[2023-11-16 07:23:12,345] {processor.py:153} INFO - Started process (PID=2494) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:23:12,347] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:23:12,348] {logging_mixin.py:115} INFO - [2023-11-16 07:23:12,348] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:23:12,380] {logging_mixin.py:115} INFO - [2023-11-16 07:23:12,374] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:23:12,382] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:23:12,410] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.068 seconds
[2023-11-16 07:23:42,761] {processor.py:153} INFO - Started process (PID=2561) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:23:42,762] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:23:42,764] {logging_mixin.py:115} INFO - [2023-11-16 07:23:42,763] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:23:42,792] {logging_mixin.py:115} INFO - [2023-11-16 07:23:42,787] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:23:42,794] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:23:42,819] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.061 seconds
[2023-11-16 07:24:13,115] {processor.py:153} INFO - Started process (PID=2619) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:24:13,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:24:13,118] {logging_mixin.py:115} INFO - [2023-11-16 07:24:13,118] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:24:13,148] {logging_mixin.py:115} INFO - [2023-11-16 07:24:13,142] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:24:13,151] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:24:13,182] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.071 seconds
[2023-11-16 07:24:43,449] {processor.py:153} INFO - Started process (PID=2684) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:24:43,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:24:43,451] {logging_mixin.py:115} INFO - [2023-11-16 07:24:43,451] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:24:43,486] {logging_mixin.py:115} INFO - [2023-11-16 07:24:43,480] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:24:43,488] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:24:43,518] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.073 seconds
[2023-11-16 07:25:14,163] {processor.py:153} INFO - Started process (PID=2751) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:25:14,164] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:25:14,165] {logging_mixin.py:115} INFO - [2023-11-16 07:25:14,165] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:25:14,201] {logging_mixin.py:115} INFO - [2023-11-16 07:25:14,196] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
ModuleNotFoundError: No module named 'parsing_hh'
[2023-11-16 07:25:14,204] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:25:14,234] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.074 seconds
[2023-11-16 07:25:45,171] {processor.py:153} INFO - Started process (PID=2809) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:25:45,172] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:25:45,174] {logging_mixin.py:115} INFO - [2023-11-16 07:25:45,173] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:25:45,342] {logging_mixin.py:115} INFO - [2023-11-16 07:25:45,316] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:25:45,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:25:45,386] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 07:26:15,723] {processor.py:153} INFO - Started process (PID=2876) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:26:15,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:26:15,725] {logging_mixin.py:115} INFO - [2023-11-16 07:26:15,725] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:26:15,803] {logging_mixin.py:115} INFO - [2023-11-16 07:26:15,785] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:26:15,806] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:26:15,836] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.117 seconds
[2023-11-16 07:26:46,301] {processor.py:153} INFO - Started process (PID=2935) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:26:46,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:26:46,304] {logging_mixin.py:115} INFO - [2023-11-16 07:26:46,304] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:26:46,375] {logging_mixin.py:115} INFO - [2023-11-16 07:26:46,360] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:26:46,377] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:26:46,403] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.104 seconds
[2023-11-16 07:27:16,987] {processor.py:153} INFO - Started process (PID=3002) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:27:16,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:27:16,989] {logging_mixin.py:115} INFO - [2023-11-16 07:27:16,989] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:27:17,057] {logging_mixin.py:115} INFO - [2023-11-16 07:27:17,039] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:27:17,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:27:17,089] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.104 seconds
[2023-11-16 07:27:47,201] {processor.py:153} INFO - Started process (PID=3060) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:27:47,202] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:27:47,204] {logging_mixin.py:115} INFO - [2023-11-16 07:27:47,204] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:27:47,280] {logging_mixin.py:115} INFO - [2023-11-16 07:27:47,261] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:27:47,282] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:27:47,307] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.111 seconds
[2023-11-16 07:28:17,556] {processor.py:153} INFO - Started process (PID=3127) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:28:17,557] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:28:17,558] {logging_mixin.py:115} INFO - [2023-11-16 07:28:17,558] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:28:17,619] {logging_mixin.py:115} INFO - [2023-11-16 07:28:17,604] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:28:17,621] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:28:17,649] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.096 seconds
[2023-11-16 07:28:48,522] {processor.py:153} INFO - Started process (PID=3185) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:28:48,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:28:48,525] {logging_mixin.py:115} INFO - [2023-11-16 07:28:48,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:28:48,589] {logging_mixin.py:115} INFO - [2023-11-16 07:28:48,574] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:28:48,592] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:28:48,619] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.100 seconds
[2023-11-16 07:29:18,958] {processor.py:153} INFO - Started process (PID=3253) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:29:18,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:29:18,961] {logging_mixin.py:115} INFO - [2023-11-16 07:29:18,961] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:29:19,079] {logging_mixin.py:115} INFO - [2023-11-16 07:29:19,052] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:29:19,082] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:29:19,118] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 07:29:49,391] {processor.py:153} INFO - Started process (PID=3312) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:29:49,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:29:49,394] {logging_mixin.py:115} INFO - [2023-11-16 07:29:49,394] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:29:49,476] {logging_mixin.py:115} INFO - [2023-11-16 07:29:49,455] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:29:49,480] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:29:49,514] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.127 seconds
[2023-11-16 07:30:19,988] {processor.py:153} INFO - Started process (PID=3379) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:30:19,989] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:30:19,992] {logging_mixin.py:115} INFO - [2023-11-16 07:30:19,991] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:30:20,076] {logging_mixin.py:115} INFO - [2023-11-16 07:30:20,055] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:30:20,079] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:30:20,117] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.133 seconds
[2023-11-16 07:30:50,177] {processor.py:153} INFO - Started process (PID=3437) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:30:50,179] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:30:50,180] {logging_mixin.py:115} INFO - [2023-11-16 07:30:50,180] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:30:50,252] {logging_mixin.py:115} INFO - [2023-11-16 07:30:50,233] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:30:50,255] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:30:50,286] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.113 seconds
[2023-11-16 07:31:20,582] {processor.py:153} INFO - Started process (PID=3504) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:31:20,583] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:31:20,585] {logging_mixin.py:115} INFO - [2023-11-16 07:31:20,585] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:31:20,669] {logging_mixin.py:115} INFO - [2023-11-16 07:31:20,648] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:31:20,672] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:31:20,703] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.125 seconds
[2023-11-16 07:31:51,089] {processor.py:153} INFO - Started process (PID=3562) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:31:51,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:31:51,092] {logging_mixin.py:115} INFO - [2023-11-16 07:31:51,092] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:31:51,213] {logging_mixin.py:115} INFO - [2023-11-16 07:31:51,179] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:31:51,218] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:31:51,272] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.187 seconds
[2023-11-16 07:32:21,669] {processor.py:153} INFO - Started process (PID=3620) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:32:21,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:32:21,673] {logging_mixin.py:115} INFO - [2023-11-16 07:32:21,672] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:32:21,785] {logging_mixin.py:115} INFO - [2023-11-16 07:32:21,745] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:32:21,795] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:32:21,857] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.193 seconds
[2023-11-16 07:32:52,522] {processor.py:153} INFO - Started process (PID=3687) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:32:52,523] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:32:52,525] {logging_mixin.py:115} INFO - [2023-11-16 07:32:52,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:32:52,630] {logging_mixin.py:115} INFO - [2023-11-16 07:32:52,607] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:32:52,634] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:32:52,672] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.157 seconds
[2023-11-16 07:33:23,477] {processor.py:153} INFO - Started process (PID=3744) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:33:23,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:33:23,480] {logging_mixin.py:115} INFO - [2023-11-16 07:33:23,480] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:33:23,584] {logging_mixin.py:115} INFO - [2023-11-16 07:33:23,550] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:33:23,589] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:33:23,636] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 07:33:53,961] {processor.py:153} INFO - Started process (PID=3802) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:33:53,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:33:53,964] {logging_mixin.py:115} INFO - [2023-11-16 07:33:53,964] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:33:54,084] {logging_mixin.py:115} INFO - [2023-11-16 07:33:54,056] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:33:54,089] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:33:54,143] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.187 seconds
[2023-11-16 07:34:24,793] {processor.py:153} INFO - Started process (PID=3860) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:34:24,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:34:24,802] {logging_mixin.py:115} INFO - [2023-11-16 07:34:24,802] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:34:24,973] {logging_mixin.py:115} INFO - [2023-11-16 07:34:24,937] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:34:24,979] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:34:25,045] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.259 seconds
[2023-11-16 07:34:55,562] {processor.py:153} INFO - Started process (PID=3928) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:34:55,564] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:34:55,566] {logging_mixin.py:115} INFO - [2023-11-16 07:34:55,566] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:34:55,681] {logging_mixin.py:115} INFO - [2023-11-16 07:34:55,650] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:34:55,686] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:34:55,744] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.189 seconds
[2023-11-16 07:35:26,559] {processor.py:153} INFO - Started process (PID=3986) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:35:26,561] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:35:26,563] {logging_mixin.py:115} INFO - [2023-11-16 07:35:26,562] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:35:26,698] {logging_mixin.py:115} INFO - [2023-11-16 07:35:26,658] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:35:26,704] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:35:26,797] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.243 seconds
[2023-11-16 07:35:57,290] {processor.py:153} INFO - Started process (PID=4044) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:35:57,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:35:57,293] {logging_mixin.py:115} INFO - [2023-11-16 07:35:57,293] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:35:57,418] {logging_mixin.py:115} INFO - [2023-11-16 07:35:57,389] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:35:57,422] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:35:57,480] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.195 seconds
[2023-11-16 07:36:27,915] {processor.py:153} INFO - Started process (PID=4102) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:36:27,917] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:36:27,918] {logging_mixin.py:115} INFO - [2023-11-16 07:36:27,918] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:36:28,093] {logging_mixin.py:115} INFO - [2023-11-16 07:36:28,064] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:36:28,097] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:36:28,175] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.264 seconds
[2023-11-16 07:36:58,732] {processor.py:153} INFO - Started process (PID=4168) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:36:58,734] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:36:58,736] {logging_mixin.py:115} INFO - [2023-11-16 07:36:58,736] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:36:58,851] {logging_mixin.py:115} INFO - [2023-11-16 07:36:58,830] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:36:58,855] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:36:58,910] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.184 seconds
[2023-11-16 07:37:29,890] {processor.py:153} INFO - Started process (PID=4226) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:37:29,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:37:29,893] {logging_mixin.py:115} INFO - [2023-11-16 07:37:29,893] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:37:30,033] {logging_mixin.py:115} INFO - [2023-11-16 07:37:30,000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:37:30,039] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:37:30,103] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 07:38:00,910] {processor.py:153} INFO - Started process (PID=4284) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:38:00,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:38:00,915] {logging_mixin.py:115} INFO - [2023-11-16 07:38:00,915] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:38:01,056] {logging_mixin.py:115} INFO - [2023-11-16 07:38:01,005] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:38:01,066] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:38:01,130] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.226 seconds
[2023-11-16 07:38:32,114] {processor.py:153} INFO - Started process (PID=4343) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:38:32,115] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:38:32,117] {logging_mixin.py:115} INFO - [2023-11-16 07:38:32,117] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:38:32,237] {logging_mixin.py:115} INFO - [2023-11-16 07:38:32,198] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:38:32,243] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:38:32,307] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.198 seconds
[2023-11-16 07:39:02,560] {processor.py:153} INFO - Started process (PID=4410) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:39:02,562] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:39:02,565] {logging_mixin.py:115} INFO - [2023-11-16 07:39:02,565] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:39:02,713] {logging_mixin.py:115} INFO - [2023-11-16 07:39:02,676] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:39:02,720] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:39:02,823] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.279 seconds
[2023-11-16 07:39:33,331] {processor.py:153} INFO - Started process (PID=4468) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:39:33,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:39:33,335] {logging_mixin.py:115} INFO - [2023-11-16 07:39:33,335] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:39:33,501] {logging_mixin.py:115} INFO - [2023-11-16 07:39:33,456] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:39:33,511] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:39:33,606] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.282 seconds
[2023-11-16 07:40:03,808] {processor.py:153} INFO - Started process (PID=4526) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:40:03,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:40:03,810] {logging_mixin.py:115} INFO - [2023-11-16 07:40:03,810] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:40:03,914] {logging_mixin.py:115} INFO - [2023-11-16 07:40:03,885] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:40:03,919] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:40:03,982] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.180 seconds
[2023-11-16 07:40:34,898] {processor.py:153} INFO - Started process (PID=4584) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:40:34,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:40:34,901] {logging_mixin.py:115} INFO - [2023-11-16 07:40:34,901] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:40:34,987] {logging_mixin.py:115} INFO - [2023-11-16 07:40:34,964] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:40:34,991] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:40:35,046] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.154 seconds
[2023-11-16 07:41:05,502] {processor.py:153} INFO - Started process (PID=4642) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:41:05,504] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:41:05,505] {logging_mixin.py:115} INFO - [2023-11-16 07:41:05,505] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:41:05,616] {logging_mixin.py:115} INFO - [2023-11-16 07:41:05,587] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:41:05,624] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:41:05,684] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.187 seconds
[2023-11-16 07:41:36,621] {processor.py:153} INFO - Started process (PID=4709) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:41:36,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:41:36,625] {logging_mixin.py:115} INFO - [2023-11-16 07:41:36,624] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:41:36,734] {logging_mixin.py:115} INFO - [2023-11-16 07:41:36,706] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:41:36,738] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:41:36,793] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.178 seconds
[2023-11-16 07:42:06,962] {processor.py:153} INFO - Started process (PID=4767) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:42:06,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:42:06,966] {logging_mixin.py:115} INFO - [2023-11-16 07:42:06,966] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:42:07,081] {logging_mixin.py:115} INFO - [2023-11-16 07:42:07,049] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:42:07,086] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:42:07,148] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.194 seconds
[2023-11-16 07:42:37,323] {processor.py:153} INFO - Started process (PID=4825) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:42:37,324] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:42:37,326] {logging_mixin.py:115} INFO - [2023-11-16 07:42:37,325] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:42:37,458] {logging_mixin.py:115} INFO - [2023-11-16 07:42:37,435] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:42:37,462] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:42:37,513] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.195 seconds
[2023-11-16 07:43:07,945] {processor.py:153} INFO - Started process (PID=4884) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:43:07,947] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:43:07,949] {logging_mixin.py:115} INFO - [2023-11-16 07:43:07,948] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:43:08,059] {logging_mixin.py:115} INFO - [2023-11-16 07:43:08,027] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:43:08,064] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:43:08,122] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 07:43:38,742] {processor.py:153} INFO - Started process (PID=4942) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:43:38,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:43:38,746] {logging_mixin.py:115} INFO - [2023-11-16 07:43:38,746] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:43:38,897] {logging_mixin.py:115} INFO - [2023-11-16 07:43:38,861] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:43:38,904] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:43:38,966] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.231 seconds
[2023-11-16 07:44:09,104] {processor.py:153} INFO - Started process (PID=5009) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:44:09,106] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:44:09,109] {logging_mixin.py:115} INFO - [2023-11-16 07:44:09,108] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:44:09,299] {logging_mixin.py:115} INFO - [2023-11-16 07:44:09,260] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:44:09,306] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:44:09,355] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.256 seconds
[2023-11-16 07:44:39,529] {processor.py:153} INFO - Started process (PID=5067) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:44:39,532] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:44:39,534] {logging_mixin.py:115} INFO - [2023-11-16 07:44:39,534] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:44:39,630] {logging_mixin.py:115} INFO - [2023-11-16 07:44:39,609] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:44:39,633] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:44:39,684] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 07:45:10,218] {processor.py:153} INFO - Started process (PID=5126) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:45:10,219] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:45:10,221] {logging_mixin.py:115} INFO - [2023-11-16 07:45:10,220] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:45:10,340] {logging_mixin.py:115} INFO - [2023-11-16 07:45:10,305] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:45:10,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:45:10,407] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.194 seconds
[2023-11-16 07:45:40,800] {processor.py:153} INFO - Started process (PID=5184) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:45:40,802] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:45:40,804] {logging_mixin.py:115} INFO - [2023-11-16 07:45:40,803] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:45:40,939] {logging_mixin.py:115} INFO - [2023-11-16 07:45:40,899] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:45:40,945] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:45:41,016] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.221 seconds
[2023-11-16 07:46:11,297] {processor.py:153} INFO - Started process (PID=5251) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:46:11,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:46:11,300] {logging_mixin.py:115} INFO - [2023-11-16 07:46:11,300] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:46:11,452] {logging_mixin.py:115} INFO - [2023-11-16 07:46:11,404] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:46:11,459] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:46:11,510] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 07:46:41,788] {processor.py:153} INFO - Started process (PID=5310) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:46:41,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:46:41,791] {logging_mixin.py:115} INFO - [2023-11-16 07:46:41,791] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:46:41,927] {logging_mixin.py:115} INFO - [2023-11-16 07:46:41,889] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:46:41,934] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:46:42,005] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.223 seconds
[2023-11-16 07:47:12,277] {processor.py:153} INFO - Started process (PID=5368) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:47:12,279] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:47:12,281] {logging_mixin.py:115} INFO - [2023-11-16 07:47:12,281] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:47:12,395] {logging_mixin.py:115} INFO - [2023-11-16 07:47:12,371] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:47:12,399] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:47:12,451] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.181 seconds
[2023-11-16 07:47:43,156] {processor.py:153} INFO - Started process (PID=5423) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:47:43,159] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:47:43,161] {logging_mixin.py:115} INFO - [2023-11-16 07:47:43,161] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:47:43,298] {logging_mixin.py:115} INFO - [2023-11-16 07:47:43,267] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:47:43,304] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:47:43,359] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.209 seconds
[2023-11-16 07:48:13,933] {processor.py:153} INFO - Started process (PID=5488) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:48:13,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:48:13,936] {logging_mixin.py:115} INFO - [2023-11-16 07:48:13,935] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:48:14,055] {logging_mixin.py:115} INFO - [2023-11-16 07:48:14,030] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:48:14,060] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:48:14,113] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.185 seconds
[2023-11-16 07:48:44,699] {processor.py:153} INFO - Started process (PID=5548) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:48:44,701] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:48:44,702] {logging_mixin.py:115} INFO - [2023-11-16 07:48:44,702] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:48:44,818] {logging_mixin.py:115} INFO - [2023-11-16 07:48:44,787] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:48:44,822] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:48:44,864] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.168 seconds
[2023-11-16 07:49:14,961] {processor.py:153} INFO - Started process (PID=5606) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:49:14,963] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:49:14,964] {logging_mixin.py:115} INFO - [2023-11-16 07:49:14,964] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:49:15,074] {logging_mixin.py:115} INFO - [2023-11-16 07:49:15,047] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:49:15,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:49:15,129] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.172 seconds
[2023-11-16 07:49:45,603] {processor.py:153} INFO - Started process (PID=5665) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:49:45,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:49:45,606] {logging_mixin.py:115} INFO - [2023-11-16 07:49:45,606] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:49:45,703] {logging_mixin.py:115} INFO - [2023-11-16 07:49:45,679] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:49:45,710] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:49:45,764] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.166 seconds
[2023-11-16 07:50:16,608] {processor.py:153} INFO - Started process (PID=5733) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:50:16,610] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:50:16,612] {logging_mixin.py:115} INFO - [2023-11-16 07:50:16,611] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:50:16,740] {logging_mixin.py:115} INFO - [2023-11-16 07:50:16,706] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:50:16,745] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:50:16,799] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.195 seconds
[2023-11-16 07:50:46,942] {processor.py:153} INFO - Started process (PID=5792) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:50:46,943] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:50:46,945] {logging_mixin.py:115} INFO - [2023-11-16 07:50:46,944] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:50:47,027] {logging_mixin.py:115} INFO - [2023-11-16 07:50:47,004] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:50:47,030] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:50:47,082] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.145 seconds
[2023-11-16 07:51:17,279] {processor.py:153} INFO - Started process (PID=5850) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:51:17,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:51:17,282] {logging_mixin.py:115} INFO - [2023-11-16 07:51:17,282] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:51:17,385] {logging_mixin.py:115} INFO - [2023-11-16 07:51:17,363] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:51:17,388] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:51:17,425] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.151 seconds
[2023-11-16 07:51:48,377] {processor.py:153} INFO - Started process (PID=5908) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:51:48,379] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:51:48,380] {logging_mixin.py:115} INFO - [2023-11-16 07:51:48,380] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:51:48,478] {logging_mixin.py:115} INFO - [2023-11-16 07:51:48,454] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:51:48,482] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:51:48,538] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.166 seconds
[2023-11-16 07:52:03,468] {processor.py:153} INFO - Started process (PID=5949) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:52:03,471] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:52:03,473] {logging_mixin.py:115} INFO - [2023-11-16 07:52:03,473] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:52:03,735] {logging_mixin.py:115} INFO - [2023-11-16 07:52:03,690] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:52:03,742] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:52:03,849] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.391 seconds
[2023-11-16 07:52:34,778] {processor.py:153} INFO - Started process (PID=6016) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:52:34,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:52:34,782] {logging_mixin.py:115} INFO - [2023-11-16 07:52:34,782] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:52:34,971] {logging_mixin.py:115} INFO - [2023-11-16 07:52:34,938] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:52:34,976] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:52:35,032] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.259 seconds
[2023-11-16 07:53:05,279] {processor.py:153} INFO - Started process (PID=6074) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:53:05,280] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:53:05,282] {logging_mixin.py:115} INFO - [2023-11-16 07:53:05,281] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:53:05,430] {logging_mixin.py:115} INFO - [2023-11-16 07:53:05,392] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:53:05,441] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:53:05,509] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.236 seconds
[2023-11-16 07:53:36,399] {processor.py:153} INFO - Started process (PID=6133) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:53:36,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:53:36,403] {logging_mixin.py:115} INFO - [2023-11-16 07:53:36,402] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:53:36,506] {logging_mixin.py:115} INFO - [2023-11-16 07:53:36,480] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:53:36,510] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:53:36,568] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.177 seconds
[2023-11-16 07:54:06,682] {processor.py:153} INFO - Started process (PID=6192) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:54:06,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:54:06,685] {logging_mixin.py:115} INFO - [2023-11-16 07:54:06,685] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:54:06,778] {logging_mixin.py:115} INFO - [2023-11-16 07:54:06,756] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:54:06,781] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:54:06,828] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.150 seconds
[2023-11-16 07:54:37,575] {processor.py:153} INFO - Started process (PID=6258) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:54:37,577] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:54:37,578] {logging_mixin.py:115} INFO - [2023-11-16 07:54:37,578] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:54:37,681] {logging_mixin.py:115} INFO - [2023-11-16 07:54:37,648] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:54:37,686] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:54:37,729] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 07:55:08,523] {processor.py:153} INFO - Started process (PID=6318) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:55:08,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:55:08,527] {logging_mixin.py:115} INFO - [2023-11-16 07:55:08,527] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:55:08,699] {logging_mixin.py:115} INFO - [2023-11-16 07:55:08,654] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:55:08,704] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:55:08,755] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.240 seconds
[2023-11-16 07:55:39,439] {processor.py:153} INFO - Started process (PID=6377) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:55:39,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:55:39,443] {logging_mixin.py:115} INFO - [2023-11-16 07:55:39,442] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:55:39,600] {logging_mixin.py:115} INFO - [2023-11-16 07:55:39,563] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:55:39,605] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:55:39,674] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.242 seconds
[2023-11-16 07:56:10,439] {processor.py:153} INFO - Started process (PID=6435) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:56:10,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:56:10,444] {logging_mixin.py:115} INFO - [2023-11-16 07:56:10,444] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:56:10,615] {logging_mixin.py:115} INFO - [2023-11-16 07:56:10,578] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:56:10,619] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:56:10,660] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.228 seconds
[2023-11-16 07:56:40,772] {processor.py:153} INFO - Started process (PID=6493) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:56:40,774] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:56:40,776] {logging_mixin.py:115} INFO - [2023-11-16 07:56:40,776] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:56:40,935] {logging_mixin.py:115} INFO - [2023-11-16 07:56:40,906] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:56:40,938] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:56:40,990] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.225 seconds
[2023-11-16 07:57:11,311] {processor.py:153} INFO - Started process (PID=6560) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:57:11,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:57:11,315] {logging_mixin.py:115} INFO - [2023-11-16 07:57:11,315] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:57:11,424] {logging_mixin.py:115} INFO - [2023-11-16 07:57:11,397] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:57:11,429] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:57:11,470] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.165 seconds
[2023-11-16 07:57:42,065] {processor.py:153} INFO - Started process (PID=6616) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:57:42,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:57:42,068] {logging_mixin.py:115} INFO - [2023-11-16 07:57:42,068] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:57:42,254] {logging_mixin.py:115} INFO - [2023-11-16 07:57:42,224] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:57:42,259] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:57:42,317] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.262 seconds
[2023-11-16 07:58:07,606] {processor.py:153} INFO - Started process (PID=6659) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:58:07,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:58:07,610] {logging_mixin.py:115} INFO - [2023-11-16 07:58:07,610] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:58:07,877] {logging_mixin.py:115} INFO - [2023-11-16 07:58:07,830] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:58:07,883] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:58:07,935] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.337 seconds
[2023-11-16 07:58:38,263] {processor.py:153} INFO - Started process (PID=6717) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:58:38,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:58:38,267] {logging_mixin.py:115} INFO - [2023-11-16 07:58:38,267] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:58:38,507] {logging_mixin.py:115} INFO - [2023-11-16 07:58:38,453] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:58:38,512] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:58:38,584] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.330 seconds
[2023-11-16 07:59:09,281] {processor.py:153} INFO - Started process (PID=6775) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:59:09,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:59:09,285] {logging_mixin.py:115} INFO - [2023-11-16 07:59:09,285] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:59:09,394] {logging_mixin.py:115} INFO - [2023-11-16 07:59:09,366] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:59:09,399] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:59:09,449] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.174 seconds
[2023-11-16 07:59:39,777] {processor.py:153} INFO - Started process (PID=6833) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 07:59:39,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 07:59:39,783] {logging_mixin.py:115} INFO - [2023-11-16 07:59:39,782] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 07:59:39,946] {logging_mixin.py:115} INFO - [2023-11-16 07:59:39,900] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 07:59:39,952] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 07:59:40,029] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.261 seconds
[2023-11-16 08:00:10,594] {processor.py:153} INFO - Started process (PID=6898) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:00:10,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:00:10,597] {logging_mixin.py:115} INFO - [2023-11-16 08:00:10,597] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:00:10,713] {logging_mixin.py:115} INFO - [2023-11-16 08:00:10,680] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:00:10,719] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:00:10,779] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.192 seconds
[2023-11-16 08:00:41,357] {processor.py:153} INFO - Started process (PID=6958) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:00:41,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:00:41,361] {logging_mixin.py:115} INFO - [2023-11-16 08:00:41,360] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:00:41,504] {logging_mixin.py:115} INFO - [2023-11-16 08:00:41,466] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:00:41,510] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:00:41,576] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.225 seconds
[2023-11-16 08:01:12,162] {processor.py:153} INFO - Started process (PID=7016) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:01:12,165] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:01:12,167] {logging_mixin.py:115} INFO - [2023-11-16 08:01:12,167] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:01:12,432] {logging_mixin.py:115} INFO - [2023-11-16 08:01:12,392] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:01:12,441] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:01:12,509] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.355 seconds
[2023-11-16 08:01:42,729] {processor.py:153} INFO - Started process (PID=7074) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:01:42,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:01:42,733] {logging_mixin.py:115} INFO - [2023-11-16 08:01:42,733] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:01:42,892] {logging_mixin.py:115} INFO - [2023-11-16 08:01:42,848] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:01:42,899] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:01:42,967] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.244 seconds
[2023-11-16 08:02:13,528] {processor.py:153} INFO - Started process (PID=7132) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:02:13,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:02:13,533] {logging_mixin.py:115} INFO - [2023-11-16 08:02:13,533] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:02:13,645] {logging_mixin.py:115} INFO - [2023-11-16 08:02:13,622] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:02:13,650] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:02:13,703] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.186 seconds
[2023-11-16 08:02:43,824] {processor.py:153} INFO - Started process (PID=7199) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:02:43,825] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:02:43,827] {logging_mixin.py:115} INFO - [2023-11-16 08:02:43,827] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:02:43,951] {logging_mixin.py:115} INFO - [2023-11-16 08:02:43,923] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:02:43,956] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:02:44,011] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.194 seconds
[2023-11-16 08:03:14,281] {processor.py:153} INFO - Started process (PID=7257) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:03:14,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:03:14,285] {logging_mixin.py:115} INFO - [2023-11-16 08:03:14,285] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:03:14,415] {logging_mixin.py:115} INFO - [2023-11-16 08:03:14,381] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:03:14,423] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:03:14,480] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.206 seconds
[2023-11-16 08:03:44,555] {processor.py:153} INFO - Started process (PID=7314) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:03:44,556] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:03:44,559] {logging_mixin.py:115} INFO - [2023-11-16 08:03:44,558] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:03:44,671] {logging_mixin.py:115} INFO - [2023-11-16 08:03:44,647] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:03:44,675] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:03:44,722] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.174 seconds
[2023-11-16 08:04:15,386] {processor.py:153} INFO - Started process (PID=7372) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:04:15,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:04:15,390] {logging_mixin.py:115} INFO - [2023-11-16 08:04:15,389] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:04:15,558] {logging_mixin.py:115} INFO - [2023-11-16 08:04:15,529] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:04:15,563] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:04:15,621] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.241 seconds
[2023-11-16 08:04:45,868] {processor.py:153} INFO - Started process (PID=7439) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:04:45,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:04:45,892] {logging_mixin.py:115} INFO - [2023-11-16 08:04:45,891] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:04:46,128] {logging_mixin.py:115} INFO - [2023-11-16 08:04:46,075] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:04:46,135] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:04:46,206] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.346 seconds
[2023-11-16 08:05:16,284] {processor.py:153} INFO - Started process (PID=7497) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:05:16,286] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:05:16,287] {logging_mixin.py:115} INFO - [2023-11-16 08:05:16,287] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:05:16,413] {logging_mixin.py:115} INFO - [2023-11-16 08:05:16,382] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:05:16,418] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:05:16,460] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 08:05:45,046] {processor.py:153} INFO - Started process (PID=7554) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:05:45,048] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:05:45,050] {logging_mixin.py:115} INFO - [2023-11-16 08:05:45,050] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:05:45,339] {logging_mixin.py:115} INFO - [2023-11-16 08:05:45,280] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:05:45,346] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:05:45,397] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.365 seconds
[2023-11-16 08:06:15,884] {processor.py:153} INFO - Started process (PID=7613) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:06:15,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:06:15,888] {logging_mixin.py:115} INFO - [2023-11-16 08:06:15,888] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:06:16,009] {logging_mixin.py:115} INFO - [2023-11-16 08:06:15,979] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:06:16,014] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:06:16,063] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.187 seconds
[2023-11-16 08:06:46,803] {processor.py:153} INFO - Started process (PID=7671) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:06:46,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:06:46,807] {logging_mixin.py:115} INFO - [2023-11-16 08:06:46,807] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:06:46,929] {logging_mixin.py:115} INFO - [2023-11-16 08:06:46,900] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:06:46,933] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:06:46,975] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.177 seconds
[2023-11-16 08:07:17,453] {processor.py:153} INFO - Started process (PID=7736) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:07:17,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:07:17,457] {logging_mixin.py:115} INFO - [2023-11-16 08:07:17,457] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:07:17,585] {logging_mixin.py:115} INFO - [2023-11-16 08:07:17,555] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:07:17,589] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:07:17,643] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.198 seconds
[2023-11-16 08:07:47,966] {processor.py:153} INFO - Started process (PID=7796) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:07:47,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:07:47,970] {logging_mixin.py:115} INFO - [2023-11-16 08:07:47,969] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:07:48,106] {logging_mixin.py:115} INFO - [2023-11-16 08:07:48,073] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:07:48,111] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:07:48,155] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.196 seconds
[2023-11-16 08:08:18,968] {processor.py:153} INFO - Started process (PID=7854) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:08:18,969] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:08:18,971] {logging_mixin.py:115} INFO - [2023-11-16 08:08:18,971] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:08:19,080] {logging_mixin.py:115} INFO - [2023-11-16 08:08:19,051] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:08:19,084] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:08:19,136] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.173 seconds
[2023-11-16 08:08:49,292] {processor.py:153} INFO - Started process (PID=7913) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:08:49,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:08:49,298] {logging_mixin.py:115} INFO - [2023-11-16 08:08:49,298] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:08:49,439] {logging_mixin.py:115} INFO - [2023-11-16 08:08:49,414] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:08:49,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:08:49,512] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.235 seconds
[2023-11-16 08:09:19,693] {processor.py:153} INFO - Started process (PID=7971) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:09:19,695] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:09:19,697] {logging_mixin.py:115} INFO - [2023-11-16 08:09:19,696] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:09:19,813] {logging_mixin.py:115} INFO - [2023-11-16 08:09:19,775] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:09:19,818] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:09:19,882] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.196 seconds
[2023-11-16 08:09:50,055] {processor.py:153} INFO - Started process (PID=8038) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:09:50,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:09:50,060] {logging_mixin.py:115} INFO - [2023-11-16 08:09:50,060] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:09:50,209] {logging_mixin.py:115} INFO - [2023-11-16 08:09:50,168] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:09:50,215] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:09:50,309] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.267 seconds
[2023-11-16 08:10:20,560] {processor.py:153} INFO - Started process (PID=8096) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:10:20,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:10:20,565] {logging_mixin.py:115} INFO - [2023-11-16 08:10:20,564] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:10:20,792] {logging_mixin.py:115} INFO - [2023-11-16 08:10:20,746] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:10:20,800] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:10:20,874] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.322 seconds
[2023-11-16 08:10:51,050] {processor.py:153} INFO - Started process (PID=8154) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:10:51,053] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:10:51,055] {logging_mixin.py:115} INFO - [2023-11-16 08:10:51,055] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:10:51,226] {logging_mixin.py:115} INFO - [2023-11-16 08:10:51,177] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:10:51,232] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:10:51,283] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.241 seconds
[2023-11-16 08:11:21,729] {processor.py:153} INFO - Started process (PID=8211) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:21,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:11:21,733] {logging_mixin.py:115} INFO - [2023-11-16 08:11:21,733] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:21,899] {logging_mixin.py:115} INFO - [2023-11-16 08:11:21,869] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:11:21,903] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:21,961] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.240 seconds
[2023-11-16 08:11:28,684] {processor.py:153} INFO - Started process (PID=8235) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:28,688] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:11:28,691] {logging_mixin.py:115} INFO - [2023-11-16 08:11:28,690] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:29,053] {logging_mixin.py:115} INFO - [2023-11-16 08:11:28,994] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:11:29,063] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:29,129] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.459 seconds
[2023-11-16 08:11:59,483] {processor.py:153} INFO - Started process (PID=8293) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:59,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:11:59,490] {logging_mixin.py:115} INFO - [2023-11-16 08:11:59,489] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:59,654] {logging_mixin.py:115} INFO - [2023-11-16 08:11:59,621] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:11:59,658] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:11:59,703] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.234 seconds
[2023-11-16 08:12:29,770] {processor.py:153} INFO - Started process (PID=8351) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:12:29,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:12:29,774] {logging_mixin.py:115} INFO - [2023-11-16 08:12:29,774] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:12:29,899] {logging_mixin.py:115} INFO - [2023-11-16 08:12:29,871] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:12:29,904] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:12:29,957] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.193 seconds
[2023-11-16 08:13:00,054] {processor.py:153} INFO - Started process (PID=8410) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:13:00,055] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:13:00,056] {logging_mixin.py:115} INFO - [2023-11-16 08:13:00,056] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:13:00,179] {logging_mixin.py:115} INFO - [2023-11-16 08:13:00,146] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:13:00,184] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:13:00,248] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.199 seconds
[2023-11-16 08:13:30,664] {processor.py:153} INFO - Started process (PID=8476) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:13:30,667] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:13:30,670] {logging_mixin.py:115} INFO - [2023-11-16 08:13:30,670] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:13:30,835] {logging_mixin.py:115} INFO - [2023-11-16 08:13:30,795] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:13:30,840] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:13:30,885] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.233 seconds
[2023-11-16 08:14:01,719] {processor.py:153} INFO - Started process (PID=8535) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:14:01,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:14:01,724] {logging_mixin.py:115} INFO - [2023-11-16 08:14:01,723] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:14:01,828] {logging_mixin.py:115} INFO - [2023-11-16 08:14:01,802] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:14:01,832] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:14:01,883] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.172 seconds
[2023-11-16 08:14:32,182] {processor.py:153} INFO - Started process (PID=8593) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:14:32,184] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:14:32,186] {logging_mixin.py:115} INFO - [2023-11-16 08:14:32,186] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:14:32,303] {logging_mixin.py:115} INFO - [2023-11-16 08:14:32,276] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:14:32,308] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:14:32,361] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.187 seconds
[2023-11-16 08:15:02,876] {processor.py:153} INFO - Started process (PID=8650) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:15:02,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:15:02,880] {logging_mixin.py:115} INFO - [2023-11-16 08:15:02,879] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:15:03,005] {logging_mixin.py:115} INFO - [2023-11-16 08:15:02,977] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:15:03,009] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:15:03,072] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.203 seconds
[2023-11-16 08:15:33,375] {processor.py:153} INFO - Started process (PID=8717) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:15:33,378] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:15:33,381] {logging_mixin.py:115} INFO - [2023-11-16 08:15:33,381] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:15:33,568] {logging_mixin.py:115} INFO - [2023-11-16 08:15:33,525] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:15:33,574] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:15:33,648] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.288 seconds
[2023-11-16 08:16:03,910] {processor.py:153} INFO - Started process (PID=8775) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:16:03,912] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:16:03,913] {logging_mixin.py:115} INFO - [2023-11-16 08:16:03,913] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:16:04,022] {logging_mixin.py:115} INFO - [2023-11-16 08:16:03,996] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:16:04,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:16:04,071] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.165 seconds
[2023-11-16 08:16:34,135] {processor.py:153} INFO - Started process (PID=8831) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:16:34,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:16:34,137] {logging_mixin.py:115} INFO - [2023-11-16 08:16:34,137] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:16:34,212] {logging_mixin.py:115} INFO - [2023-11-16 08:16:34,192] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:16:34,215] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:16:34,267] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.136 seconds
[2023-11-16 08:17:04,538] {processor.py:153} INFO - Started process (PID=8887) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:17:04,539] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:17:04,541] {logging_mixin.py:115} INFO - [2023-11-16 08:17:04,541] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:17:04,661] {logging_mixin.py:115} INFO - [2023-11-16 08:17:04,630] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:17:04,665] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:17:04,717] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.188 seconds
[2023-11-16 08:17:35,247] {processor.py:153} INFO - Started process (PID=8954) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:17:35,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:17:35,252] {logging_mixin.py:115} INFO - [2023-11-16 08:17:35,252] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:17:35,407] {logging_mixin.py:115} INFO - [2023-11-16 08:17:35,373] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:17:35,412] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:17:35,469] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.234 seconds
[2023-11-16 08:18:06,059] {processor.py:153} INFO - Started process (PID=9012) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:18:06,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:18:06,064] {logging_mixin.py:115} INFO - [2023-11-16 08:18:06,063] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:18:06,469] {logging_mixin.py:115} INFO - [2023-11-16 08:18:06,421] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:18:06,476] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:18:06,535] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.486 seconds
[2023-11-16 08:18:36,913] {processor.py:153} INFO - Started process (PID=9070) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:18:36,915] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:18:36,918] {logging_mixin.py:115} INFO - [2023-11-16 08:18:36,917] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:18:37,049] {logging_mixin.py:115} INFO - [2023-11-16 08:18:37,019] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:18:37,054] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:18:37,096] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.190 seconds
[2023-11-16 08:19:07,738] {processor.py:153} INFO - Started process (PID=9128) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:19:07,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:19:07,743] {logging_mixin.py:115} INFO - [2023-11-16 08:19:07,742] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:19:07,859] {logging_mixin.py:115} INFO - [2023-11-16 08:19:07,830] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:19:07,864] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:19:07,921] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.190 seconds
[2023-11-16 08:19:37,991] {processor.py:153} INFO - Started process (PID=9186) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:19:37,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:19:37,994] {logging_mixin.py:115} INFO - [2023-11-16 08:19:37,993] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:19:38,080] {logging_mixin.py:115} INFO - [2023-11-16 08:19:38,058] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:19:38,083] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:19:38,132] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.146 seconds
[2023-11-16 08:20:08,700] {processor.py:153} INFO - Started process (PID=9253) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:20:08,702] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:20:08,704] {logging_mixin.py:115} INFO - [2023-11-16 08:20:08,704] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:20:08,856] {logging_mixin.py:115} INFO - [2023-11-16 08:20:08,815] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:20:08,862] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:20:08,935] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.243 seconds
[2023-11-16 08:20:39,682] {processor.py:153} INFO - Started process (PID=9311) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:20:39,684] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:20:39,686] {logging_mixin.py:115} INFO - [2023-11-16 08:20:39,686] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:20:39,795] {logging_mixin.py:115} INFO - [2023-11-16 08:20:39,767] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:20:39,800] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:20:39,836] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.163 seconds
[2023-11-16 08:21:10,362] {processor.py:153} INFO - Started process (PID=9369) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:21:10,363] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:21:10,366] {logging_mixin.py:115} INFO - [2023-11-16 08:21:10,365] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:21:10,485] {logging_mixin.py:115} INFO - [2023-11-16 08:21:10,455] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:21:10,489] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:21:10,558] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.204 seconds
[2023-11-16 08:21:41,188] {processor.py:153} INFO - Started process (PID=9437) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:21:41,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:21:41,196] {logging_mixin.py:115} INFO - [2023-11-16 08:21:41,195] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:21:41,406] {logging_mixin.py:115} INFO - [2023-11-16 08:21:41,367] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:21:41,413] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:21:41,470] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.290 seconds
[2023-11-16 08:22:11,607] {processor.py:153} INFO - Started process (PID=9495) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:22:11,609] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:22:11,611] {logging_mixin.py:115} INFO - [2023-11-16 08:22:11,611] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:22:11,760] {logging_mixin.py:115} INFO - [2023-11-16 08:22:11,726] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:22:11,765] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:22:11,828] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.228 seconds
[2023-11-16 08:22:42,405] {processor.py:153} INFO - Started process (PID=9553) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:22:42,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:22:42,412] {logging_mixin.py:115} INFO - [2023-11-16 08:22:42,411] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:22:42,626] {logging_mixin.py:115} INFO - [2023-11-16 08:22:42,563] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:22:42,633] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:22:42,733] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.340 seconds
[2023-11-16 08:23:13,362] {processor.py:153} INFO - Started process (PID=9611) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:23:13,364] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:23:13,366] {logging_mixin.py:115} INFO - [2023-11-16 08:23:13,366] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:23:13,491] {logging_mixin.py:115} INFO - [2023-11-16 08:23:13,462] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:23:13,497] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:23:13,548] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.193 seconds
[2023-11-16 08:23:43,959] {processor.py:153} INFO - Started process (PID=9669) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:23:43,960] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:23:43,963] {logging_mixin.py:115} INFO - [2023-11-16 08:23:43,962] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:23:44,071] {logging_mixin.py:115} INFO - [2023-11-16 08:23:44,039] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:23:44,075] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:23:44,124] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.172 seconds
[2023-11-16 08:24:14,616] {processor.py:153} INFO - Started process (PID=9727) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:24:14,617] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:24:14,621] {logging_mixin.py:115} INFO - [2023-11-16 08:24:14,621] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:24:14,757] {logging_mixin.py:115} INFO - [2023-11-16 08:24:14,720] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:24:14,761] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:24:14,816] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.207 seconds
[2023-11-16 08:24:45,349] {processor.py:153} INFO - Started process (PID=9794) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:24:45,353] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:24:45,361] {logging_mixin.py:115} INFO - [2023-11-16 08:24:45,361] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:24:45,576] {logging_mixin.py:115} INFO - [2023-11-16 08:24:45,530] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:24:45,582] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:24:45,671] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.332 seconds
[2023-11-16 08:25:15,800] {processor.py:153} INFO - Started process (PID=9852) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:25:15,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:25:15,803] {logging_mixin.py:115} INFO - [2023-11-16 08:25:15,803] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:25:15,920] {logging_mixin.py:115} INFO - [2023-11-16 08:25:15,890] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:25:15,925] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:25:15,984] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.189 seconds
[2023-11-16 08:25:46,668] {processor.py:153} INFO - Started process (PID=9910) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:25:46,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:25:46,672] {logging_mixin.py:115} INFO - [2023-11-16 08:25:46,672] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:25:46,796] {logging_mixin.py:115} INFO - [2023-11-16 08:25:46,763] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:25:46,802] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:25:46,858] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.196 seconds
[2023-11-16 08:26:17,373] {processor.py:153} INFO - Started process (PID=9969) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:26:17,375] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:26:17,377] {logging_mixin.py:115} INFO - [2023-11-16 08:26:17,377] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:26:17,527] {logging_mixin.py:115} INFO - [2023-11-16 08:26:17,493] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:26:17,533] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:26:17,595] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.228 seconds
[2023-11-16 08:26:47,885] {processor.py:153} INFO - Started process (PID=10027) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:26:47,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:26:47,888] {logging_mixin.py:115} INFO - [2023-11-16 08:26:47,888] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:26:48,043] {logging_mixin.py:115} INFO - [2023-11-16 08:26:48,006] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:26:48,049] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:26:48,104] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.239 seconds
[2023-11-16 08:27:18,551] {processor.py:153} INFO - Started process (PID=10085) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:27:18,553] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:27:18,556] {logging_mixin.py:115} INFO - [2023-11-16 08:27:18,555] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:27:18,684] {logging_mixin.py:115} INFO - [2023-11-16 08:27:18,643] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:27:18,690] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:27:18,749] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.209 seconds
[2023-11-16 08:27:49,331] {processor.py:153} INFO - Started process (PID=10152) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:27:49,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:27:49,335] {logging_mixin.py:115} INFO - [2023-11-16 08:27:49,335] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:27:49,490] {logging_mixin.py:115} INFO - [2023-11-16 08:27:49,455] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:27:49,497] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:27:49,573] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.248 seconds
[2023-11-16 08:28:19,705] {processor.py:153} INFO - Started process (PID=10210) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:28:19,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:28:19,709] {logging_mixin.py:115} INFO - [2023-11-16 08:28:19,708] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:28:19,882] {logging_mixin.py:115} INFO - [2023-11-16 08:28:19,830] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:28:19,895] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:28:19,956] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.259 seconds
[2023-11-16 08:28:50,775] {processor.py:153} INFO - Started process (PID=10268) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:28:50,777] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:28:50,779] {logging_mixin.py:115} INFO - [2023-11-16 08:28:50,778] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:28:50,911] {logging_mixin.py:115} INFO - [2023-11-16 08:28:50,865] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:28:50,920] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:28:50,998] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.230 seconds
[2023-11-16 08:29:21,220] {processor.py:153} INFO - Started process (PID=10326) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:29:21,221] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:29:21,223] {logging_mixin.py:115} INFO - [2023-11-16 08:29:21,223] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:29:21,376] {logging_mixin.py:115} INFO - [2023-11-16 08:29:21,344] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:29:21,380] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:29:21,421] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.207 seconds
[2023-11-16 08:29:51,740] {processor.py:153} INFO - Started process (PID=10384) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:29:51,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:29:51,744] {logging_mixin.py:115} INFO - [2023-11-16 08:29:51,744] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:29:51,936] {logging_mixin.py:115} INFO - [2023-11-16 08:29:51,895] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:29:51,942] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:29:51,993] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.261 seconds
[2023-11-16 08:30:22,161] {processor.py:153} INFO - Started process (PID=10442) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:30:22,163] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:30:22,165] {logging_mixin.py:115} INFO - [2023-11-16 08:30:22,165] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:30:22,307] {logging_mixin.py:115} INFO - [2023-11-16 08:30:22,270] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:30:22,312] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:30:22,371] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.217 seconds
[2023-11-16 08:30:52,768] {processor.py:153} INFO - Started process (PID=10509) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:30:52,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:30:52,772] {logging_mixin.py:115} INFO - [2023-11-16 08:30:52,772] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:30:52,907] {logging_mixin.py:115} INFO - [2023-11-16 08:30:52,880] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:30:52,911] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:30:52,959] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.198 seconds
[2023-11-16 08:31:02,715] {processor.py:153} INFO - Started process (PID=10526) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:31:02,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:31:02,718] {logging_mixin.py:115} INFO - [2023-11-16 08:31:02,718] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:31:02,889] {logging_mixin.py:115} INFO - [2023-11-16 08:31:02,856] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:31:02,893] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:31:02,937] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.226 seconds
[2023-11-16 08:31:33,391] {processor.py:153} INFO - Started process (PID=10584) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:31:33,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:31:33,394] {logging_mixin.py:115} INFO - [2023-11-16 08:31:33,394] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:31:33,511] {logging_mixin.py:115} INFO - [2023-11-16 08:31:33,490] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:31:33,515] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:31:33,561] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.177 seconds
[2023-11-16 08:32:04,876] {processor.py:153} INFO - Started process (PID=10651) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:32:04,878] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:32:04,880] {logging_mixin.py:115} INFO - [2023-11-16 08:32:04,880] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:32:05,028] {logging_mixin.py:115} INFO - [2023-11-16 08:32:04,994] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:32:05,033] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:32:05,086] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.216 seconds
[2023-11-16 08:32:35,424] {processor.py:153} INFO - Started process (PID=10707) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:32:35,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:32:35,427] {logging_mixin.py:115} INFO - [2023-11-16 08:32:35,426] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:32:35,543] {logging_mixin.py:115} INFO - [2023-11-16 08:32:35,518] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:32:35,547] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:32:35,599] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.179 seconds
[2023-11-16 08:33:05,794] {processor.py:153} INFO - Started process (PID=10774) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:33:05,796] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:33:05,797] {logging_mixin.py:115} INFO - [2023-11-16 08:33:05,797] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:33:05,916] {logging_mixin.py:115} INFO - [2023-11-16 08:33:05,889] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:33:05,921] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:33:05,955] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.167 seconds
[2023-11-16 08:33:36,621] {processor.py:153} INFO - Started process (PID=10832) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:33:36,622] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:33:36,623] {logging_mixin.py:115} INFO - [2023-11-16 08:33:36,623] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:33:36,733] {logging_mixin.py:115} INFO - [2023-11-16 08:33:36,707] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:33:36,737] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:33:36,776] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.159 seconds
[2023-11-16 08:34:07,428] {processor.py:153} INFO - Started process (PID=10899) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:34:07,429] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:34:07,431] {logging_mixin.py:115} INFO - [2023-11-16 08:34:07,431] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:34:07,539] {logging_mixin.py:115} INFO - [2023-11-16 08:34:07,515] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:34:07,543] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:34:07,588] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.166 seconds
[2023-11-16 08:34:38,268] {processor.py:153} INFO - Started process (PID=10957) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:34:38,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:34:38,271] {logging_mixin.py:115} INFO - [2023-11-16 08:34:38,270] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:34:38,387] {logging_mixin.py:115} INFO - [2023-11-16 08:34:38,365] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:34:38,390] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:34:38,423] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.158 seconds
[2023-11-16 08:35:09,124] {processor.py:153} INFO - Started process (PID=11015) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:35:09,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:35:09,127] {logging_mixin.py:115} INFO - [2023-11-16 08:35:09,126] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:35:09,240] {logging_mixin.py:115} INFO - [2023-11-16 08:35:09,219] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:35:09,243] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:35:09,275] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.159 seconds
[2023-11-16 08:35:39,949] {processor.py:153} INFO - Started process (PID=11082) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:35:39,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:35:39,952] {logging_mixin.py:115} INFO - [2023-11-16 08:35:39,952] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:35:40,048] {logging_mixin.py:115} INFO - [2023-11-16 08:35:40,029] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:35:40,051] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:35:40,081] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.136 seconds
[2023-11-16 08:36:10,457] {processor.py:153} INFO - Started process (PID=11140) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:36:10,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:36:10,459] {logging_mixin.py:115} INFO - [2023-11-16 08:36:10,459] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:36:10,574] {logging_mixin.py:115} INFO - [2023-11-16 08:36:10,551] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:36:10,578] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:36:10,619] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.166 seconds
[2023-11-16 08:36:41,145] {processor.py:153} INFO - Started process (PID=11207) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:36:41,146] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:36:41,148] {logging_mixin.py:115} INFO - [2023-11-16 08:36:41,147] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:36:41,245] {logging_mixin.py:115} INFO - [2023-11-16 08:36:41,221] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:36:41,248] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:36:41,280] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.140 seconds
[2023-11-16 08:37:11,635] {processor.py:153} INFO - Started process (PID=11265) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:37:11,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:37:11,641] {logging_mixin.py:115} INFO - [2023-11-16 08:37:11,641] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:37:11,782] {logging_mixin.py:115} INFO - [2023-11-16 08:37:11,753] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:37:11,786] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:37:11,828] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.201 seconds
[2023-11-16 08:37:42,009] {processor.py:153} INFO - Started process (PID=11332) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:37:42,010] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:37:42,012] {logging_mixin.py:115} INFO - [2023-11-16 08:37:42,011] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:37:42,167] {logging_mixin.py:115} INFO - [2023-11-16 08:37:42,135] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:37:42,172] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:37:42,212] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.209 seconds
[2023-11-16 08:38:12,677] {processor.py:153} INFO - Started process (PID=11390) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:38:12,678] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:38:12,680] {logging_mixin.py:115} INFO - [2023-11-16 08:38:12,680] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:38:12,804] {logging_mixin.py:115} INFO - [2023-11-16 08:38:12,777] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:38:12,809] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:38:12,852] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 08:38:43,340] {processor.py:153} INFO - Started process (PID=11457) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:38:43,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:38:43,342] {logging_mixin.py:115} INFO - [2023-11-16 08:38:43,342] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:38:43,447] {logging_mixin.py:115} INFO - [2023-11-16 08:38:43,426] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:38:43,451] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:38:43,485] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.149 seconds
[2023-11-16 08:39:13,872] {processor.py:153} INFO - Started process (PID=11515) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:39:13,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:39:13,875] {logging_mixin.py:115} INFO - [2023-11-16 08:39:13,875] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:39:13,988] {logging_mixin.py:115} INFO - [2023-11-16 08:39:13,966] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:39:13,991] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:39:14,031] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.163 seconds
[2023-11-16 08:39:44,510] {processor.py:153} INFO - Started process (PID=11582) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:39:44,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:39:44,513] {logging_mixin.py:115} INFO - [2023-11-16 08:39:44,513] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:39:44,641] {logging_mixin.py:115} INFO - [2023-11-16 08:39:44,613] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 13, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:39:44,646] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:39:44,694] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.189 seconds
[2023-11-16 08:40:01,589] {processor.py:153} INFO - Started process (PID=11610) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:40:01,591] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:40:01,593] {logging_mixin.py:115} INFO - [2023-11-16 08:40:01,593] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:40:01,750] {logging_mixin.py:115} INFO - [2023-11-16 08:40:01,728] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:40:01,755] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:40:01,801] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.219 seconds
[2023-11-16 08:40:31,907] {processor.py:153} INFO - Started process (PID=11668) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:40:31,908] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:40:31,909] {logging_mixin.py:115} INFO - [2023-11-16 08:40:31,909] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:40:32,006] {logging_mixin.py:115} INFO - [2023-11-16 08:40:31,982] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:40:32,011] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:40:32,042] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.139 seconds
[2023-11-16 08:41:02,180] {processor.py:153} INFO - Started process (PID=11735) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:41:02,182] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:41:02,183] {logging_mixin.py:115} INFO - [2023-11-16 08:41:02,183] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:41:02,400] {logging_mixin.py:115} INFO - [2023-11-16 08:41:02,347] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:41:02,405] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:41:02,450] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.277 seconds
[2023-11-16 08:41:32,917] {processor.py:153} INFO - Started process (PID=11793) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:41:32,918] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:41:32,919] {logging_mixin.py:115} INFO - [2023-11-16 08:41:32,919] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:41:33,001] {logging_mixin.py:115} INFO - [2023-11-16 08:41:32,983] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:41:33,004] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:41:33,036] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.124 seconds
[2023-11-16 08:42:03,704] {processor.py:153} INFO - Started process (PID=11860) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:42:03,705] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:42:03,707] {logging_mixin.py:115} INFO - [2023-11-16 08:42:03,706] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:42:03,812] {logging_mixin.py:115} INFO - [2023-11-16 08:42:03,787] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:42:03,815] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:42:03,847] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.147 seconds
[2023-11-16 08:42:34,291] {processor.py:153} INFO - Started process (PID=11918) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:42:34,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:42:34,294] {logging_mixin.py:115} INFO - [2023-11-16 08:42:34,294] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:42:34,423] {logging_mixin.py:115} INFO - [2023-11-16 08:42:34,392] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:42:34,428] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:42:34,466] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.180 seconds
[2023-11-16 08:43:04,872] {processor.py:153} INFO - Started process (PID=11976) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:43:04,873] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:43:04,874] {logging_mixin.py:115} INFO - [2023-11-16 08:43:04,874] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:43:04,961] {logging_mixin.py:115} INFO - [2023-11-16 08:43:04,942] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:43:04,964] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:43:05,002] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.134 seconds
[2023-11-16 08:43:34,342] {processor.py:153} INFO - Started process (PID=12043) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:43:34,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:43:34,344] {logging_mixin.py:115} INFO - [2023-11-16 08:43:34,344] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:43:34,515] {logging_mixin.py:115} INFO - [2023-11-16 08:43:34,493] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 08:43:34,518] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:43:34,556] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.219 seconds
[2023-11-16 08:44:04,742] {processor.py:153} INFO - Started process (PID=12097) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:44:04,743] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:44:04,744] {logging_mixin.py:115} INFO - [2023-11-16 08:44:04,744] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:44:04,791] {logging_mixin.py:115} INFO - [2023-11-16 08:44:04,790] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:44:04,792] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:44:04,828] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.091 seconds
[2023-11-16 08:49:20,594] {processor.py:153} INFO - Started process (PID=60) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:49:20,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:49:20,601] {logging_mixin.py:115} INFO - [2023-11-16 08:49:20,601] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:49:20,649] {logging_mixin.py:115} INFO - [2023-11-16 08:49:20,647] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:49:20,650] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:49:20,724] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.139 seconds
[2023-11-16 08:49:50,853] {processor.py:153} INFO - Started process (PID=118) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:49:50,854] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:49:50,856] {logging_mixin.py:115} INFO - [2023-11-16 08:49:50,856] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:49:50,888] {logging_mixin.py:115} INFO - [2023-11-16 08:49:50,887] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:49:50,889] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:49:50,928] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.079 seconds
[2023-11-16 08:50:21,139] {processor.py:153} INFO - Started process (PID=185) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:50:21,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:50:21,142] {logging_mixin.py:115} INFO - [2023-11-16 08:50:21,141] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:50:21,180] {logging_mixin.py:115} INFO - [2023-11-16 08:50:21,179] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:50:21,181] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:50:21,210] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.074 seconds
[2023-11-16 08:50:51,356] {processor.py:153} INFO - Started process (PID=243) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:50:51,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:50:51,359] {logging_mixin.py:115} INFO - [2023-11-16 08:50:51,359] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:50:51,388] {logging_mixin.py:115} INFO - [2023-11-16 08:50:51,387] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:50:51,389] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:50:51,419] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.067 seconds
[2023-11-16 08:51:21,697] {processor.py:153} INFO - Started process (PID=310) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:51:21,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:51:21,700] {logging_mixin.py:115} INFO - [2023-11-16 08:51:21,700] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:51:21,728] {logging_mixin.py:115} INFO - [2023-11-16 08:51:21,727] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:51:21,729] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:51:21,760] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.070 seconds
[2023-11-16 08:51:52,430] {processor.py:153} INFO - Started process (PID=368) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:51:52,431] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:51:52,432] {logging_mixin.py:115} INFO - [2023-11-16 08:51:52,432] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:51:52,468] {logging_mixin.py:115} INFO - [2023-11-16 08:51:52,467] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:51:52,468] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:51:52,496] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.072 seconds
[2023-11-16 08:52:23,208] {processor.py:153} INFO - Started process (PID=435) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:52:23,209] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:52:23,210] {logging_mixin.py:115} INFO - [2023-11-16 08:52:23,210] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:52:23,240] {logging_mixin.py:115} INFO - [2023-11-16 08:52:23,239] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:52:23,241] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:52:23,274] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.070 seconds
[2023-11-16 08:52:54,206] {processor.py:153} INFO - Started process (PID=502) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:52:54,207] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:52:54,208] {logging_mixin.py:115} INFO - [2023-11-16 08:52:54,208] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:52:54,246] {logging_mixin.py:115} INFO - [2023-11-16 08:52:54,245] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:52:54,247] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:52:54,284] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.082 seconds
[2023-11-16 08:53:24,918] {processor.py:153} INFO - Started process (PID=560) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:53:24,919] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:53:24,920] {logging_mixin.py:115} INFO - [2023-11-16 08:53:24,920] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:53:24,952] {logging_mixin.py:115} INFO - [2023-11-16 08:53:24,951] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:53:24,953] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:53:24,984] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.070 seconds
[2023-11-16 08:53:55,515] {processor.py:153} INFO - Started process (PID=628) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:53:55,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:53:55,517] {logging_mixin.py:115} INFO - [2023-11-16 08:53:55,516] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:53:55,548] {logging_mixin.py:115} INFO - [2023-11-16 08:53:55,547] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:53:55,549] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:53:55,582] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.071 seconds
[2023-11-16 08:54:26,019] {processor.py:153} INFO - Started process (PID=686) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:54:26,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:54:26,022] {logging_mixin.py:115} INFO - [2023-11-16 08:54:26,021] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:54:26,050] {logging_mixin.py:115} INFO - [2023-11-16 08:54:26,049] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:54:26,051] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:54:26,080] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.066 seconds
[2023-11-16 08:54:56,291] {processor.py:153} INFO - Started process (PID=753) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:54:56,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:54:56,294] {logging_mixin.py:115} INFO - [2023-11-16 08:54:56,294] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:54:56,322] {logging_mixin.py:115} INFO - [2023-11-16 08:54:56,321] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:54:56,323] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:54:56,355] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.069 seconds
[2023-11-16 08:55:27,233] {processor.py:153} INFO - Started process (PID=818) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:55:27,234] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:55:27,235] {logging_mixin.py:115} INFO - [2023-11-16 08:55:27,235] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:55:27,275] {logging_mixin.py:115} INFO - [2023-11-16 08:55:27,274] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:55:27,275] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:55:27,311] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.083 seconds
[2023-11-16 08:55:57,578] {processor.py:153} INFO - Started process (PID=878) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:55:57,579] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:55:57,582] {logging_mixin.py:115} INFO - [2023-11-16 08:55:57,582] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:55:57,616] {logging_mixin.py:115} INFO - [2023-11-16 08:55:57,615] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:55:57,616] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:55:57,646] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.072 seconds
[2023-11-16 08:56:28,036] {processor.py:153} INFO - Started process (PID=945) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:56:28,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:56:28,038] {logging_mixin.py:115} INFO - [2023-11-16 08:56:28,038] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:56:28,077] {logging_mixin.py:115} INFO - [2023-11-16 08:56:28,076] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:56:28,078] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:56:28,109] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.076 seconds
[2023-11-16 08:56:58,927] {processor.py:153} INFO - Started process (PID=1003) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:56:58,928] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:56:58,930] {logging_mixin.py:115} INFO - [2023-11-16 08:56:58,930] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:56:58,958] {logging_mixin.py:115} INFO - [2023-11-16 08:56:58,957] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:56:58,959] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:56:58,988] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.064 seconds
[2023-11-16 08:57:29,881] {processor.py:153} INFO - Started process (PID=1070) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:57:29,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:57:29,884] {logging_mixin.py:115} INFO - [2023-11-16 08:57:29,884] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:57:29,926] {logging_mixin.py:115} INFO - [2023-11-16 08:57:29,925] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:57:29,927] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:57:29,969] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.093 seconds
[2023-11-16 08:58:00,318] {processor.py:153} INFO - Started process (PID=1128) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:58:00,319] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:58:00,320] {logging_mixin.py:115} INFO - [2023-11-16 08:58:00,320] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:58:00,354] {logging_mixin.py:115} INFO - [2023-11-16 08:58:00,353] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:58:00,355] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:58:00,387] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.072 seconds
[2023-11-16 08:58:31,313] {processor.py:153} INFO - Started process (PID=1195) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:58:31,315] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:58:31,316] {logging_mixin.py:115} INFO - [2023-11-16 08:58:31,316] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:58:31,352] {logging_mixin.py:115} INFO - [2023-11-16 08:58:31,351] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:58:31,354] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:58:31,387] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.079 seconds
[2023-11-16 08:59:01,822] {processor.py:153} INFO - Started process (PID=1253) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:59:01,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:59:01,825] {logging_mixin.py:115} INFO - [2023-11-16 08:59:01,825] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:59:01,853] {logging_mixin.py:115} INFO - [2023-11-16 08:59:01,852] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:59:01,854] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:59:01,887] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.068 seconds
[2023-11-16 08:59:32,649] {processor.py:153} INFO - Started process (PID=1320) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 08:59:32,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 08:59:32,652] {logging_mixin.py:115} INFO - [2023-11-16 08:59:32,652] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 08:59:32,688] {logging_mixin.py:115} INFO - [2023-11-16 08:59:32,687] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 08:59:32,689] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 08:59:32,734] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.089 seconds
[2023-11-16 09:00:03,404] {processor.py:153} INFO - Started process (PID=1385) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:00:03,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:00:03,407] {logging_mixin.py:115} INFO - [2023-11-16 09:00:03,407] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:00:03,446] {logging_mixin.py:115} INFO - [2023-11-16 09:00:03,446] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:00:03,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:00:03,480] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.082 seconds
[2023-11-16 09:00:33,940] {processor.py:153} INFO - Started process (PID=1445) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:00:33,941] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:00:33,943] {logging_mixin.py:115} INFO - [2023-11-16 09:00:33,943] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:00:33,975] {logging_mixin.py:115} INFO - [2023-11-16 09:00:33,974] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:00:33,976] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:00:34,007] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.070 seconds
[2023-11-16 09:01:04,862] {processor.py:153} INFO - Started process (PID=1512) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:01:04,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:01:04,865] {logging_mixin.py:115} INFO - [2023-11-16 09:01:04,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:01:04,901] {logging_mixin.py:115} INFO - [2023-11-16 09:01:04,900] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:01:04,902] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:01:04,934] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.075 seconds
[2023-11-16 09:01:35,514] {processor.py:153} INFO - Started process (PID=1570) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:01:35,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:01:35,517] {logging_mixin.py:115} INFO - [2023-11-16 09:01:35,516] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:01:35,543] {logging_mixin.py:115} INFO - [2023-11-16 09:01:35,542] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:01:35,544] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:01:35,573] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.062 seconds
[2023-11-16 09:02:05,696] {processor.py:153} INFO - Started process (PID=1637) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:02:05,697] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:02:05,699] {logging_mixin.py:115} INFO - [2023-11-16 09:02:05,699] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:02:05,733] {logging_mixin.py:115} INFO - [2023-11-16 09:02:05,732] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:02:05,733] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:02:05,778] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.086 seconds
[2023-11-16 09:02:35,870] {processor.py:153} INFO - Started process (PID=1695) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:02:35,872] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:02:35,872] {logging_mixin.py:115} INFO - [2023-11-16 09:02:35,872] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:02:35,892] {logging_mixin.py:115} INFO - [2023-11-16 09:02:35,891] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:02:35,893] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:02:35,920] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.053 seconds
[2023-11-16 09:03:06,204] {processor.py:153} INFO - Started process (PID=1762) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:03:06,205] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:03:06,207] {logging_mixin.py:115} INFO - [2023-11-16 09:03:06,206] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:03:06,236] {logging_mixin.py:115} INFO - [2023-11-16 09:03:06,235] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:03:06,237] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:03:06,266] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.066 seconds
[2023-11-16 09:03:36,617] {processor.py:153} INFO - Started process (PID=1820) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:03:36,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:03:36,619] {logging_mixin.py:115} INFO - [2023-11-16 09:03:36,619] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:03:36,654] {logging_mixin.py:115} INFO - [2023-11-16 09:03:36,653] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:03:36,655] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:03:36,690] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.077 seconds
[2023-11-16 09:04:06,909] {processor.py:153} INFO - Started process (PID=1887) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:04:06,910] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:04:06,912] {logging_mixin.py:115} INFO - [2023-11-16 09:04:06,911] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:04:06,936] {logging_mixin.py:115} INFO - [2023-11-16 09:04:06,935] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:04:06,937] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:04:06,965] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.059 seconds
[2023-11-16 09:04:37,036] {processor.py:153} INFO - Started process (PID=1954) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:04:37,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:04:37,038] {logging_mixin.py:115} INFO - [2023-11-16 09:04:37,038] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:04:37,064] {logging_mixin.py:115} INFO - [2023-11-16 09:04:37,063] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:04:37,065] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:04:37,093] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.061 seconds
[2023-11-16 09:05:07,372] {processor.py:153} INFO - Started process (PID=2012) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:05:07,373] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:05:07,374] {logging_mixin.py:115} INFO - [2023-11-16 09:05:07,374] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:05:07,402] {logging_mixin.py:115} INFO - [2023-11-16 09:05:07,401] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:05:07,403] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:05:07,430] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.061 seconds
[2023-11-16 09:05:37,808] {processor.py:153} INFO - Started process (PID=2079) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:05:37,809] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:05:37,810] {logging_mixin.py:115} INFO - [2023-11-16 09:05:37,810] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:05:37,842] {logging_mixin.py:115} INFO - [2023-11-16 09:05:37,841] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:05:37,843] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:05:37,878] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.074 seconds
[2023-11-16 09:06:08,383] {processor.py:153} INFO - Started process (PID=2137) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:08,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:06:08,386] {logging_mixin.py:115} INFO - [2023-11-16 09:06:08,386] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:08,418] {logging_mixin.py:115} INFO - [2023-11-16 09:06:08,417] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 16
    Получение объекта Connection с помощью метода BaseHook.get_connection
                    ^
SyntaxError: invalid syntax
[2023-11-16 09:06:08,418] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:08,447] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.068 seconds
[2023-11-16 09:06:22,392] {processor.py:153} INFO - Started process (PID=2185) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:22,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:06:22,394] {logging_mixin.py:115} INFO - [2023-11-16 09:06:22,393] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:22,506] {logging_mixin.py:115} INFO - [2023-11-16 09:06:22,489] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:06:22,509] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:22,536] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.148 seconds
[2023-11-16 09:06:25,447] {processor.py:153} INFO - Started process (PID=2195) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:25,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:06:25,450] {logging_mixin.py:115} INFO - [2023-11-16 09:06:25,450] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:25,588] {logging_mixin.py:115} INFO - [2023-11-16 09:06:25,558] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:06:25,593] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:25,631] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.187 seconds
[2023-11-16 09:06:55,698] {processor.py:153} INFO - Started process (PID=2253) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:55,699] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:06:55,701] {logging_mixin.py:115} INFO - [2023-11-16 09:06:55,700] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:55,773] {logging_mixin.py:115} INFO - [2023-11-16 09:06:55,756] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:06:55,776] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:06:55,808] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.113 seconds
[2023-11-16 09:07:26,255] {processor.py:153} INFO - Started process (PID=2320) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:07:26,256] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:07:26,258] {logging_mixin.py:115} INFO - [2023-11-16 09:07:26,258] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:07:26,338] {logging_mixin.py:115} INFO - [2023-11-16 09:07:26,320] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:07:26,341] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:07:26,370] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.119 seconds
[2023-11-16 09:07:56,665] {processor.py:153} INFO - Started process (PID=2378) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:07:56,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:07:56,667] {logging_mixin.py:115} INFO - [2023-11-16 09:07:56,667] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:07:56,737] {logging_mixin.py:115} INFO - [2023-11-16 09:07:56,721] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:07:56,740] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:07:56,768] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.107 seconds
[2023-11-16 09:08:27,132] {processor.py:153} INFO - Started process (PID=2445) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:08:27,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:08:27,135] {logging_mixin.py:115} INFO - [2023-11-16 09:08:27,135] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:08:27,217] {logging_mixin.py:115} INFO - [2023-11-16 09:08:27,196] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:08:27,220] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:08:27,254] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.125 seconds
[2023-11-16 09:08:57,665] {processor.py:153} INFO - Started process (PID=2503) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:08:57,666] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:08:57,667] {logging_mixin.py:115} INFO - [2023-11-16 09:08:57,667] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:08:57,738] {logging_mixin.py:115} INFO - [2023-11-16 09:08:57,722] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:08:57,741] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:08:57,770] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.108 seconds
[2023-11-16 09:09:28,468] {processor.py:153} INFO - Started process (PID=2570) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:09:28,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:09:28,470] {logging_mixin.py:115} INFO - [2023-11-16 09:09:28,470] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:09:28,543] {logging_mixin.py:115} INFO - [2023-11-16 09:09:28,528] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:09:28,547] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:09:28,577] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.112 seconds
[2023-11-16 09:09:59,068] {processor.py:153} INFO - Started process (PID=2637) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:09:59,070] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:09:59,071] {logging_mixin.py:115} INFO - [2023-11-16 09:09:59,071] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:09:59,152] {logging_mixin.py:115} INFO - [2023-11-16 09:09:59,136] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:09:59,154] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:09:59,183] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.118 seconds
[2023-11-16 09:10:29,498] {processor.py:153} INFO - Started process (PID=2695) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:10:29,499] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:10:29,500] {logging_mixin.py:115} INFO - [2023-11-16 09:10:29,500] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:10:29,572] {logging_mixin.py:115} INFO - [2023-11-16 09:10:29,556] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:10:29,575] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:10:29,601] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.105 seconds
[2023-11-16 09:10:59,795] {processor.py:153} INFO - Started process (PID=2762) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:10:59,796] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:10:59,796] {logging_mixin.py:115} INFO - [2023-11-16 09:10:59,796] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:10:59,873] {logging_mixin.py:115} INFO - [2023-11-16 09:10:59,856] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:10:59,876] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:10:59,900] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.108 seconds
[2023-11-16 09:11:30,340] {processor.py:153} INFO - Started process (PID=2820) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:11:30,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:11:30,342] {logging_mixin.py:115} INFO - [2023-11-16 09:11:30,342] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:11:30,421] {logging_mixin.py:115} INFO - [2023-11-16 09:11:30,397] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:11:30,424] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:11:30,452] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.115 seconds
[2023-11-16 09:12:00,553] {processor.py:153} INFO - Started process (PID=2887) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:12:00,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:12:00,555] {logging_mixin.py:115} INFO - [2023-11-16 09:12:00,555] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:12:00,654] {logging_mixin.py:115} INFO - [2023-11-16 09:12:00,633] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:12:00,658] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:12:00,689] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.140 seconds
[2023-11-16 09:12:31,089] {processor.py:153} INFO - Started process (PID=2945) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:12:31,098] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:12:31,104] {logging_mixin.py:115} INFO - [2023-11-16 09:12:31,104] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:12:31,260] {logging_mixin.py:115} INFO - [2023-11-16 09:12:31,236] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:12:31,264] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:12:31,299] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.216 seconds
[2023-11-16 09:13:01,953] {processor.py:153} INFO - Started process (PID=3012) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:13:01,954] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:13:01,957] {logging_mixin.py:115} INFO - [2023-11-16 09:13:01,956] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:13:02,037] {logging_mixin.py:115} INFO - [2023-11-16 09:13:02,019] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:13:02,041] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:13:02,067] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.118 seconds
[2023-11-16 09:13:32,133] {processor.py:153} INFO - Started process (PID=3077) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:13:32,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:13:32,136] {logging_mixin.py:115} INFO - [2023-11-16 09:13:32,136] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:13:32,234] {logging_mixin.py:115} INFO - [2023-11-16 09:13:32,211] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:13:32,238] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:13:32,267] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.139 seconds
[2023-11-16 09:14:02,513] {processor.py:153} INFO - Started process (PID=3137) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:14:02,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:14:02,515] {logging_mixin.py:115} INFO - [2023-11-16 09:14:02,515] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:14:02,587] {logging_mixin.py:115} INFO - [2023-11-16 09:14:02,571] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:14:02,590] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:14:02,616] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.108 seconds
[2023-11-16 09:14:33,033] {processor.py:153} INFO - Started process (PID=3195) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:14:33,034] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:14:33,035] {logging_mixin.py:115} INFO - [2023-11-16 09:14:33,035] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:14:33,113] {logging_mixin.py:115} INFO - [2023-11-16 09:14:33,095] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:14:33,116] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:14:33,142] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.113 seconds
[2023-11-16 09:15:03,383] {processor.py:153} INFO - Started process (PID=3262) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:15:03,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:15:03,385] {logging_mixin.py:115} INFO - [2023-11-16 09:15:03,385] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:15:03,476] {logging_mixin.py:115} INFO - [2023-11-16 09:15:03,450] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:15:03,480] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:15:03,517] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.138 seconds
[2023-11-16 09:15:34,293] {processor.py:153} INFO - Started process (PID=3327) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:15:34,294] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:15:34,296] {logging_mixin.py:115} INFO - [2023-11-16 09:15:34,296] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:15:34,396] {logging_mixin.py:115} INFO - [2023-11-16 09:15:34,376] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 12, in <module>
    host='127.0.0.1', port='5430')
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "127.0.0.1", port 5430 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
[2023-11-16 09:15:34,401] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:15:34,433] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.143 seconds
[2023-11-16 09:16:04,490] {processor.py:153} INFO - Started process (PID=3387) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:16:04,491] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:16:04,492] {logging_mixin.py:115} INFO - [2023-11-16 09:16:04,492] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:16:04,622] {logging_mixin.py:115} INFO - [2023-11-16 09:16:04,597] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:16:04,626] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:16:04,657] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.170 seconds
[2023-11-16 09:16:35,631] {processor.py:153} INFO - Started process (PID=3454) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:16:35,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:16:35,634] {logging_mixin.py:115} INFO - [2023-11-16 09:16:35,634] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:16:35,719] {logging_mixin.py:115} INFO - [2023-11-16 09:16:35,698] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:16:35,723] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:16:35,754] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.126 seconds
[2023-11-16 09:17:05,937] {processor.py:153} INFO - Started process (PID=3512) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:17:05,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:17:05,939] {logging_mixin.py:115} INFO - [2023-11-16 09:17:05,938] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:17:06,007] {logging_mixin.py:115} INFO - [2023-11-16 09:17:05,991] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:17:06,010] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:17:06,037] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.103 seconds
[2023-11-16 09:17:36,528] {processor.py:153} INFO - Started process (PID=3579) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:17:36,529] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:17:36,530] {logging_mixin.py:115} INFO - [2023-11-16 09:17:36,530] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:17:36,609] {logging_mixin.py:115} INFO - [2023-11-16 09:17:36,591] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:17:36,612] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:17:36,642] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.118 seconds
[2023-11-16 09:18:07,057] {processor.py:153} INFO - Started process (PID=3637) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:18:07,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:18:07,059] {logging_mixin.py:115} INFO - [2023-11-16 09:18:07,059] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:18:07,172] {logging_mixin.py:115} INFO - [2023-11-16 09:18:07,152] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:18:07,176] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:18:07,206] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 09:18:37,482] {processor.py:153} INFO - Started process (PID=3705) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:18:37,483] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:18:37,484] {logging_mixin.py:115} INFO - [2023-11-16 09:18:37,484] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:18:37,567] {logging_mixin.py:115} INFO - [2023-11-16 09:18:37,548] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:18:37,570] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:18:37,602] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.123 seconds
[2023-11-16 09:19:07,775] {processor.py:153} INFO - Started process (PID=3763) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:19:07,776] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:19:07,777] {logging_mixin.py:115} INFO - [2023-11-16 09:19:07,777] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:19:07,863] {logging_mixin.py:115} INFO - [2023-11-16 09:19:07,845] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:19:07,865] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:19:07,896] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.125 seconds
[2023-11-16 09:19:38,373] {processor.py:153} INFO - Started process (PID=3830) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:19:38,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:19:38,376] {logging_mixin.py:115} INFO - [2023-11-16 09:19:38,376] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:19:38,449] {logging_mixin.py:115} INFO - [2023-11-16 09:19:38,433] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:19:38,452] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:19:38,481] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.112 seconds
[2023-11-16 09:20:09,122] {processor.py:153} INFO - Started process (PID=3888) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:20:09,123] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:20:09,125] {logging_mixin.py:115} INFO - [2023-11-16 09:20:09,125] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:20:09,210] {logging_mixin.py:115} INFO - [2023-11-16 09:20:09,189] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:20:09,213] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:20:09,245] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.126 seconds
[2023-11-16 09:20:39,847] {processor.py:153} INFO - Started process (PID=3955) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:20:39,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:20:39,849] {logging_mixin.py:115} INFO - [2023-11-16 09:20:39,849] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:20:39,923] {logging_mixin.py:115} INFO - [2023-11-16 09:20:39,907] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:20:39,926] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:20:39,954] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.110 seconds
[2023-11-16 09:21:10,328] {processor.py:153} INFO - Started process (PID=4013) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:21:10,329] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:21:10,330] {logging_mixin.py:115} INFO - [2023-11-16 09:21:10,330] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:21:10,409] {logging_mixin.py:115} INFO - [2023-11-16 09:21:10,390] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:21:10,411] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:21:10,440] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.116 seconds
[2023-11-16 09:21:40,756] {processor.py:153} INFO - Started process (PID=4080) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:21:40,757] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:21:40,758] {logging_mixin.py:115} INFO - [2023-11-16 09:21:40,758] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:21:40,834] {logging_mixin.py:115} INFO - [2023-11-16 09:21:40,817] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:21:40,837] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:21:40,864] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.113 seconds
[2023-11-16 09:22:11,798] {processor.py:153} INFO - Started process (PID=4147) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:22:11,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:22:11,800] {logging_mixin.py:115} INFO - [2023-11-16 09:22:11,800] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:22:11,886] {logging_mixin.py:115} INFO - [2023-11-16 09:22:11,867] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:22:11,889] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:22:11,919] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.124 seconds
[2023-11-16 09:22:42,859] {processor.py:153} INFO - Started process (PID=4205) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:22:42,860] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:22:42,861] {logging_mixin.py:115} INFO - [2023-11-16 09:22:42,861] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:22:42,937] {logging_mixin.py:115} INFO - [2023-11-16 09:22:42,921] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:22:42,940] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:22:42,968] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.112 seconds
[2023-11-16 09:23:13,365] {processor.py:153} INFO - Started process (PID=4272) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:23:13,366] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:23:13,367] {logging_mixin.py:115} INFO - [2023-11-16 09:23:13,367] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:23:13,454] {logging_mixin.py:115} INFO - [2023-11-16 09:23:13,437] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:23:13,457] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:23:13,487] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.127 seconds
[2023-11-16 09:23:43,667] {processor.py:153} INFO - Started process (PID=4330) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:23:43,668] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:23:43,670] {logging_mixin.py:115} INFO - [2023-11-16 09:23:43,670] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:23:43,758] {logging_mixin.py:115} INFO - [2023-11-16 09:23:43,736] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:23:43,761] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:23:43,792] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.129 seconds
[2023-11-16 09:24:14,484] {processor.py:153} INFO - Started process (PID=4397) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:24:14,486] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:24:14,487] {logging_mixin.py:115} INFO - [2023-11-16 09:24:14,487] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:24:14,591] {logging_mixin.py:115} INFO - [2023-11-16 09:24:14,566] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:24:14,594] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:24:14,630] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.149 seconds
[2023-11-16 09:24:45,120] {processor.py:153} INFO - Started process (PID=4455) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:24:45,121] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:24:45,123] {logging_mixin.py:115} INFO - [2023-11-16 09:24:45,123] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:24:45,199] {logging_mixin.py:115} INFO - [2023-11-16 09:24:45,179] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:24:45,202] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:24:45,235] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.118 seconds
[2023-11-16 09:25:15,936] {processor.py:153} INFO - Started process (PID=4522) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:25:15,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:25:15,938] {logging_mixin.py:115} INFO - [2023-11-16 09:25:15,938] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:25:16,024] {logging_mixin.py:115} INFO - [2023-11-16 09:25:16,005] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:25:16,027] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:25:16,059] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.130 seconds
[2023-11-16 09:25:46,680] {processor.py:153} INFO - Started process (PID=4580) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:25:46,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:25:46,682] {logging_mixin.py:115} INFO - [2023-11-16 09:25:46,682] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:25:46,757] {logging_mixin.py:115} INFO - [2023-11-16 09:25:46,738] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:25:46,759] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:25:46,789] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.112 seconds
[2023-11-16 09:26:17,299] {processor.py:153} INFO - Started process (PID=4647) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:26:17,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:26:17,301] {logging_mixin.py:115} INFO - [2023-11-16 09:26:17,301] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:26:17,379] {logging_mixin.py:115} INFO - [2023-11-16 09:26:17,361] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:26:17,382] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:26:17,420] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.124 seconds
[2023-11-16 09:26:47,743] {processor.py:153} INFO - Started process (PID=4705) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:26:47,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:26:47,744] {logging_mixin.py:115} INFO - [2023-11-16 09:26:47,744] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:26:47,818] {logging_mixin.py:115} INFO - [2023-11-16 09:26:47,800] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:26:47,821] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:26:47,851] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.112 seconds
[2023-11-16 09:27:18,232] {processor.py:153} INFO - Started process (PID=4772) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:27:18,233] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:27:18,234] {logging_mixin.py:115} INFO - [2023-11-16 09:27:18,234] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:27:18,316] {logging_mixin.py:115} INFO - [2023-11-16 09:27:18,297] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:27:18,319] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:27:18,353] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.125 seconds
[2023-11-16 09:27:48,798] {processor.py:153} INFO - Started process (PID=4830) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:27:48,799] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:27:48,799] {logging_mixin.py:115} INFO - [2023-11-16 09:27:48,799] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:27:48,889] {logging_mixin.py:115} INFO - [2023-11-16 09:27:48,865] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:27:48,893] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:27:48,930] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.137 seconds
[2023-11-16 09:28:19,298] {processor.py:153} INFO - Started process (PID=4897) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:28:19,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:28:19,300] {logging_mixin.py:115} INFO - [2023-11-16 09:28:19,300] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:28:19,367] {logging_mixin.py:115} INFO - [2023-11-16 09:28:19,351] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:28:19,369] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:28:19,394] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.099 seconds
[2023-11-16 09:28:49,791] {processor.py:153} INFO - Started process (PID=4955) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:28:49,792] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:28:49,797] {logging_mixin.py:115} INFO - [2023-11-16 09:28:49,796] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:28:49,868] {logging_mixin.py:115} INFO - [2023-11-16 09:28:49,851] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:28:49,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:28:49,899] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.111 seconds
[2023-11-16 09:29:20,373] {processor.py:153} INFO - Started process (PID=5022) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:29:20,374] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:29:20,375] {logging_mixin.py:115} INFO - [2023-11-16 09:29:20,375] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:29:20,449] {logging_mixin.py:115} INFO - [2023-11-16 09:29:20,432] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:29:20,451] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:29:20,476] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.107 seconds
[2023-11-16 09:29:51,060] {processor.py:153} INFO - Started process (PID=5090) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:29:51,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:29:51,064] {logging_mixin.py:115} INFO - [2023-11-16 09:29:51,064] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:29:51,193] {logging_mixin.py:115} INFO - [2023-11-16 09:29:51,170] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:29:51,196] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:29:51,237] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.182 seconds
[2023-11-16 09:30:22,115] {processor.py:153} INFO - Started process (PID=5148) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:30:22,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:30:22,117] {logging_mixin.py:115} INFO - [2023-11-16 09:30:22,117] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:30:22,194] {logging_mixin.py:115} INFO - [2023-11-16 09:30:22,176] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:30:22,197] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:30:22,229] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.119 seconds
[2023-11-16 09:30:53,042] {processor.py:153} INFO - Started process (PID=5216) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:30:53,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:30:53,045] {logging_mixin.py:115} INFO - [2023-11-16 09:30:53,045] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:30:53,143] {logging_mixin.py:115} INFO - [2023-11-16 09:30:53,123] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 45, in get_vacancy
    if not check_db_result():
  File "/opt/airflow/dags/parsing_hh/main.py", line 36, in check_db_result
    cursor = conn.cursor()
NameError: name 'conn' is not defined
[2023-11-16 09:30:53,146] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:30:53,178] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.140 seconds
[2023-11-16 09:31:23,273] {processor.py:153} INFO - Started process (PID=5274) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:31:23,274] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:31:23,275] {logging_mixin.py:115} INFO - [2023-11-16 09:31:23,275] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:31:23,376] {logging_mixin.py:115} INFO - [2023-11-16 09:31:23,376] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:31:46,022] {logging_mixin.py:115} INFO - [2023-11-16 09:31:45,988] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 424, in connect
    tls_in_tls=tls_in_tls,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 450, in ssl_wrap_socket
    sock, context, tls_in_tls, server_hostname=server_hostname
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/local/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/usr/local/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/usr/local/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
OSError: [Errno 0] Error

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 499, in send
    timeout=timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 786, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1040, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connection.py", line 424, in connect
    tls_in_tls=tls_in_tls,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 450, in ssl_wrap_socket
    sock, context, tls_in_tls, server_hostname=server_hostname
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/usr/local/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/usr/local/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/usr/local/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
urllib3.exceptions.ProtocolError: ('Connection aborted.', OSError(0, 'Error'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/__init__.py", line 1, in <module>
    from parsing_hh.main import get_vacancy
  File "/opt/airflow/dags/parsing_hh/main.py", line 107, in <module>
    get_vacancy()
  File "/opt/airflow/dags/parsing_hh/main.py", line 79, in get_vacancy
    page_dict = json.loads(get_hh(filter, page, period)[1])
  File "/opt/airflow/dags/parsing_hh/main.py", line 55, in get_hh
    r = requests.get(url, params=params)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/requests/adapters.py", line 547, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', OSError(0, 'Error'))
[2023-11-16 09:31:46,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:31:46,043] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 22.774 seconds
[2023-11-16 09:32:16,639] {processor.py:153} INFO - Started process (PID=5388) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:32:16,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:32:16,642] {logging_mixin.py:115} INFO - [2023-11-16 09:32:16,642] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:32:16,760] {logging_mixin.py:115} INFO - [2023-11-16 09:32:16,760] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:32:18,739] {logging_mixin.py:115} INFO - [2023-11-16 09:32:18,739] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:32:18,766] {logging_mixin.py:115} INFO - [2023-11-16 09:32:18,760] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:32:18,768] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:32:18,785] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 2.151 seconds
[2023-11-16 09:32:49,494] {processor.py:153} INFO - Started process (PID=5455) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:32:49,494] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:32:49,496] {logging_mixin.py:115} INFO - [2023-11-16 09:32:49,495] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:32:49,576] {logging_mixin.py:115} INFO - [2023-11-16 09:32:49,576] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:32:51,743] {logging_mixin.py:115} INFO - [2023-11-16 09:32:51,743] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:32:51,772] {logging_mixin.py:115} INFO - [2023-11-16 09:32:51,765] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:32:51,775] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:32:51,792] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 2.302 seconds
[2023-11-16 09:33:22,247] {processor.py:153} INFO - Started process (PID=5523) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:33:22,248] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:33:22,249] {logging_mixin.py:115} INFO - [2023-11-16 09:33:22,248] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:33:22,324] {logging_mixin.py:115} INFO - [2023-11-16 09:33:22,324] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:33:23,908] {logging_mixin.py:115} INFO - [2023-11-16 09:33:23,908] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:33:23,938] {logging_mixin.py:115} INFO - [2023-11-16 09:33:23,932] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:33:23,941] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:33:23,959] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 1.716 seconds
[2023-11-16 09:33:54,493] {processor.py:153} INFO - Started process (PID=5590) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:33:54,494] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:33:54,495] {logging_mixin.py:115} INFO - [2023-11-16 09:33:54,495] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:33:54,605] {logging_mixin.py:115} INFO - [2023-11-16 09:33:54,605] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:33:56,272] {logging_mixin.py:115} INFO - [2023-11-16 09:33:56,272] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:33:56,312] {logging_mixin.py:115} INFO - [2023-11-16 09:33:56,305] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:33:56,315] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:33:56,337] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 1.850 seconds
[2023-11-16 09:34:26,499] {processor.py:153} INFO - Started process (PID=5648) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:34:26,500] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:34:26,501] {logging_mixin.py:115} INFO - [2023-11-16 09:34:26,501] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:34:26,571] {logging_mixin.py:115} INFO - [2023-11-16 09:34:26,571] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:34:34,171] {logging_mixin.py:115} INFO - [2023-11-16 09:34:34,171] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:34:34,206] {logging_mixin.py:115} INFO - [2023-11-16 09:34:34,198] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:34:34,209] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:34:34,244] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 7.748 seconds
[2023-11-16 09:35:05,095] {processor.py:153} INFO - Started process (PID=5724) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:35:05,095] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:35:05,097] {logging_mixin.py:115} INFO - [2023-11-16 09:35:05,097] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:35:05,180] {logging_mixin.py:115} INFO - [2023-11-16 09:35:05,180] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:35:06,618] {logging_mixin.py:115} INFO - [2023-11-16 09:35:06,618] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:35:06,649] {logging_mixin.py:115} INFO - [2023-11-16 09:35:06,642] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:35:06,651] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:35:06,667] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 1.576 seconds
[2023-11-16 09:35:37,510] {processor.py:153} INFO - Started process (PID=5782) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:35:37,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:35:37,512] {logging_mixin.py:115} INFO - [2023-11-16 09:35:37,512] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:35:37,584] {logging_mixin.py:115} INFO - [2023-11-16 09:35:37,584] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:35:39,260] {logging_mixin.py:115} INFO - [2023-11-16 09:35:39,260] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:35:39,288] {logging_mixin.py:115} INFO - [2023-11-16 09:35:39,282] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:35:39,290] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:35:39,307] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 1.801 seconds
[2023-11-16 09:36:09,398] {processor.py:153} INFO - Started process (PID=5849) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:36:09,399] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:36:09,400] {logging_mixin.py:115} INFO - [2023-11-16 09:36:09,400] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:36:09,481] {logging_mixin.py:115} INFO - [2023-11-16 09:36:09,481] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:36:11,303] {logging_mixin.py:115} INFO - [2023-11-16 09:36:11,303] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:36:11,356] {logging_mixin.py:115} INFO - [2023-11-16 09:36:11,346] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:36:11,359] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:36:11,390] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 1.996 seconds
[2023-11-16 09:36:41,541] {processor.py:153} INFO - Started process (PID=5921) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:36:41,542] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:36:41,543] {logging_mixin.py:115} INFO - [2023-11-16 09:36:41,543] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:36:41,650] {logging_mixin.py:115} INFO - [2023-11-16 09:36:41,650] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:36:43,392] {logging_mixin.py:115} INFO - [2023-11-16 09:36:43,391] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:36:43,423] {logging_mixin.py:115} INFO - [2023-11-16 09:36:43,416] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:36:43,426] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:36:43,444] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 1.909 seconds
[2023-11-16 09:37:13,585] {processor.py:153} INFO - Started process (PID=5983) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:37:13,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:37:13,587] {logging_mixin.py:115} INFO - [2023-11-16 09:37:13,587] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:37:13,673] {logging_mixin.py:115} INFO - [2023-11-16 09:37:13,673] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:37:15,878] {logging_mixin.py:115} INFO - [2023-11-16 09:37:15,878] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:37:15,911] {logging_mixin.py:115} INFO - [2023-11-16 09:37:15,902] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:37:15,915] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:37:15,941] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 2.361 seconds
[2023-11-16 09:37:46,133] {processor.py:153} INFO - Started process (PID=6051) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:37:46,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:37:46,135] {logging_mixin.py:115} INFO - [2023-11-16 09:37:46,135] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:37:46,225] {logging_mixin.py:115} INFO - [2023-11-16 09:37:46,225] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:37:48,071] {logging_mixin.py:115} INFO - [2023-11-16 09:37:48,071] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:37:48,098] {logging_mixin.py:115} INFO - [2023-11-16 09:37:48,093] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:37:48,100] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:37:48,117] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 1.988 seconds
[2023-11-16 09:38:18,184] {processor.py:153} INFO - Started process (PID=6122) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:38:18,185] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:38:18,186] {logging_mixin.py:115} INFO - [2023-11-16 09:38:18,186] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:38:18,294] {logging_mixin.py:115} INFO - [2023-11-16 09:38:18,294] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:38:22,176] {logging_mixin.py:115} INFO - [2023-11-16 09:38:22,176] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:38:22,202] {logging_mixin.py:115} INFO - [2023-11-16 09:38:22,197] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:38:22,205] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:38:22,223] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 4.044 seconds
[2023-11-16 09:38:52,661] {processor.py:153} INFO - Started process (PID=6200) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:38:52,662] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:38:52,663] {logging_mixin.py:115} INFO - [2023-11-16 09:38:52,663] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:38:52,774] {logging_mixin.py:115} INFO - [2023-11-16 09:38:52,774] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:38:54,685] {logging_mixin.py:115} INFO - [2023-11-16 09:38:54,685] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:38:54,737] {logging_mixin.py:115} INFO - [2023-11-16 09:38:54,725] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:38:54,740] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:38:54,765] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 2.108 seconds
[2023-11-16 09:39:25,564] {processor.py:153} INFO - Started process (PID=6261) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:39:25,565] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:39:25,567] {logging_mixin.py:115} INFO - [2023-11-16 09:39:25,567] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:39:25,669] {logging_mixin.py:115} INFO - [2023-11-16 09:39:25,669] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:39:27,949] {logging_mixin.py:115} INFO - [2023-11-16 09:39:27,949] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:39:27,996] {logging_mixin.py:115} INFO - [2023-11-16 09:39:27,987] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:39:27,999] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:39:28,021] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 2.460 seconds
[2023-11-16 09:39:58,143] {processor.py:153} INFO - Started process (PID=6335) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:39:58,144] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:39:58,146] {logging_mixin.py:115} INFO - [2023-11-16 09:39:58,145] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:39:58,283] {logging_mixin.py:115} INFO - [2023-11-16 09:39:58,283] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:39:58,312] {logging_mixin.py:115} INFO - [2023-11-16 09:39:58,312] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:39:58,341] {logging_mixin.py:115} INFO - [2023-11-16 09:39:58,335] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:39:58,343] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:39:58,359] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.220 seconds
[2023-11-16 09:40:28,407] {processor.py:153} INFO - Started process (PID=6392) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:40:28,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:40:28,410] {logging_mixin.py:115} INFO - [2023-11-16 09:40:28,410] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:40:28,497] {logging_mixin.py:115} INFO - [2023-11-16 09:40:28,497] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:40:28,527] {logging_mixin.py:115} INFO - [2023-11-16 09:40:28,527] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:40:28,557] {logging_mixin.py:115} INFO - [2023-11-16 09:40:28,550] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:40:28,561] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:40:28,580] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.177 seconds
[2023-11-16 09:40:58,799] {processor.py:153} INFO - Started process (PID=6459) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:40:58,800] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:40:58,800] {logging_mixin.py:115} INFO - [2023-11-16 09:40:58,800] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:40:58,918] {logging_mixin.py:115} INFO - [2023-11-16 09:40:58,918] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:40:58,955] {logging_mixin.py:115} INFO - [2023-11-16 09:40:58,955] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:40:58,989] {logging_mixin.py:115} INFO - [2023-11-16 09:40:58,982] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:40:58,992] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:40:59,013] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 09:41:29,177] {processor.py:153} INFO - Started process (PID=6523) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:41:29,178] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:41:29,179] {logging_mixin.py:115} INFO - [2023-11-16 09:41:29,179] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:41:29,290] {logging_mixin.py:115} INFO - [2023-11-16 09:41:29,290] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:41:29,321] {logging_mixin.py:115} INFO - [2023-11-16 09:41:29,321] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:41:29,353] {logging_mixin.py:115} INFO - [2023-11-16 09:41:29,347] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 65, in <module>
    catchup=False
TypeError: __init__() got an unexpected keyword argument 'shedule_interval'
[2023-11-16 09:41:29,356] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:41:29,377] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.204 seconds
[2023-11-16 09:41:55,202] {processor.py:153} INFO - Started process (PID=6578) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:41:55,203] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:41:55,204] {logging_mixin.py:115} INFO - [2023-11-16 09:41:55,204] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:41:55,313] {logging_mixin.py:115} INFO - [2023-11-16 09:41:55,313] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:41:55,342] {logging_mixin.py:115} INFO - [2023-11-16 09:41:55,342] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:41:55,376] {logging_mixin.py:115} INFO - [2023-11-16 09:41:55,366] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 70, in <module>
    python_callable = load_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 156, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 880, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 990, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1048, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 09:41:55,377] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:41:55,394] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.196 seconds
[2023-11-16 09:42:25,870] {processor.py:153} INFO - Started process (PID=6635) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:42:25,871] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:42:25,873] {logging_mixin.py:115} INFO - [2023-11-16 09:42:25,872] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:42:25,962] {logging_mixin.py:115} INFO - [2023-11-16 09:42:25,962] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:42:25,990] {logging_mixin.py:115} INFO - [2023-11-16 09:42:25,990] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:42:26,022] {logging_mixin.py:115} INFO - [2023-11-16 09:42:26,014] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 70, in <module>
    python_callable = load_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 156, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 880, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 990, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1048, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 09:42:26,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:42:26,041] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.174 seconds
[2023-11-16 09:42:56,357] {processor.py:153} INFO - Started process (PID=6702) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:42:56,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:42:56,360] {logging_mixin.py:115} INFO - [2023-11-16 09:42:56,360] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:42:56,494] {logging_mixin.py:115} INFO - [2023-11-16 09:42:56,494] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:42:56,526] {logging_mixin.py:115} INFO - [2023-11-16 09:42:56,526] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:42:56,561] {logging_mixin.py:115} INFO - [2023-11-16 09:42:56,552] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 70, in <module>
    python_callable = load_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 156, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 880, in __init__
    self.dag = dag
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 990, in __setattr__
    super().__setattr__(key, value)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1048, in dag
    dag.add_task(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 09:42:56,562] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:42:56,583] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.231 seconds
[2023-11-16 09:43:02,537] {processor.py:153} INFO - Started process (PID=6716) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:43:02,538] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:43:02,539] {logging_mixin.py:115} INFO - [2023-11-16 09:43:02,539] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:43:02,715] {logging_mixin.py:115} INFO - [2023-11-16 09:43:02,715] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:43:02,748] {logging_mixin.py:115} INFO - [2023-11-16 09:43:02,747] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:43:02,781] {logging_mixin.py:115} INFO - [2023-11-16 09:43:02,775] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 71, in <module>
    python_callable = load_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    raise AirflowException('`python_callable` param must be callable')
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2023-11-16 09:43:02,782] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:43:02,803] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.271 seconds
[2023-11-16 09:43:33,630] {processor.py:153} INFO - Started process (PID=6783) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:43:33,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:43:33,632] {logging_mixin.py:115} INFO - [2023-11-16 09:43:33,632] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:43:33,715] {logging_mixin.py:115} INFO - [2023-11-16 09:43:33,715] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:43:33,745] {logging_mixin.py:115} INFO - [2023-11-16 09:43:33,744] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:43:33,776] {logging_mixin.py:115} INFO - [2023-11-16 09:43:33,770] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 71, in <module>
    python_callable = load_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    raise AirflowException('`python_callable` param must be callable')
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2023-11-16 09:43:33,777] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:43:33,797] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.172 seconds
[2023-11-16 09:44:03,869] {processor.py:153} INFO - Started process (PID=6848) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:03,870] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:44:03,871] {logging_mixin.py:115} INFO - [2023-11-16 09:44:03,871] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:03,964] {logging_mixin.py:115} INFO - [2023-11-16 09:44:03,964] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:44:03,993] {logging_mixin.py:115} INFO - [2023-11-16 09:44:03,993] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:44:04,025] {logging_mixin.py:115} INFO - [2023-11-16 09:44:04,019] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 71, in <module>
    python_callable = load_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    raise AirflowException('`python_callable` param must be callable')
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2023-11-16 09:44:04,026] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:04,045] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.181 seconds
[2023-11-16 09:44:34,728] {processor.py:153} INFO - Started process (PID=6908) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:34,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:44:34,734] {logging_mixin.py:115} INFO - [2023-11-16 09:44:34,733] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:34,902] {logging_mixin.py:115} INFO - [2023-11-16 09:44:34,902] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:44:34,935] {logging_mixin.py:115} INFO - [2023-11-16 09:44:34,934] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:44:34,969] {logging_mixin.py:115} INFO - [2023-11-16 09:44:34,960] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 71, in <module>
    python_callable = load_data()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 158, in __init__
    raise AirflowException('`python_callable` param must be callable')
airflow.exceptions.AirflowException: `python_callable` param must be callable
[2023-11-16 09:44:34,970] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:34,990] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.272 seconds
[2023-11-16 09:44:58,280] {processor.py:153} INFO - Started process (PID=6953) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:58,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:44:58,282] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,282] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:58,376] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,376] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:44:58,402] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,402] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:44:58,426] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:44:58,554] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,554] {manager.py:508} INFO - Created Permission View: can edit on DAG:etl_hh
[2023-11-16 09:44:58,569] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,569] {manager.py:508} INFO - Created Permission View: can read on DAG:etl_hh
[2023-11-16 09:44:58,583] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,583] {manager.py:508} INFO - Created Permission View: can delete on DAG:etl_hh
[2023-11-16 09:44:58,583] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,583] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:44:58,597] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,597] {dag.py:2439} INFO - Creating ORM DAG for etl_hh
[2023-11-16 09:44:58,616] {logging_mixin.py:115} INFO - [2023-11-16 09:44:58,616] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:44:58,641] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.364 seconds
[2023-11-16 09:45:29,384] {processor.py:153} INFO - Started process (PID=7020) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:45:29,386] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:45:29,387] {logging_mixin.py:115} INFO - [2023-11-16 09:45:29,387] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:45:29,470] {logging_mixin.py:115} INFO - [2023-11-16 09:45:29,470] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:45:29,498] {logging_mixin.py:115} INFO - [2023-11-16 09:45:29,498] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:45:29,523] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:45:29,542] {logging_mixin.py:115} INFO - [2023-11-16 09:45:29,541] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:45:29,581] {logging_mixin.py:115} INFO - [2023-11-16 09:45:29,581] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:45:29,603] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.222 seconds
[2023-11-16 09:46:00,519] {processor.py:153} INFO - Started process (PID=7078) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:46:00,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:46:00,522] {logging_mixin.py:115} INFO - [2023-11-16 09:46:00,522] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:46:00,594] {logging_mixin.py:115} INFO - [2023-11-16 09:46:00,594] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:46:00,621] {logging_mixin.py:115} INFO - [2023-11-16 09:46:00,621] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:46:00,645] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:46:00,664] {logging_mixin.py:115} INFO - [2023-11-16 09:46:00,664] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:46:00,695] {logging_mixin.py:115} INFO - [2023-11-16 09:46:00,695] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:46:00,719] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.204 seconds
[2023-11-16 09:46:30,901] {processor.py:153} INFO - Started process (PID=7145) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:46:30,902] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:46:30,904] {logging_mixin.py:115} INFO - [2023-11-16 09:46:30,904] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:46:30,978] {logging_mixin.py:115} INFO - [2023-11-16 09:46:30,978] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:46:31,005] {logging_mixin.py:115} INFO - [2023-11-16 09:46:31,005] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:46:31,030] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:46:31,049] {logging_mixin.py:115} INFO - [2023-11-16 09:46:31,049] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:46:31,081] {logging_mixin.py:115} INFO - [2023-11-16 09:46:31,081] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:46:31,104] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.207 seconds
[2023-11-16 09:47:01,242] {processor.py:153} INFO - Started process (PID=7203) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:47:01,243] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:47:01,244] {logging_mixin.py:115} INFO - [2023-11-16 09:47:01,244] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:47:01,320] {logging_mixin.py:115} INFO - [2023-11-16 09:47:01,320] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:47:01,346] {logging_mixin.py:115} INFO - [2023-11-16 09:47:01,346] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:47:01,369] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:47:01,388] {logging_mixin.py:115} INFO - [2023-11-16 09:47:01,388] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:47:01,420] {logging_mixin.py:115} INFO - [2023-11-16 09:47:01,420] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:47:01,444] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.207 seconds
[2023-11-16 09:47:31,705] {processor.py:153} INFO - Started process (PID=7271) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:47:31,707] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:47:31,708] {logging_mixin.py:115} INFO - [2023-11-16 09:47:31,708] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:47:31,798] {logging_mixin.py:115} INFO - [2023-11-16 09:47:31,798] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:47:31,827] {logging_mixin.py:115} INFO - [2023-11-16 09:47:31,826] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:47:31,853] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:47:31,873] {logging_mixin.py:115} INFO - [2023-11-16 09:47:31,873] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:47:31,907] {logging_mixin.py:115} INFO - [2023-11-16 09:47:31,907] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:47:31,929] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.227 seconds
[2023-11-16 09:48:02,092] {processor.py:153} INFO - Started process (PID=7340) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:48:02,093] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:48:02,094] {logging_mixin.py:115} INFO - [2023-11-16 09:48:02,094] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:48:02,190] {logging_mixin.py:115} INFO - [2023-11-16 09:48:02,189] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:48:02,220] {logging_mixin.py:115} INFO - [2023-11-16 09:48:02,220] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:48:02,247] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:48:02,272] {logging_mixin.py:115} INFO - [2023-11-16 09:48:02,272] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:48:02,311] {logging_mixin.py:115} INFO - [2023-11-16 09:48:02,311] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:48:02,336] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.247 seconds
[2023-11-16 09:48:32,515] {processor.py:153} INFO - Started process (PID=7398) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:48:32,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:48:32,517] {logging_mixin.py:115} INFO - [2023-11-16 09:48:32,517] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:48:32,594] {logging_mixin.py:115} INFO - [2023-11-16 09:48:32,594] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:48:32,619] {logging_mixin.py:115} INFO - [2023-11-16 09:48:32,619] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:48:32,641] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:48:32,658] {logging_mixin.py:115} INFO - [2023-11-16 09:48:32,658] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:48:32,685] {logging_mixin.py:115} INFO - [2023-11-16 09:48:32,685] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:48:32,703] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.191 seconds
[2023-11-16 09:49:02,860] {processor.py:153} INFO - Started process (PID=7466) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:49:02,861] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:49:02,862] {logging_mixin.py:115} INFO - [2023-11-16 09:49:02,862] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:49:02,948] {logging_mixin.py:115} INFO - [2023-11-16 09:49:02,948] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:49:02,973] {logging_mixin.py:115} INFO - [2023-11-16 09:49:02,973] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:49:02,995] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:49:03,013] {logging_mixin.py:115} INFO - [2023-11-16 09:49:03,013] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:49:03,047] {logging_mixin.py:115} INFO - [2023-11-16 09:49:03,047] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:49:03,064] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.208 seconds
[2023-11-16 09:49:33,280] {processor.py:153} INFO - Started process (PID=7522) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:49:33,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:49:33,283] {logging_mixin.py:115} INFO - [2023-11-16 09:49:33,282] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:49:33,361] {logging_mixin.py:115} INFO - [2023-11-16 09:49:33,361] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:49:33,395] {logging_mixin.py:115} INFO - [2023-11-16 09:49:33,395] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:49:33,435] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:49:33,461] {logging_mixin.py:115} INFO - [2023-11-16 09:49:33,461] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:49:33,501] {logging_mixin.py:115} INFO - [2023-11-16 09:49:33,501] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:49:33,523] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.247 seconds
[2023-11-16 09:50:04,261] {processor.py:153} INFO - Started process (PID=7589) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:50:04,262] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:50:04,263] {logging_mixin.py:115} INFO - [2023-11-16 09:50:04,263] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:50:04,354] {logging_mixin.py:115} INFO - [2023-11-16 09:50:04,354] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:50:04,381] {logging_mixin.py:115} INFO - [2023-11-16 09:50:04,381] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:50:04,405] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:50:04,425] {logging_mixin.py:115} INFO - [2023-11-16 09:50:04,425] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:50:04,460] {logging_mixin.py:115} INFO - [2023-11-16 09:50:04,460] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:50:04,493] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.237 seconds
[2023-11-16 09:50:34,757] {processor.py:153} INFO - Started process (PID=7647) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:50:34,758] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:50:34,759] {logging_mixin.py:115} INFO - [2023-11-16 09:50:34,759] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:50:34,854] {logging_mixin.py:115} INFO - [2023-11-16 09:50:34,854] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:50:34,882] {logging_mixin.py:115} INFO - [2023-11-16 09:50:34,882] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:50:34,907] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:50:34,932] {logging_mixin.py:115} INFO - [2023-11-16 09:50:34,931] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:50:34,975] {logging_mixin.py:115} INFO - [2023-11-16 09:50:34,975] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:50:35,001] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.247 seconds
[2023-11-16 09:51:05,994] {processor.py:153} INFO - Started process (PID=7714) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:51:05,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:51:05,996] {logging_mixin.py:115} INFO - [2023-11-16 09:51:05,996] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:51:06,075] {logging_mixin.py:115} INFO - [2023-11-16 09:51:06,075] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:51:06,102] {logging_mixin.py:115} INFO - [2023-11-16 09:51:06,102] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:51:06,128] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:51:06,154] {logging_mixin.py:115} INFO - [2023-11-16 09:51:06,154] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:51:06,195] {logging_mixin.py:115} INFO - [2023-11-16 09:51:06,195] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:51:06,219] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.231 seconds
[2023-11-16 09:51:36,584] {processor.py:153} INFO - Started process (PID=7781) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:51:36,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:51:36,587] {logging_mixin.py:115} INFO - [2023-11-16 09:51:36,587] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:51:36,731] {logging_mixin.py:115} INFO - [2023-11-16 09:51:36,730] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:51:36,762] {logging_mixin.py:115} INFO - [2023-11-16 09:51:36,762] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:51:36,792] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:51:36,822] {logging_mixin.py:115} INFO - [2023-11-16 09:51:36,821] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:51:36,867] {logging_mixin.py:115} INFO - [2023-11-16 09:51:36,866] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:51:36,891] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.312 seconds
[2023-11-16 09:52:07,461] {processor.py:153} INFO - Started process (PID=7839) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:07,462] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:52:07,464] {logging_mixin.py:115} INFO - [2023-11-16 09:52:07,463] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:07,570] {logging_mixin.py:115} INFO - [2023-11-16 09:52:07,569] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:52:07,599] {logging_mixin.py:115} INFO - [2023-11-16 09:52:07,599] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:52:07,630] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:07,670] {logging_mixin.py:115} INFO - [2023-11-16 09:52:07,669] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:52:07,743] {logging_mixin.py:115} INFO - [2023-11-16 09:52:07,743] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:52:07,766] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.311 seconds
[2023-11-16 09:52:38,151] {processor.py:153} INFO - Started process (PID=7906) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:38,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:52:38,155] {logging_mixin.py:115} INFO - [2023-11-16 09:52:38,155] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:38,263] {logging_mixin.py:115} INFO - [2023-11-16 09:52:38,263] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:52:38,307] {logging_mixin.py:115} INFO - [2023-11-16 09:52:38,307] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:52:38,344] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:38,378] {logging_mixin.py:115} INFO - [2023-11-16 09:52:38,377] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:52:38,428] {logging_mixin.py:115} INFO - [2023-11-16 09:52:38,428] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:52:38,453] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.308 seconds
[2023-11-16 09:52:54,881] {processor.py:153} INFO - Started process (PID=7929) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:54,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:52:54,883] {logging_mixin.py:115} INFO - [2023-11-16 09:52:54,883] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:55,008] {logging_mixin.py:115} INFO - [2023-11-16 09:52:55,008] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:52:55,038] {logging_mixin.py:115} INFO - [2023-11-16 09:52:55,038] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:52:55,065] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:52:55,090] {logging_mixin.py:115} INFO - [2023-11-16 09:52:55,090] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:52:55,136] {logging_mixin.py:115} INFO - [2023-11-16 09:52:55,136] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:52:55,174] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.297 seconds
[2023-11-16 09:53:25,814] {processor.py:153} INFO - Started process (PID=7994) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:53:25,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:53:25,818] {logging_mixin.py:115} INFO - [2023-11-16 09:53:25,817] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:53:25,930] {logging_mixin.py:115} INFO - [2023-11-16 09:53:25,929] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:53:25,958] {logging_mixin.py:115} INFO - [2023-11-16 09:53:25,958] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:53:25,986] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:53:26,009] {logging_mixin.py:115} INFO - [2023-11-16 09:53:26,009] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:53:26,089] {logging_mixin.py:115} INFO - [2023-11-16 09:53:26,088] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:53:26,133] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.325 seconds
[2023-11-16 09:53:56,243] {processor.py:153} INFO - Started process (PID=8055) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:53:56,244] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:53:56,246] {logging_mixin.py:115} INFO - [2023-11-16 09:53:56,246] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:53:56,336] {logging_mixin.py:115} INFO - [2023-11-16 09:53:56,336] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:53:56,367] {logging_mixin.py:115} INFO - [2023-11-16 09:53:56,367] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:53:56,392] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:53:56,422] {logging_mixin.py:115} INFO - [2023-11-16 09:53:56,422] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:53:56,460] {logging_mixin.py:115} INFO - [2023-11-16 09:53:56,460] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:53:56,487] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.247 seconds
[2023-11-16 09:54:26,717] {processor.py:153} INFO - Started process (PID=8121) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:54:26,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:54:26,720] {logging_mixin.py:115} INFO - [2023-11-16 09:54:26,720] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:54:26,825] {logging_mixin.py:115} INFO - [2023-11-16 09:54:26,825] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:54:26,855] {logging_mixin.py:115} INFO - [2023-11-16 09:54:26,855] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:54:26,884] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:54:26,913] {logging_mixin.py:115} INFO - [2023-11-16 09:54:26,913] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:54:26,958] {logging_mixin.py:115} INFO - [2023-11-16 09:54:26,958] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:54:26,984] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.271 seconds
[2023-11-16 09:54:57,083] {processor.py:153} INFO - Started process (PID=8180) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:54:57,084] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:54:57,085] {logging_mixin.py:115} INFO - [2023-11-16 09:54:57,085] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:54:57,170] {logging_mixin.py:115} INFO - [2023-11-16 09:54:57,170] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:54:57,197] {logging_mixin.py:115} INFO - [2023-11-16 09:54:57,197] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:54:57,222] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:54:57,249] {logging_mixin.py:115} INFO - [2023-11-16 09:54:57,249] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:54:57,287] {logging_mixin.py:115} INFO - [2023-11-16 09:54:57,287] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:54:57,311] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.232 seconds
[2023-11-16 09:55:27,446] {processor.py:153} INFO - Started process (PID=8246) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:55:27,448] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:55:27,450] {logging_mixin.py:115} INFO - [2023-11-16 09:55:27,449] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:55:27,535] {logging_mixin.py:115} INFO - [2023-11-16 09:55:27,535] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:55:27,570] {logging_mixin.py:115} INFO - [2023-11-16 09:55:27,570] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:55:27,594] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:55:27,617] {logging_mixin.py:115} INFO - [2023-11-16 09:55:27,616] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:55:27,700] {logging_mixin.py:115} INFO - [2023-11-16 09:55:27,700] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:55:27,738] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.297 seconds
[2023-11-16 09:55:58,006] {processor.py:153} INFO - Started process (PID=8304) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:55:58,007] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:55:58,009] {logging_mixin.py:115} INFO - [2023-11-16 09:55:58,008] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:55:58,090] {logging_mixin.py:115} INFO - [2023-11-16 09:55:58,089] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:55:58,120] {logging_mixin.py:115} INFO - [2023-11-16 09:55:58,120] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:55:58,146] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:55:58,169] {logging_mixin.py:115} INFO - [2023-11-16 09:55:58,169] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:55:58,204] {logging_mixin.py:115} INFO - [2023-11-16 09:55:58,204] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:55:58,226] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.224 seconds
[2023-11-16 09:56:04,044] {processor.py:153} INFO - Started process (PID=8324) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:56:04,045] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:56:04,046] {logging_mixin.py:115} INFO - [2023-11-16 09:56:04,046] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:56:04,130] {logging_mixin.py:115} INFO - [2023-11-16 09:56:04,129] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:56:04,155] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:56:04,183] {logging_mixin.py:115} INFO - [2023-11-16 09:56:04,183] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:56:04,219] {logging_mixin.py:115} INFO - [2023-11-16 09:56:04,219] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:56:04,251] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.210 seconds
[2023-11-16 09:56:30,007] {processor.py:153} INFO - Started process (PID=8377) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:56:30,008] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:56:30,010] {logging_mixin.py:115} INFO - [2023-11-16 09:56:30,009] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:56:30,120] {logging_mixin.py:115} INFO - [2023-11-16 09:56:30,120] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:56:30,152] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:56:30,182] {logging_mixin.py:115} INFO - [2023-11-16 09:56:30,182] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:56:30,226] {logging_mixin.py:115} INFO - [2023-11-16 09:56:30,226] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:56:30,257] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.255 seconds
[2023-11-16 09:57:00,805] {processor.py:153} INFO - Started process (PID=8434) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:57:00,806] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:57:00,807] {logging_mixin.py:115} INFO - [2023-11-16 09:57:00,807] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:57:00,856] {logging_mixin.py:115} INFO - [2023-11-16 09:57:00,856] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:57:00,881] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:57:00,903] {logging_mixin.py:115} INFO - [2023-11-16 09:57:00,902] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:57:00,937] {logging_mixin.py:115} INFO - [2023-11-16 09:57:00,937] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:57:00,958] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.157 seconds
[2023-11-16 09:57:31,511] {processor.py:153} INFO - Started process (PID=8501) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:57:31,512] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:57:31,514] {logging_mixin.py:115} INFO - [2023-11-16 09:57:31,514] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:57:31,584] {logging_mixin.py:115} INFO - [2023-11-16 09:57:31,584] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:57:31,632] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:57:31,656] {logging_mixin.py:115} INFO - [2023-11-16 09:57:31,656] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:57:31,711] {logging_mixin.py:115} INFO - [2023-11-16 09:57:31,711] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:57:31,734] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.227 seconds
[2023-11-16 09:58:02,264] {processor.py:153} INFO - Started process (PID=8559) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:58:02,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:58:02,266] {logging_mixin.py:115} INFO - [2023-11-16 09:58:02,266] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:58:02,322] {logging_mixin.py:115} INFO - [2023-11-16 09:58:02,322] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:58:02,347] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:58:02,368] {logging_mixin.py:115} INFO - [2023-11-16 09:58:02,368] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:58:02,404] {logging_mixin.py:115} INFO - [2023-11-16 09:58:02,403] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:58:02,421] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 09:58:33,073] {processor.py:153} INFO - Started process (PID=8626) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:58:33,075] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:58:33,077] {logging_mixin.py:115} INFO - [2023-11-16 09:58:33,076] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:58:33,179] {logging_mixin.py:115} INFO - [2023-11-16 09:58:33,179] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:58:33,220] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:58:33,260] {logging_mixin.py:115} INFO - [2023-11-16 09:58:33,260] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:58:33,342] {logging_mixin.py:115} INFO - [2023-11-16 09:58:33,342] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:58:33,394] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.327 seconds
[2023-11-16 09:59:03,543] {processor.py:153} INFO - Started process (PID=8691) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:59:03,544] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:59:03,545] {logging_mixin.py:115} INFO - [2023-11-16 09:59:03,545] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:59:03,595] {logging_mixin.py:115} INFO - [2023-11-16 09:59:03,595] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:59:03,622] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:59:03,645] {logging_mixin.py:115} INFO - [2023-11-16 09:59:03,645] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:59:03,695] {logging_mixin.py:115} INFO - [2023-11-16 09:59:03,695] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:59:03,725] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.186 seconds
[2023-11-16 09:59:34,393] {processor.py:153} INFO - Started process (PID=8751) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 09:59:34,394] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 09:59:34,396] {logging_mixin.py:115} INFO - [2023-11-16 09:59:34,395] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 09:59:34,456] {logging_mixin.py:115} INFO - [2023-11-16 09:59:34,456] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 09:59:34,481] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 09:59:34,503] {logging_mixin.py:115} INFO - [2023-11-16 09:59:34,503] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 09:59:34,560] {logging_mixin.py:115} INFO - [2023-11-16 09:59:34,560] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 09:59:34,612] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.223 seconds
[2023-11-16 10:00:03,406] {processor.py:153} INFO - Started process (PID=8805) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:00:03,407] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:00:03,408] {logging_mixin.py:115} INFO - [2023-11-16 10:00:03,408] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:00:03,497] {logging_mixin.py:115} INFO - [2023-11-16 10:00:03,497] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:00:03,533] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:00:03,580] {logging_mixin.py:115} INFO - [2023-11-16 10:00:03,580] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:00:03,668] {logging_mixin.py:115} INFO - [2023-11-16 10:00:03,667] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:00:03,708] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.307 seconds
[2023-11-16 10:00:33,779] {processor.py:153} INFO - Started process (PID=8872) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:00:33,780] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:00:33,781] {logging_mixin.py:115} INFO - [2023-11-16 10:00:33,781] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:00:33,836] {logging_mixin.py:115} INFO - [2023-11-16 10:00:33,836] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:00:33,873] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:00:33,897] {logging_mixin.py:115} INFO - [2023-11-16 10:00:33,897] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:00:33,940] {logging_mixin.py:115} INFO - [2023-11-16 10:00:33,940] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:00:33,971] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.195 seconds
[2023-11-16 10:01:04,185] {processor.py:153} INFO - Started process (PID=8930) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:01:04,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:01:04,187] {logging_mixin.py:115} INFO - [2023-11-16 10:01:04,187] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:01:04,245] {logging_mixin.py:115} INFO - [2023-11-16 10:01:04,244] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:01:04,273] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:01:04,293] {logging_mixin.py:115} INFO - [2023-11-16 10:01:04,293] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:01:04,325] {logging_mixin.py:115} INFO - [2023-11-16 10:01:04,325] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:01:04,344] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.163 seconds
[2023-11-16 10:01:34,399] {processor.py:153} INFO - Started process (PID=8997) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:01:34,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:01:34,403] {logging_mixin.py:115} INFO - [2023-11-16 10:01:34,403] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:01:34,481] {logging_mixin.py:115} INFO - [2023-11-16 10:01:34,481] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:01:34,509] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:01:34,542] {logging_mixin.py:115} INFO - [2023-11-16 10:01:34,541] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:01:34,585] {logging_mixin.py:115} INFO - [2023-11-16 10:01:34,585] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:01:34,614] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.220 seconds
[2023-11-16 10:02:04,822] {processor.py:153} INFO - Started process (PID=9056) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:02:04,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:02:04,824] {logging_mixin.py:115} INFO - [2023-11-16 10:02:04,824] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:02:04,877] {logging_mixin.py:115} INFO - [2023-11-16 10:02:04,877] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:02:04,903] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:02:04,923] {logging_mixin.py:115} INFO - [2023-11-16 10:02:04,923] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:02:04,954] {logging_mixin.py:115} INFO - [2023-11-16 10:02:04,954] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:02:04,975] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.157 seconds
[2023-11-16 10:02:32,797] {processor.py:153} INFO - Started process (PID=9122) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:02:32,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:02:32,800] {logging_mixin.py:115} INFO - [2023-11-16 10:02:32,799] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:02:32,901] {logging_mixin.py:115} INFO - [2023-11-16 10:02:32,900] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:02:32,928] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:02:33,047] {logging_mixin.py:115} INFO - [2023-11-16 10:02:33,046] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:02:33,083] {logging_mixin.py:115} INFO - [2023-11-16 10:02:33,083] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:02:33,114] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.321 seconds
[2023-11-16 10:03:03,422] {processor.py:153} INFO - Started process (PID=9180) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:03:03,423] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:03:03,424] {logging_mixin.py:115} INFO - [2023-11-16 10:03:03,423] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:03:03,473] {logging_mixin.py:115} INFO - [2023-11-16 10:03:03,473] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:03:03,502] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:03:03,578] {logging_mixin.py:115} INFO - [2023-11-16 10:03:03,578] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:03:03,590] {logging_mixin.py:115} INFO - [2023-11-16 10:03:03,590] {dag.py:2439} INFO - Creating ORM DAG for etl_hh
[2023-11-16 10:03:03,611] {logging_mixin.py:115} INFO - [2023-11-16 10:03:03,611] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:03:03,635] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.217 seconds
[2023-11-16 10:03:33,780] {processor.py:153} INFO - Started process (PID=9248) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:03:33,782] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:03:33,783] {logging_mixin.py:115} INFO - [2023-11-16 10:03:33,783] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:03:33,835] {logging_mixin.py:115} INFO - [2023-11-16 10:03:33,835] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:03:33,861] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:03:33,882] {logging_mixin.py:115} INFO - [2023-11-16 10:03:33,882] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:03:33,916] {logging_mixin.py:115} INFO - [2023-11-16 10:03:33,915] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:03:33,937] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.160 seconds
[2023-11-16 10:04:04,711] {processor.py:153} INFO - Started process (PID=9306) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:04:04,712] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:04:04,713] {logging_mixin.py:115} INFO - [2023-11-16 10:04:04,712] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:04:04,754] {logging_mixin.py:115} INFO - [2023-11-16 10:04:04,754] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:04:04,779] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:04:04,796] {logging_mixin.py:115} INFO - [2023-11-16 10:04:04,796] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:04:04,823] {logging_mixin.py:115} INFO - [2023-11-16 10:04:04,823] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:04:04,841] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.134 seconds
[2023-11-16 10:04:35,249] {processor.py:153} INFO - Started process (PID=9373) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:04:35,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:04:35,251] {logging_mixin.py:115} INFO - [2023-11-16 10:04:35,251] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:04:35,305] {logging_mixin.py:115} INFO - [2023-11-16 10:04:35,305] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:04:35,337] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:04:35,362] {logging_mixin.py:115} INFO - [2023-11-16 10:04:35,362] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:04:35,400] {logging_mixin.py:115} INFO - [2023-11-16 10:04:35,400] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:04:35,425] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.179 seconds
[2023-11-16 10:05:05,685] {processor.py:153} INFO - Started process (PID=9431) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:05:05,686] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:05:05,687] {logging_mixin.py:115} INFO - [2023-11-16 10:05:05,687] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:05:05,745] {logging_mixin.py:115} INFO - [2023-11-16 10:05:05,745] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:05:05,774] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:05:05,799] {logging_mixin.py:115} INFO - [2023-11-16 10:05:05,799] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:05:05,836] {logging_mixin.py:115} INFO - [2023-11-16 10:05:05,836] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:05:05,867] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.186 seconds
[2023-11-16 10:05:36,552] {processor.py:153} INFO - Started process (PID=9498) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:05:36,554] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:05:36,555] {logging_mixin.py:115} INFO - [2023-11-16 10:05:36,555] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:05:36,609] {logging_mixin.py:115} INFO - [2023-11-16 10:05:36,609] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:05:36,635] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:05:36,657] {logging_mixin.py:115} INFO - [2023-11-16 10:05:36,657] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:05:36,689] {logging_mixin.py:115} INFO - [2023-11-16 10:05:36,689] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:05:36,712] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 10:06:07,256] {processor.py:153} INFO - Started process (PID=9565) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:06:07,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:06:07,258] {logging_mixin.py:115} INFO - [2023-11-16 10:06:07,258] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:06:07,319] {logging_mixin.py:115} INFO - [2023-11-16 10:06:07,319] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:06:07,346] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:06:07,369] {logging_mixin.py:115} INFO - [2023-11-16 10:06:07,369] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:06:07,405] {logging_mixin.py:115} INFO - [2023-11-16 10:06:07,405] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:06:07,428] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.176 seconds
[2023-11-16 10:06:37,586] {processor.py:153} INFO - Started process (PID=9623) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:06:37,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:06:37,589] {logging_mixin.py:115} INFO - [2023-11-16 10:06:37,589] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:06:37,662] {logging_mixin.py:115} INFO - [2023-11-16 10:06:37,662] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:06:37,690] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:06:37,713] {logging_mixin.py:115} INFO - [2023-11-16 10:06:37,713] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:06:37,755] {logging_mixin.py:115} INFO - [2023-11-16 10:06:37,755] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:06:37,780] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.197 seconds
[2023-11-16 10:07:07,881] {processor.py:153} INFO - Started process (PID=9690) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:07:07,883] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:07:07,884] {logging_mixin.py:115} INFO - [2023-11-16 10:07:07,884] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:07:07,946] {logging_mixin.py:115} INFO - [2023-11-16 10:07:07,945] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:07:07,978] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:07:08,013] {logging_mixin.py:115} INFO - [2023-11-16 10:07:08,013] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:07:08,045] {logging_mixin.py:115} INFO - [2023-11-16 10:07:08,045] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:07:08,066] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.190 seconds
[2023-11-16 10:07:38,155] {processor.py:153} INFO - Started process (PID=9748) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:07:38,156] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:07:38,157] {logging_mixin.py:115} INFO - [2023-11-16 10:07:38,157] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:07:38,209] {logging_mixin.py:115} INFO - [2023-11-16 10:07:38,208] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:07:38,235] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:07:38,255] {logging_mixin.py:115} INFO - [2023-11-16 10:07:38,255] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:07:38,291] {logging_mixin.py:115} INFO - [2023-11-16 10:07:38,291] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:07:38,312] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 10:08:08,449] {processor.py:153} INFO - Started process (PID=9815) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:08:08,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:08:08,451] {logging_mixin.py:115} INFO - [2023-11-16 10:08:08,451] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:08:08,501] {logging_mixin.py:115} INFO - [2023-11-16 10:08:08,501] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:08:08,527] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:08:08,547] {logging_mixin.py:115} INFO - [2023-11-16 10:08:08,547] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:08:08,593] {logging_mixin.py:115} INFO - [2023-11-16 10:08:08,593] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:08:08,616] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.170 seconds
[2023-11-16 10:08:38,919] {processor.py:153} INFO - Started process (PID=9873) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:08:38,920] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:08:38,922] {logging_mixin.py:115} INFO - [2023-11-16 10:08:38,922] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:08:38,978] {logging_mixin.py:115} INFO - [2023-11-16 10:08:38,978] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:08:39,008] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:08:39,037] {logging_mixin.py:115} INFO - [2023-11-16 10:08:39,036] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:08:39,081] {logging_mixin.py:115} INFO - [2023-11-16 10:08:39,081] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:08:39,106] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.191 seconds
[2023-11-16 10:09:00,448] {processor.py:153} INFO - Started process (PID=9928) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:09:00,449] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:09:00,451] {logging_mixin.py:115} INFO - [2023-11-16 10:09:00,451] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:09:00,535] {logging_mixin.py:115} INFO - [2023-11-16 10:09:00,534] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:09:00,568] {logging_mixin.py:115} INFO - [2023-11-16 10:09:00,560] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 133, in <module>
    t_start>>task1
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 10:09:00,569] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:09:00,588] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.144 seconds
[2023-11-16 10:09:30,686] {processor.py:153} INFO - Started process (PID=9986) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:09:30,687] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:09:30,688] {logging_mixin.py:115} INFO - [2023-11-16 10:09:30,688] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:09:30,740] {logging_mixin.py:115} INFO - [2023-11-16 10:09:30,740] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:09:30,770] {logging_mixin.py:115} INFO - [2023-11-16 10:09:30,764] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 133, in <module>
    t_start>>task1
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 10:09:30,771] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:09:30,788] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.107 seconds
[2023-11-16 10:10:01,453] {processor.py:153} INFO - Started process (PID=10053) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:10:01,455] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:10:01,456] {logging_mixin.py:115} INFO - [2023-11-16 10:10:01,456] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:10:01,511] {logging_mixin.py:115} INFO - [2023-11-16 10:10:01,511] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:10:01,551] {logging_mixin.py:115} INFO - [2023-11-16 10:10:01,541] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 133, in <module>
    t_start>>task1
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 10:10:01,552] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:10:01,576] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.128 seconds
[2023-11-16 10:10:31,723] {processor.py:153} INFO - Started process (PID=10111) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:10:31,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:10:31,725] {logging_mixin.py:115} INFO - [2023-11-16 10:10:31,725] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:10:31,795] {logging_mixin.py:115} INFO - [2023-11-16 10:10:31,795] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:10:31,830] {logging_mixin.py:115} INFO - [2023-11-16 10:10:31,822] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 133, in <module>
    t_start>>task1
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 10:10:31,831] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:10:31,849] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.130 seconds
[2023-11-16 10:11:02,804] {processor.py:153} INFO - Started process (PID=10178) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:11:02,805] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:11:02,807] {logging_mixin.py:115} INFO - [2023-11-16 10:11:02,807] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:11:02,904] {logging_mixin.py:115} INFO - [2023-11-16 10:11:02,903] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:11:02,951] {logging_mixin.py:115} INFO - [2023-11-16 10:11:02,935] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 133, in <module>
    t_start>>task1
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 10:11:02,952] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:11:02,983] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.185 seconds
[2023-11-16 10:11:33,111] {processor.py:153} INFO - Started process (PID=10236) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:11:33,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:11:33,113] {logging_mixin.py:115} INFO - [2023-11-16 10:11:33,113] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:11:33,181] {logging_mixin.py:115} INFO - [2023-11-16 10:11:33,180] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:11:33,219] {logging_mixin.py:115} INFO - [2023-11-16 10:11:33,210] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 133, in <module>
    t_start>>task1
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 10:11:33,220] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:11:33,246] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.139 seconds
[2023-11-16 10:12:03,441] {processor.py:153} INFO - Started process (PID=10303) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:03,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:12:03,444] {logging_mixin.py:115} INFO - [2023-11-16 10:12:03,444] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:03,517] {logging_mixin.py:115} INFO - [2023-11-16 10:12:03,517] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:12:03,554] {logging_mixin.py:115} INFO - [2023-11-16 10:12:03,545] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 133, in <module>
    t_start>>task1
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2171, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2023-11-16 10:12:03,555] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:03,575] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.139 seconds
[2023-11-16 10:12:21,444] {processor.py:153} INFO - Started process (PID=10326) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:21,445] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:12:21,447] {logging_mixin.py:115} INFO - [2023-11-16 10:12:21,446] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:21,527] {logging_mixin.py:115} INFO - [2023-11-16 10:12:21,527] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:12:21,553] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:21,574] {logging_mixin.py:115} INFO - [2023-11-16 10:12:21,574] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:12:21,613] {logging_mixin.py:115} INFO - [2023-11-16 10:12:21,612] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:12:21,646] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.206 seconds
[2023-11-16 10:12:39,226] {processor.py:153} INFO - Started process (PID=10372) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:39,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:12:39,228] {logging_mixin.py:115} INFO - [2023-11-16 10:12:39,228] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:39,315] {logging_mixin.py:115} INFO - [2023-11-16 10:12:39,315] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:12:39,342] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:12:39,366] {logging_mixin.py:115} INFO - [2023-11-16 10:12:39,366] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:12:39,403] {logging_mixin.py:115} INFO - [2023-11-16 10:12:39,403] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:12:39,434] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.212 seconds
[2023-11-16 10:13:09,658] {processor.py:153} INFO - Started process (PID=10430) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:13:09,659] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:13:09,661] {logging_mixin.py:115} INFO - [2023-11-16 10:13:09,661] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:13:09,739] {logging_mixin.py:115} INFO - [2023-11-16 10:13:09,738] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:13:09,769] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:13:09,891] {logging_mixin.py:115} INFO - [2023-11-16 10:13:09,891] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:13:09,909] {logging_mixin.py:115} INFO - [2023-11-16 10:13:09,909] {dag.py:2439} INFO - Creating ORM DAG for etl_hh
[2023-11-16 10:13:09,939] {logging_mixin.py:115} INFO - [2023-11-16 10:13:09,939] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:13:09,980] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.329 seconds
[2023-11-16 10:13:40,330] {processor.py:153} INFO - Started process (PID=10497) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:13:40,331] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:13:40,331] {logging_mixin.py:115} INFO - [2023-11-16 10:13:40,331] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:13:40,375] {logging_mixin.py:115} INFO - [2023-11-16 10:13:40,375] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:13:40,398] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:13:40,419] {logging_mixin.py:115} INFO - [2023-11-16 10:13:40,419] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:13:40,451] {logging_mixin.py:115} INFO - [2023-11-16 10:13:40,451] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:13:40,472] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.145 seconds
[2023-11-16 10:14:10,820] {processor.py:153} INFO - Started process (PID=10555) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:14:10,821] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:14:10,822] {logging_mixin.py:115} INFO - [2023-11-16 10:14:10,822] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:14:10,869] {logging_mixin.py:115} INFO - [2023-11-16 10:14:10,869] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:14:10,907] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:14:10,930] {logging_mixin.py:115} INFO - [2023-11-16 10:14:10,930] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:14:10,963] {logging_mixin.py:115} INFO - [2023-11-16 10:14:10,963] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:14:10,982] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 10:14:41,246] {processor.py:153} INFO - Started process (PID=10622) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:14:41,247] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:14:41,248] {logging_mixin.py:115} INFO - [2023-11-16 10:14:41,248] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:14:41,294] {logging_mixin.py:115} INFO - [2023-11-16 10:14:41,294] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:14:41,317] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:14:41,333] {logging_mixin.py:115} INFO - [2023-11-16 10:14:41,333] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:14:41,359] {logging_mixin.py:115} INFO - [2023-11-16 10:14:41,359] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:14:41,379] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.136 seconds
[2023-11-16 10:15:11,584] {processor.py:153} INFO - Started process (PID=10680) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:15:11,585] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:15:11,586] {logging_mixin.py:115} INFO - [2023-11-16 10:15:11,586] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:15:11,638] {logging_mixin.py:115} INFO - [2023-11-16 10:15:11,638] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:15:11,662] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:15:11,681] {logging_mixin.py:115} INFO - [2023-11-16 10:15:11,681] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:15:11,713] {logging_mixin.py:115} INFO - [2023-11-16 10:15:11,713] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:15:11,732] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.152 seconds
[2023-11-16 10:15:42,319] {processor.py:153} INFO - Started process (PID=10747) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:15:42,321] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:15:42,322] {logging_mixin.py:115} INFO - [2023-11-16 10:15:42,321] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:15:42,366] {logging_mixin.py:115} INFO - [2023-11-16 10:15:42,366] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:15:42,393] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:15:42,417] {logging_mixin.py:115} INFO - [2023-11-16 10:15:42,417] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:15:42,468] {logging_mixin.py:115} INFO - [2023-11-16 10:15:42,468] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:15:42,492] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.176 seconds
[2023-11-16 10:16:12,846] {processor.py:153} INFO - Started process (PID=10814) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:16:12,848] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:16:12,849] {logging_mixin.py:115} INFO - [2023-11-16 10:16:12,849] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:16:12,909] {logging_mixin.py:115} INFO - [2023-11-16 10:16:12,908] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:16:12,937] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:16:12,959] {logging_mixin.py:115} INFO - [2023-11-16 10:16:12,959] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:16:13,002] {logging_mixin.py:115} INFO - [2023-11-16 10:16:13,002] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:16:13,025] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.182 seconds
[2023-11-16 10:16:43,147] {processor.py:153} INFO - Started process (PID=10872) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:16:43,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:16:43,149] {logging_mixin.py:115} INFO - [2023-11-16 10:16:43,149] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:16:43,200] {logging_mixin.py:115} INFO - [2023-11-16 10:16:43,200] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:16:43,226] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:16:43,247] {logging_mixin.py:115} INFO - [2023-11-16 10:16:43,247] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:16:43,284] {logging_mixin.py:115} INFO - [2023-11-16 10:16:43,284] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:16:43,305] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.162 seconds
[2023-11-16 10:17:13,665] {processor.py:153} INFO - Started process (PID=10939) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:17:13,667] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:17:13,668] {logging_mixin.py:115} INFO - [2023-11-16 10:17:13,668] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:17:13,738] {logging_mixin.py:115} INFO - [2023-11-16 10:17:13,738] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:17:13,764] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:17:13,787] {logging_mixin.py:115} INFO - [2023-11-16 10:17:13,787] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:17:13,823] {logging_mixin.py:115} INFO - [2023-11-16 10:17:13,823] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:17:13,844] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 10:17:44,092] {processor.py:153} INFO - Started process (PID=10997) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:17:44,093] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:17:44,095] {logging_mixin.py:115} INFO - [2023-11-16 10:17:44,095] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:17:44,139] {logging_mixin.py:115} INFO - [2023-11-16 10:17:44,139] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:17:44,163] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:17:44,182] {logging_mixin.py:115} INFO - [2023-11-16 10:17:44,182] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:17:44,212] {logging_mixin.py:115} INFO - [2023-11-16 10:17:44,212] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:17:44,244] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.155 seconds
[2023-11-16 10:18:14,438] {processor.py:153} INFO - Started process (PID=11064) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:18:14,441] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:18:14,443] {logging_mixin.py:115} INFO - [2023-11-16 10:18:14,443] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:18:14,511] {logging_mixin.py:115} INFO - [2023-11-16 10:18:14,510] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:18:14,539] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:18:14,565] {logging_mixin.py:115} INFO - [2023-11-16 10:18:14,565] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:18:14,611] {logging_mixin.py:115} INFO - [2023-11-16 10:18:14,611] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:18:14,635] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.203 seconds
[2023-11-16 10:18:45,199] {processor.py:153} INFO - Started process (PID=11122) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:18:45,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:18:45,202] {logging_mixin.py:115} INFO - [2023-11-16 10:18:45,202] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:18:45,262] {logging_mixin.py:115} INFO - [2023-11-16 10:18:45,262] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:18:45,290] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:18:45,311] {logging_mixin.py:115} INFO - [2023-11-16 10:18:45,311] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:18:45,352] {logging_mixin.py:115} INFO - [2023-11-16 10:18:45,351] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:18:45,373] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.178 seconds
[2023-11-16 10:19:15,691] {processor.py:153} INFO - Started process (PID=11189) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:19:15,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:19:15,693] {logging_mixin.py:115} INFO - [2023-11-16 10:19:15,693] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:19:15,742] {logging_mixin.py:115} INFO - [2023-11-16 10:19:15,742] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:19:15,768] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:19:15,792] {logging_mixin.py:115} INFO - [2023-11-16 10:19:15,792] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:19:15,824] {logging_mixin.py:115} INFO - [2023-11-16 10:19:15,824] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:19:15,843] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 10:19:46,027] {processor.py:153} INFO - Started process (PID=11247) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:19:46,028] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:19:46,029] {logging_mixin.py:115} INFO - [2023-11-16 10:19:46,029] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:19:46,088] {logging_mixin.py:115} INFO - [2023-11-16 10:19:46,088] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:19:46,115] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:19:46,135] {logging_mixin.py:115} INFO - [2023-11-16 10:19:46,135] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:19:46,188] {logging_mixin.py:115} INFO - [2023-11-16 10:19:46,187] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:19:46,210] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.186 seconds
[2023-11-16 10:20:16,513] {processor.py:153} INFO - Started process (PID=11314) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:20:16,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:20:16,515] {logging_mixin.py:115} INFO - [2023-11-16 10:20:16,515] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:20:16,580] {logging_mixin.py:115} INFO - [2023-11-16 10:20:16,580] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:20:16,609] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:20:16,635] {logging_mixin.py:115} INFO - [2023-11-16 10:20:16,634] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:20:16,674] {logging_mixin.py:115} INFO - [2023-11-16 10:20:16,674] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:20:16,700] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.191 seconds
[2023-11-16 10:20:46,762] {processor.py:153} INFO - Started process (PID=11372) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:20:46,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:20:46,764] {logging_mixin.py:115} INFO - [2023-11-16 10:20:46,764] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:20:46,808] {logging_mixin.py:115} INFO - [2023-11-16 10:20:46,808] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:20:46,833] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:20:46,862] {logging_mixin.py:115} INFO - [2023-11-16 10:20:46,862] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:20:46,902] {logging_mixin.py:115} INFO - [2023-11-16 10:20:46,902] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:20:46,928] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.170 seconds
[2023-11-16 10:21:17,037] {processor.py:153} INFO - Started process (PID=11439) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:21:17,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:21:17,039] {logging_mixin.py:115} INFO - [2023-11-16 10:21:17,039] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:21:17,091] {logging_mixin.py:115} INFO - [2023-11-16 10:21:17,091] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:21:17,114] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:21:17,134] {logging_mixin.py:115} INFO - [2023-11-16 10:21:17,134] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:21:17,167] {logging_mixin.py:115} INFO - [2023-11-16 10:21:17,166] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:21:17,185] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.151 seconds
[2023-11-16 10:21:47,252] {processor.py:153} INFO - Started process (PID=11497) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:21:47,253] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:21:47,254] {logging_mixin.py:115} INFO - [2023-11-16 10:21:47,254] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:21:47,301] {logging_mixin.py:115} INFO - [2023-11-16 10:21:47,301] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:21:47,326] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:21:47,343] {logging_mixin.py:115} INFO - [2023-11-16 10:21:47,343] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:21:47,377] {logging_mixin.py:115} INFO - [2023-11-16 10:21:47,377] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:21:47,395] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.146 seconds
[2023-11-16 10:22:17,565] {processor.py:153} INFO - Started process (PID=11564) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:22:17,566] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:22:17,567] {logging_mixin.py:115} INFO - [2023-11-16 10:22:17,567] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:22:17,622] {logging_mixin.py:115} INFO - [2023-11-16 10:22:17,622] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:22:17,648] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:22:17,677] {logging_mixin.py:115} INFO - [2023-11-16 10:22:17,677] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:22:17,714] {logging_mixin.py:115} INFO - [2023-11-16 10:22:17,714] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:22:17,739] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.178 seconds
[2023-11-16 10:22:47,925] {processor.py:153} INFO - Started process (PID=11622) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:22:47,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:22:47,927] {logging_mixin.py:115} INFO - [2023-11-16 10:22:47,927] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:22:47,982] {logging_mixin.py:115} INFO - [2023-11-16 10:22:47,981] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:22:48,006] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:22:48,034] {logging_mixin.py:115} INFO - [2023-11-16 10:22:48,034] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:22:48,076] {logging_mixin.py:115} INFO - [2023-11-16 10:22:48,076] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:22:48,105] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 10:23:18,176] {processor.py:153} INFO - Started process (PID=11689) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:23:18,177] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:23:18,178] {logging_mixin.py:115} INFO - [2023-11-16 10:23:18,178] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:23:18,235] {logging_mixin.py:115} INFO - [2023-11-16 10:23:18,235] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:23:18,262] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:23:18,284] {logging_mixin.py:115} INFO - [2023-11-16 10:23:18,284] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:23:18,331] {logging_mixin.py:115} INFO - [2023-11-16 10:23:18,331] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:23:18,357] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.184 seconds
[2023-11-16 10:23:49,029] {processor.py:153} INFO - Started process (PID=11747) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:23:49,031] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:23:49,032] {logging_mixin.py:115} INFO - [2023-11-16 10:23:49,032] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:23:49,081] {logging_mixin.py:115} INFO - [2023-11-16 10:23:49,081] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:23:49,106] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:23:49,127] {logging_mixin.py:115} INFO - [2023-11-16 10:23:49,127] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:23:49,175] {logging_mixin.py:115} INFO - [2023-11-16 10:23:49,175] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:23:49,205] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.179 seconds
[2023-11-16 10:24:19,440] {processor.py:153} INFO - Started process (PID=11814) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:24:19,442] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:24:19,443] {logging_mixin.py:115} INFO - [2023-11-16 10:24:19,443] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:24:19,507] {logging_mixin.py:115} INFO - [2023-11-16 10:24:19,507] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:24:19,534] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:24:19,567] {logging_mixin.py:115} INFO - [2023-11-16 10:24:19,567] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:24:19,614] {logging_mixin.py:115} INFO - [2023-11-16 10:24:19,614] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:24:19,638] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.201 seconds
[2023-11-16 10:24:50,143] {processor.py:153} INFO - Started process (PID=11881) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:24:50,145] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:24:50,147] {logging_mixin.py:115} INFO - [2023-11-16 10:24:50,146] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:24:50,215] {logging_mixin.py:115} INFO - [2023-11-16 10:24:50,215] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:24:50,242] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:24:50,267] {logging_mixin.py:115} INFO - [2023-11-16 10:24:50,267] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:24:50,310] {logging_mixin.py:115} INFO - [2023-11-16 10:24:50,310] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:24:50,330] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.193 seconds
[2023-11-16 10:25:21,023] {processor.py:153} INFO - Started process (PID=11939) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:25:21,025] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:25:21,026] {logging_mixin.py:115} INFO - [2023-11-16 10:25:21,026] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:25:21,091] {logging_mixin.py:115} INFO - [2023-11-16 10:25:21,091] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:25:21,119] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:25:21,158] {logging_mixin.py:115} INFO - [2023-11-16 10:25:21,158] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:25:21,226] {logging_mixin.py:115} INFO - [2023-11-16 10:25:21,223] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:25:21,266] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.247 seconds
[2023-11-16 10:25:51,726] {processor.py:153} INFO - Started process (PID=12006) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:25:51,727] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:25:51,728] {logging_mixin.py:115} INFO - [2023-11-16 10:25:51,727] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:25:51,779] {logging_mixin.py:115} INFO - [2023-11-16 10:25:51,779] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:25:51,805] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:25:51,834] {logging_mixin.py:115} INFO - [2023-11-16 10:25:51,834] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:25:51,873] {logging_mixin.py:115} INFO - [2023-11-16 10:25:51,872] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:25:51,903] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.182 seconds
[2023-11-16 10:26:22,517] {processor.py:153} INFO - Started process (PID=12064) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:22,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:26:22,519] {logging_mixin.py:115} INFO - [2023-11-16 10:26:22,519] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:22,577] {logging_mixin.py:115} INFO - [2023-11-16 10:26:22,576] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:26:22,607] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:22,634] {logging_mixin.py:115} INFO - [2023-11-16 10:26:22,634] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:26:22,691] {logging_mixin.py:115} INFO - [2023-11-16 10:26:22,691] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:26:22,720] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.207 seconds
[2023-11-16 10:26:50,822] {processor.py:153} INFO - Started process (PID=12129) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:50,823] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:26:50,824] {logging_mixin.py:115} INFO - [2023-11-16 10:26:50,824] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:50,920] {logging_mixin.py:115} INFO - [2023-11-16 10:26:50,920] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:26:50,953] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:50,981] {logging_mixin.py:115} INFO - [2023-11-16 10:26:50,981] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:26:51,027] {logging_mixin.py:115} INFO - [2023-11-16 10:26:51,027] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:26:51,056] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.238 seconds
[2023-11-16 10:26:52,999] {processor.py:153} INFO - Started process (PID=12132) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:53,000] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:26:53,001] {logging_mixin.py:115} INFO - [2023-11-16 10:26:53,001] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:53,068] {logging_mixin.py:115} INFO - [2023-11-16 10:26:53,068] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:26:53,092] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:26:53,116] {logging_mixin.py:115} INFO - [2023-11-16 10:26:53,115] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:26:53,153] {logging_mixin.py:115} INFO - [2023-11-16 10:26:53,153] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:26:53,178] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 10:27:23,433] {processor.py:153} INFO - Started process (PID=12190) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:27:23,434] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:27:23,435] {logging_mixin.py:115} INFO - [2023-11-16 10:27:23,434] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:27:23,494] {logging_mixin.py:115} INFO - [2023-11-16 10:27:23,494] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:27:23,520] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:27:23,546] {logging_mixin.py:115} INFO - [2023-11-16 10:27:23,546] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:27:23,586] {logging_mixin.py:115} INFO - [2023-11-16 10:27:23,586] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:27:23,612] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 10:27:32,986] {processor.py:153} INFO - Started process (PID=12205) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:27:32,987] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:27:32,989] {logging_mixin.py:115} INFO - [2023-11-16 10:27:32,989] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:27:33,093] {logging_mixin.py:115} INFO - [2023-11-16 10:27:33,093] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:27:33,118] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:27:33,139] {logging_mixin.py:115} INFO - [2023-11-16 10:27:33,139] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:27:33,170] {logging_mixin.py:115} INFO - [2023-11-16 10:27:33,170] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:27:33,200] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 10:28:03,268] {processor.py:153} INFO - Started process (PID=12263) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:28:03,269] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:28:03,271] {logging_mixin.py:115} INFO - [2023-11-16 10:28:03,271] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:28:03,320] {logging_mixin.py:115} INFO - [2023-11-16 10:28:03,319] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:28:03,344] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:28:03,370] {logging_mixin.py:115} INFO - [2023-11-16 10:28:03,370] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:28:03,400] {logging_mixin.py:115} INFO - [2023-11-16 10:28:03,400] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:28:03,419] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.155 seconds
[2023-11-16 10:28:33,998] {processor.py:153} INFO - Started process (PID=12330) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:28:33,999] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:28:34,000] {logging_mixin.py:115} INFO - [2023-11-16 10:28:34,000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:28:34,059] {logging_mixin.py:115} INFO - [2023-11-16 10:28:34,059] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:28:34,083] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:28:34,103] {logging_mixin.py:115} INFO - [2023-11-16 10:28:34,103] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:28:34,162] {logging_mixin.py:115} INFO - [2023-11-16 10:28:34,161] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:28:34,190] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.196 seconds
[2023-11-16 10:29:04,306] {processor.py:153} INFO - Started process (PID=12389) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:29:04,308] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:29:04,309] {logging_mixin.py:115} INFO - [2023-11-16 10:29:04,309] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:29:04,403] {logging_mixin.py:115} INFO - [2023-11-16 10:29:04,403] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:29:04,445] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:29:04,600] {logging_mixin.py:115} INFO - [2023-11-16 10:29:04,600] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:29:04,617] {logging_mixin.py:115} INFO - [2023-11-16 10:29:04,616] {dag.py:2439} INFO - Creating ORM DAG for etl_hh
[2023-11-16 10:29:04,642] {logging_mixin.py:115} INFO - [2023-11-16 10:29:04,642] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:29:04,672] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.371 seconds
[2023-11-16 10:29:34,741] {processor.py:153} INFO - Started process (PID=12457) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:29:34,742] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:29:34,744] {logging_mixin.py:115} INFO - [2023-11-16 10:29:34,744] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:29:34,811] {logging_mixin.py:115} INFO - [2023-11-16 10:29:34,811] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:29:34,839] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:29:34,860] {logging_mixin.py:115} INFO - [2023-11-16 10:29:34,860] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:29:34,892] {logging_mixin.py:115} INFO - [2023-11-16 10:29:34,891] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:29:34,918] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.180 seconds
[2023-11-16 10:30:05,037] {processor.py:153} INFO - Started process (PID=12515) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:30:05,038] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:30:05,039] {logging_mixin.py:115} INFO - [2023-11-16 10:30:05,039] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:30:05,091] {logging_mixin.py:115} INFO - [2023-11-16 10:30:05,090] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:30:05,118] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:30:05,142] {logging_mixin.py:115} INFO - [2023-11-16 10:30:05,142] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:30:05,179] {logging_mixin.py:115} INFO - [2023-11-16 10:30:05,179] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:30:05,198] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.165 seconds
[2023-11-16 10:30:35,382] {processor.py:153} INFO - Started process (PID=12581) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:30:35,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:30:35,385] {logging_mixin.py:115} INFO - [2023-11-16 10:30:35,385] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:30:35,443] {logging_mixin.py:115} INFO - [2023-11-16 10:30:35,442] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:30:35,467] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:30:35,486] {logging_mixin.py:115} INFO - [2023-11-16 10:30:35,486] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:30:35,514] {logging_mixin.py:115} INFO - [2023-11-16 10:30:35,514] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:30:35,534] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 10:31:05,680] {processor.py:153} INFO - Started process (PID=12639) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:05,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:31:05,681] {logging_mixin.py:115} INFO - [2023-11-16 10:31:05,681] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:05,730] {logging_mixin.py:115} INFO - [2023-11-16 10:31:05,730] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:31:05,754] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:05,777] {logging_mixin.py:115} INFO - [2023-11-16 10:31:05,776] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:31:05,814] {logging_mixin.py:115} INFO - [2023-11-16 10:31:05,814] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:31:05,850] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.174 seconds
[2023-11-16 10:31:10,659] {processor.py:153} INFO - Started process (PID=12654) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:10,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:31:10,661] {logging_mixin.py:115} INFO - [2023-11-16 10:31:10,661] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:10,750] {logging_mixin.py:115} INFO - [2023-11-16 10:31:10,750] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:31:10,775] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:10,797] {logging_mixin.py:115} INFO - [2023-11-16 10:31:10,797] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:31:10,834] {logging_mixin.py:115} INFO - [2023-11-16 10:31:10,833] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:31:10,862] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.207 seconds
[2023-11-16 10:31:40,985] {processor.py:153} INFO - Started process (PID=12712) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:40,986] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:31:40,987] {logging_mixin.py:115} INFO - [2023-11-16 10:31:40,987] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:41,097] {logging_mixin.py:115} INFO - [2023-11-16 10:31:41,097] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:31:41,154] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:31:41,188] {logging_mixin.py:115} INFO - [2023-11-16 10:31:41,188] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:31:41,239] {logging_mixin.py:115} INFO - [2023-11-16 10:31:41,239] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:31:41,267] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.287 seconds
[2023-11-16 10:32:11,396] {processor.py:153} INFO - Started process (PID=12779) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:32:11,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:32:11,400] {logging_mixin.py:115} INFO - [2023-11-16 10:32:11,400] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:32:11,477] {logging_mixin.py:115} INFO - [2023-11-16 10:32:11,476] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:32:11,509] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:32:11,632] {logging_mixin.py:115} INFO - [2023-11-16 10:32:11,632] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:32:11,649] {logging_mixin.py:115} INFO - [2023-11-16 10:32:11,648] {dag.py:2439} INFO - Creating ORM DAG for etl_hh
[2023-11-16 10:32:11,673] {logging_mixin.py:115} INFO - [2023-11-16 10:32:11,673] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:32:11,704] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.315 seconds
[2023-11-16 10:32:41,890] {processor.py:153} INFO - Started process (PID=12837) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:32:41,892] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:32:41,893] {logging_mixin.py:115} INFO - [2023-11-16 10:32:41,893] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:32:41,949] {logging_mixin.py:115} INFO - [2023-11-16 10:32:41,949] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:32:41,981] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:32:42,006] {logging_mixin.py:115} INFO - [2023-11-16 10:32:42,006] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:32:42,043] {logging_mixin.py:115} INFO - [2023-11-16 10:32:42,043] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:32:42,064] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.178 seconds
[2023-11-16 10:33:12,359] {processor.py:153} INFO - Started process (PID=12904) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:33:12,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:33:12,361] {logging_mixin.py:115} INFO - [2023-11-16 10:33:12,361] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:33:12,413] {logging_mixin.py:115} INFO - [2023-11-16 10:33:12,413] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:33:12,438] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:33:12,458] {logging_mixin.py:115} INFO - [2023-11-16 10:33:12,458] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:33:12,487] {logging_mixin.py:115} INFO - [2023-11-16 10:33:12,487] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:33:12,510] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.155 seconds
[2023-11-16 10:33:43,139] {processor.py:153} INFO - Started process (PID=12962) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:33:43,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:33:43,142] {logging_mixin.py:115} INFO - [2023-11-16 10:33:43,141] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:33:43,190] {logging_mixin.py:115} INFO - [2023-11-16 10:33:43,190] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:33:43,216] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:33:43,235] {logging_mixin.py:115} INFO - [2023-11-16 10:33:43,234] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:33:43,268] {logging_mixin.py:115} INFO - [2023-11-16 10:33:43,268] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:33:43,290] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.155 seconds
[2023-11-16 10:34:13,949] {processor.py:153} INFO - Started process (PID=13029) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:34:13,950] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:34:13,951] {logging_mixin.py:115} INFO - [2023-11-16 10:34:13,951] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:34:14,028] {logging_mixin.py:115} INFO - [2023-11-16 10:34:14,028] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:34:14,057] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:34:14,084] {logging_mixin.py:115} INFO - [2023-11-16 10:34:14,084] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:34:14,129] {logging_mixin.py:115} INFO - [2023-11-16 10:34:14,129] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:34:14,155] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.212 seconds
[2023-11-16 10:34:44,475] {processor.py:153} INFO - Started process (PID=13087) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:34:44,476] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:34:44,478] {logging_mixin.py:115} INFO - [2023-11-16 10:34:44,478] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:34:44,542] {logging_mixin.py:115} INFO - [2023-11-16 10:34:44,542] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:34:44,568] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:34:44,597] {logging_mixin.py:115} INFO - [2023-11-16 10:34:44,597] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:34:44,642] {logging_mixin.py:115} INFO - [2023-11-16 10:34:44,642] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:34:44,667] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.198 seconds
[2023-11-16 10:35:14,858] {processor.py:153} INFO - Started process (PID=13155) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:35:14,860] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:35:14,861] {logging_mixin.py:115} INFO - [2023-11-16 10:35:14,861] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:35:14,918] {logging_mixin.py:115} INFO - [2023-11-16 10:35:14,918] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:35:14,945] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:35:14,965] {logging_mixin.py:115} INFO - [2023-11-16 10:35:14,965] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:35:15,004] {logging_mixin.py:115} INFO - [2023-11-16 10:35:15,003] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:35:15,026] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.172 seconds
[2023-11-16 10:35:45,510] {processor.py:153} INFO - Started process (PID=13213) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:35:45,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:35:45,512] {logging_mixin.py:115} INFO - [2023-11-16 10:35:45,512] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:35:45,560] {logging_mixin.py:115} INFO - [2023-11-16 10:35:45,559] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:35:45,584] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:35:45,603] {logging_mixin.py:115} INFO - [2023-11-16 10:35:45,603] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:35:45,632] {logging_mixin.py:115} INFO - [2023-11-16 10:35:45,632] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:35:45,653] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.147 seconds
[2023-11-16 10:36:16,117] {processor.py:153} INFO - Started process (PID=13280) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:36:16,118] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:36:16,119] {logging_mixin.py:115} INFO - [2023-11-16 10:36:16,119] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:36:16,182] {logging_mixin.py:115} INFO - [2023-11-16 10:36:16,181] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:36:16,206] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:36:16,225] {logging_mixin.py:115} INFO - [2023-11-16 10:36:16,224] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:36:16,252] {logging_mixin.py:115} INFO - [2023-11-16 10:36:16,252] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:36:16,271] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.157 seconds
[2023-11-16 10:36:46,573] {processor.py:153} INFO - Started process (PID=13347) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:36:46,574] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:36:46,575] {logging_mixin.py:115} INFO - [2023-11-16 10:36:46,575] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:36:46,624] {logging_mixin.py:115} INFO - [2023-11-16 10:36:46,624] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:36:46,650] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:36:46,669] {logging_mixin.py:115} INFO - [2023-11-16 10:36:46,669] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:36:46,699] {logging_mixin.py:115} INFO - [2023-11-16 10:36:46,699] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:36:46,720] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.151 seconds
[2023-11-16 10:37:17,055] {processor.py:153} INFO - Started process (PID=13405) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:37:17,056] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:37:17,058] {logging_mixin.py:115} INFO - [2023-11-16 10:37:17,057] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:37:17,110] {logging_mixin.py:115} INFO - [2023-11-16 10:37:17,110] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:37:17,140] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:37:17,164] {logging_mixin.py:115} INFO - [2023-11-16 10:37:17,164] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:37:17,199] {logging_mixin.py:115} INFO - [2023-11-16 10:37:17,199] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:37:17,226] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.177 seconds
[2023-11-16 10:37:47,302] {processor.py:153} INFO - Started process (PID=13472) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:37:47,303] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:37:47,304] {logging_mixin.py:115} INFO - [2023-11-16 10:37:47,304] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:37:47,362] {logging_mixin.py:115} INFO - [2023-11-16 10:37:47,362] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:37:47,390] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:37:47,412] {logging_mixin.py:115} INFO - [2023-11-16 10:37:47,412] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:37:47,445] {logging_mixin.py:115} INFO - [2023-11-16 10:37:47,445] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:37:47,481] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.184 seconds
[2023-11-16 10:38:17,587] {processor.py:153} INFO - Started process (PID=13530) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:38:17,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:38:17,590] {logging_mixin.py:115} INFO - [2023-11-16 10:38:17,590] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:38:17,650] {logging_mixin.py:115} INFO - [2023-11-16 10:38:17,650] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:38:17,676] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:38:17,703] {logging_mixin.py:115} INFO - [2023-11-16 10:38:17,703] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:38:17,736] {logging_mixin.py:115} INFO - [2023-11-16 10:38:17,735] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:38:17,758] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.177 seconds
[2023-11-16 10:38:48,115] {processor.py:153} INFO - Started process (PID=13597) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:38:48,116] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:38:48,118] {logging_mixin.py:115} INFO - [2023-11-16 10:38:48,118] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:38:48,171] {logging_mixin.py:115} INFO - [2023-11-16 10:38:48,171] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:38:48,197] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:38:48,217] {logging_mixin.py:115} INFO - [2023-11-16 10:38:48,217] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:38:48,249] {logging_mixin.py:115} INFO - [2023-11-16 10:38:48,248] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:38:48,271] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 10:39:18,472] {processor.py:153} INFO - Started process (PID=13655) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:39:18,473] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:39:18,474] {logging_mixin.py:115} INFO - [2023-11-16 10:39:18,474] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:39:18,570] {logging_mixin.py:115} INFO - [2023-11-16 10:39:18,570] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:39:18,596] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:39:18,618] {logging_mixin.py:115} INFO - [2023-11-16 10:39:18,618] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:39:18,662] {logging_mixin.py:115} INFO - [2023-11-16 10:39:18,662] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:39:18,688] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.221 seconds
[2023-11-16 10:39:48,734] {processor.py:153} INFO - Started process (PID=13722) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:39:48,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:39:48,736] {logging_mixin.py:115} INFO - [2023-11-16 10:39:48,736] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:39:48,790] {logging_mixin.py:115} INFO - [2023-11-16 10:39:48,790] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:39:48,819] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:39:48,842] {logging_mixin.py:115} INFO - [2023-11-16 10:39:48,842] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:39:48,880] {logging_mixin.py:115} INFO - [2023-11-16 10:39:48,880] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:39:48,903] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.173 seconds
[2023-11-16 10:40:19,274] {processor.py:153} INFO - Started process (PID=13780) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:40:19,275] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:40:19,276] {logging_mixin.py:115} INFO - [2023-11-16 10:40:19,276] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:40:19,347] {logging_mixin.py:115} INFO - [2023-11-16 10:40:19,347] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:40:19,377] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:40:19,400] {logging_mixin.py:115} INFO - [2023-11-16 10:40:19,400] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:40:19,437] {logging_mixin.py:115} INFO - [2023-11-16 10:40:19,437] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:40:19,463] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.194 seconds
[2023-11-16 10:40:50,124] {processor.py:153} INFO - Started process (PID=13847) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:40:50,125] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:40:50,127] {logging_mixin.py:115} INFO - [2023-11-16 10:40:50,127] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:40:50,187] {logging_mixin.py:115} INFO - [2023-11-16 10:40:50,187] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:40:50,213] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:40:50,236] {logging_mixin.py:115} INFO - [2023-11-16 10:40:50,236] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:40:50,280] {logging_mixin.py:115} INFO - [2023-11-16 10:40:50,280] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:40:50,312] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.191 seconds
[2023-11-16 10:41:21,113] {processor.py:153} INFO - Started process (PID=13905) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:41:21,114] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:41:21,115] {logging_mixin.py:115} INFO - [2023-11-16 10:41:21,115] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:41:21,166] {logging_mixin.py:115} INFO - [2023-11-16 10:41:21,166] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:41:21,192] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:41:21,217] {logging_mixin.py:115} INFO - [2023-11-16 10:41:21,217] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:41:21,251] {logging_mixin.py:115} INFO - [2023-11-16 10:41:21,251] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:41:21,273] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 10:41:51,670] {processor.py:153} INFO - Started process (PID=13972) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:41:51,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:41:51,673] {logging_mixin.py:115} INFO - [2023-11-16 10:41:51,673] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:41:51,735] {logging_mixin.py:115} INFO - [2023-11-16 10:41:51,735] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:41:51,765] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:41:51,790] {logging_mixin.py:115} INFO - [2023-11-16 10:41:51,789] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:41:51,830] {logging_mixin.py:115} INFO - [2023-11-16 10:41:51,830] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:41:51,856] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.192 seconds
[2023-11-16 10:42:22,282] {processor.py:153} INFO - Started process (PID=14039) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:42:22,283] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:42:22,285] {logging_mixin.py:115} INFO - [2023-11-16 10:42:22,284] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:42:22,354] {logging_mixin.py:115} INFO - [2023-11-16 10:42:22,354] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:42:22,381] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:42:22,404] {logging_mixin.py:115} INFO - [2023-11-16 10:42:22,403] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:42:22,439] {logging_mixin.py:115} INFO - [2023-11-16 10:42:22,439] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:42:22,461] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.185 seconds
[2023-11-16 10:42:52,630] {processor.py:153} INFO - Started process (PID=14097) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:42:52,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:42:52,633] {logging_mixin.py:115} INFO - [2023-11-16 10:42:52,633] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:42:52,694] {logging_mixin.py:115} INFO - [2023-11-16 10:42:52,693] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:42:52,720] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:42:52,741] {logging_mixin.py:115} INFO - [2023-11-16 10:42:52,740] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:42:52,774] {logging_mixin.py:115} INFO - [2023-11-16 10:42:52,774] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:42:52,796] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.171 seconds
[2023-11-16 10:43:22,956] {processor.py:153} INFO - Started process (PID=14164) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:43:22,957] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:43:22,959] {logging_mixin.py:115} INFO - [2023-11-16 10:43:22,958] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:43:23,027] {logging_mixin.py:115} INFO - [2023-11-16 10:43:23,027] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:43:23,055] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:43:23,081] {logging_mixin.py:115} INFO - [2023-11-16 10:43:23,081] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:43:23,118] {logging_mixin.py:115} INFO - [2023-11-16 10:43:23,118] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:43:23,141] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.191 seconds
[2023-11-16 10:43:53,272] {processor.py:153} INFO - Started process (PID=14222) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:43:53,274] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:43:53,275] {logging_mixin.py:115} INFO - [2023-11-16 10:43:53,275] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:43:53,330] {logging_mixin.py:115} INFO - [2023-11-16 10:43:53,330] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:43:53,357] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:43:53,387] {logging_mixin.py:115} INFO - [2023-11-16 10:43:53,387] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:43:53,420] {logging_mixin.py:115} INFO - [2023-11-16 10:43:53,420] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:43:53,443] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.176 seconds
[2023-11-16 10:44:23,613] {processor.py:153} INFO - Started process (PID=14289) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:44:23,614] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:44:23,615] {logging_mixin.py:115} INFO - [2023-11-16 10:44:23,615] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:44:23,665] {logging_mixin.py:115} INFO - [2023-11-16 10:44:23,665] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:44:23,689] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:44:23,707] {logging_mixin.py:115} INFO - [2023-11-16 10:44:23,707] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:44:23,735] {logging_mixin.py:115} INFO - [2023-11-16 10:44:23,735] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:44:23,761] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.151 seconds
[2023-11-16 10:44:54,077] {processor.py:153} INFO - Started process (PID=14347) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:44:54,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:44:54,080] {logging_mixin.py:115} INFO - [2023-11-16 10:44:54,080] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:44:54,166] {logging_mixin.py:115} INFO - [2023-11-16 10:44:54,166] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:44:54,199] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:44:54,247] {logging_mixin.py:115} INFO - [2023-11-16 10:44:54,247] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:44:54,288] {logging_mixin.py:115} INFO - [2023-11-16 10:44:54,287] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:44:54,310] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.239 seconds
[2023-11-16 10:45:24,451] {processor.py:153} INFO - Started process (PID=14416) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:45:24,452] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:45:24,453] {logging_mixin.py:115} INFO - [2023-11-16 10:45:24,453] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:45:24,507] {logging_mixin.py:115} INFO - [2023-11-16 10:45:24,507] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:45:24,533] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:45:24,559] {logging_mixin.py:115} INFO - [2023-11-16 10:45:24,558] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:45:24,593] {logging_mixin.py:115} INFO - [2023-11-16 10:45:24,593] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:45:24,613] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.165 seconds
[2023-11-16 10:45:54,738] {processor.py:153} INFO - Started process (PID=14474) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:45:54,739] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:45:54,740] {logging_mixin.py:115} INFO - [2023-11-16 10:45:54,740] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:45:54,792] {logging_mixin.py:115} INFO - [2023-11-16 10:45:54,792] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:45:54,817] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:45:54,837] {logging_mixin.py:115} INFO - [2023-11-16 10:45:54,837] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:45:54,866] {logging_mixin.py:115} INFO - [2023-11-16 10:45:54,866] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:45:54,884] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.151 seconds
[2023-11-16 10:46:25,151] {processor.py:153} INFO - Started process (PID=14540) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:46:25,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:46:25,155] {logging_mixin.py:115} INFO - [2023-11-16 10:46:25,155] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:46:25,240] {logging_mixin.py:115} INFO - [2023-11-16 10:46:25,239] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:46:25,272] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:46:25,304] {logging_mixin.py:115} INFO - [2023-11-16 10:46:25,304] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:46:25,349] {logging_mixin.py:115} INFO - [2023-11-16 10:46:25,349] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:46:25,372] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.226 seconds
[2023-11-16 10:46:55,585] {processor.py:153} INFO - Started process (PID=14599) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:46:55,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:46:55,587] {logging_mixin.py:115} INFO - [2023-11-16 10:46:55,586] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:46:55,628] {logging_mixin.py:115} INFO - [2023-11-16 10:46:55,628] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:46:55,654] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:46:55,673] {logging_mixin.py:115} INFO - [2023-11-16 10:46:55,672] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:46:55,704] {logging_mixin.py:115} INFO - [2023-11-16 10:46:55,704] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:46:55,723] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.142 seconds
[2023-11-16 10:47:26,135] {processor.py:153} INFO - Started process (PID=14666) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:47:26,137] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:47:26,140] {logging_mixin.py:115} INFO - [2023-11-16 10:47:26,139] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:47:26,206] {logging_mixin.py:115} INFO - [2023-11-16 10:47:26,206] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:47:26,236] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:47:26,261] {logging_mixin.py:115} INFO - [2023-11-16 10:47:26,261] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:47:26,305] {logging_mixin.py:115} INFO - [2023-11-16 10:47:26,305] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:47:26,330] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.207 seconds
[2023-11-16 10:47:56,842] {processor.py:153} INFO - Started process (PID=14724) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:47:56,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:47:56,845] {logging_mixin.py:115} INFO - [2023-11-16 10:47:56,845] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:47:56,910] {logging_mixin.py:115} INFO - [2023-11-16 10:47:56,910] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:47:56,942] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:47:56,974] {logging_mixin.py:115} INFO - [2023-11-16 10:47:56,974] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:47:57,012] {logging_mixin.py:115} INFO - [2023-11-16 10:47:57,011] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:47:57,033] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.195 seconds
[2023-11-16 10:48:27,463] {processor.py:153} INFO - Started process (PID=14791) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:48:27,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:48:27,466] {logging_mixin.py:115} INFO - [2023-11-16 10:48:27,466] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:48:27,530] {logging_mixin.py:115} INFO - [2023-11-16 10:48:27,530] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:48:27,557] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:48:27,582] {logging_mixin.py:115} INFO - [2023-11-16 10:48:27,582] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:48:27,618] {logging_mixin.py:115} INFO - [2023-11-16 10:48:27,618] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:48:27,642] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 10:48:58,083] {processor.py:153} INFO - Started process (PID=14849) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:48:58,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:48:58,088] {logging_mixin.py:115} INFO - [2023-11-16 10:48:58,087] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:48:58,213] {logging_mixin.py:115} INFO - [2023-11-16 10:48:58,213] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:48:58,269] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:48:58,319] {logging_mixin.py:115} INFO - [2023-11-16 10:48:58,319] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:48:58,391] {logging_mixin.py:115} INFO - [2023-11-16 10:48:58,391] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:48:58,426] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.350 seconds
[2023-11-16 10:49:29,188] {processor.py:153} INFO - Started process (PID=14916) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:49:29,189] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:49:29,191] {logging_mixin.py:115} INFO - [2023-11-16 10:49:29,190] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:49:29,251] {logging_mixin.py:115} INFO - [2023-11-16 10:49:29,251] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:49:29,284] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:49:29,336] {logging_mixin.py:115} INFO - [2023-11-16 10:49:29,336] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:49:29,381] {logging_mixin.py:115} INFO - [2023-11-16 10:49:29,381] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:49:29,404] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.223 seconds
[2023-11-16 10:49:59,738] {processor.py:153} INFO - Started process (PID=14975) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:49:59,740] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:49:59,742] {logging_mixin.py:115} INFO - [2023-11-16 10:49:59,741] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:49:59,808] {logging_mixin.py:115} INFO - [2023-11-16 10:49:59,808] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:49:59,840] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:49:59,859] {logging_mixin.py:115} INFO - [2023-11-16 10:49:59,859] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:49:59,923] {logging_mixin.py:115} INFO - [2023-11-16 10:49:59,922] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:49:59,955] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.221 seconds
[2023-11-16 10:50:30,375] {processor.py:153} INFO - Started process (PID=15032) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:50:30,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:50:30,379] {logging_mixin.py:115} INFO - [2023-11-16 10:50:30,379] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:50:30,474] {logging_mixin.py:115} INFO - [2023-11-16 10:50:30,474] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:50:30,524] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:50:30,566] {logging_mixin.py:115} INFO - [2023-11-16 10:50:30,566] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:50:30,653] {logging_mixin.py:115} INFO - [2023-11-16 10:50:30,653] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:50:30,711] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.343 seconds
[2023-11-16 10:51:00,838] {processor.py:153} INFO - Started process (PID=15100) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:51:00,839] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:51:00,841] {logging_mixin.py:115} INFO - [2023-11-16 10:51:00,841] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:51:00,950] {logging_mixin.py:115} INFO - [2023-11-16 10:51:00,950] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:51:01,003] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:51:01,058] {logging_mixin.py:115} INFO - [2023-11-16 10:51:01,058] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:51:01,134] {logging_mixin.py:115} INFO - [2023-11-16 10:51:01,134] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:51:01,177] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.347 seconds
[2023-11-16 10:51:31,408] {processor.py:153} INFO - Started process (PID=15158) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:51:31,410] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:51:31,412] {logging_mixin.py:115} INFO - [2023-11-16 10:51:31,412] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:51:31,501] {logging_mixin.py:115} INFO - [2023-11-16 10:51:31,501] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:51:31,546] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:51:31,594] {logging_mixin.py:115} INFO - [2023-11-16 10:51:31,593] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:51:31,663] {logging_mixin.py:115} INFO - [2023-11-16 10:51:31,663] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:51:31,697] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.297 seconds
[2023-11-16 10:52:02,191] {processor.py:153} INFO - Started process (PID=15225) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:52:02,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:52:02,193] {logging_mixin.py:115} INFO - [2023-11-16 10:52:02,193] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:52:02,284] {logging_mixin.py:115} INFO - [2023-11-16 10:52:02,284] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:52:02,340] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:52:02,416] {logging_mixin.py:115} INFO - [2023-11-16 10:52:02,416] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:52:02,527] {logging_mixin.py:115} INFO - [2023-11-16 10:52:02,526] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:52:02,554] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.368 seconds
[2023-11-16 10:52:32,916] {processor.py:153} INFO - Started process (PID=15283) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:52:32,918] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:52:32,919] {logging_mixin.py:115} INFO - [2023-11-16 10:52:32,919] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:52:32,974] {logging_mixin.py:115} INFO - [2023-11-16 10:52:32,974] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:52:33,003] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:52:33,032] {logging_mixin.py:115} INFO - [2023-11-16 10:52:33,032] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:52:33,072] {logging_mixin.py:115} INFO - [2023-11-16 10:52:33,072] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:52:33,104] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.192 seconds
[2023-11-16 10:53:03,619] {processor.py:153} INFO - Started process (PID=15342) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:53:03,620] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:53:03,621] {logging_mixin.py:115} INFO - [2023-11-16 10:53:03,621] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:53:03,678] {logging_mixin.py:115} INFO - [2023-11-16 10:53:03,677] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:53:03,704] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:53:03,726] {logging_mixin.py:115} INFO - [2023-11-16 10:53:03,726] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:53:03,763] {logging_mixin.py:115} INFO - [2023-11-16 10:53:03,763] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:53:03,788] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.173 seconds
[2023-11-16 10:53:34,231] {processor.py:153} INFO - Started process (PID=15410) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:53:34,232] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:53:34,234] {logging_mixin.py:115} INFO - [2023-11-16 10:53:34,234] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:53:34,313] {logging_mixin.py:115} INFO - [2023-11-16 10:53:34,313] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:53:34,342] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:53:34,365] {logging_mixin.py:115} INFO - [2023-11-16 10:53:34,365] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:53:34,407] {logging_mixin.py:115} INFO - [2023-11-16 10:53:34,407] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:53:34,437] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.216 seconds
[2023-11-16 10:54:04,607] {processor.py:153} INFO - Started process (PID=15470) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:54:04,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:54:04,610] {logging_mixin.py:115} INFO - [2023-11-16 10:54:04,609] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:54:04,662] {logging_mixin.py:115} INFO - [2023-11-16 10:54:04,662] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:54:04,687] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:54:04,709] {logging_mixin.py:115} INFO - [2023-11-16 10:54:04,709] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:54:04,744] {logging_mixin.py:115} INFO - [2023-11-16 10:54:04,743] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:54:04,769] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.166 seconds
[2023-11-16 10:54:34,910] {processor.py:153} INFO - Started process (PID=15536) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:54:34,911] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:54:34,912] {logging_mixin.py:115} INFO - [2023-11-16 10:54:34,912] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:54:34,962] {logging_mixin.py:115} INFO - [2023-11-16 10:54:34,962] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:54:34,988] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:54:35,010] {logging_mixin.py:115} INFO - [2023-11-16 10:54:35,009] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:54:35,044] {logging_mixin.py:115} INFO - [2023-11-16 10:54:35,043] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:54:35,067] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.160 seconds
[2023-11-16 10:55:05,164] {processor.py:153} INFO - Started process (PID=15593) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:55:05,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:55:05,167] {logging_mixin.py:115} INFO - [2023-11-16 10:55:05,167] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:55:05,216] {logging_mixin.py:115} INFO - [2023-11-16 10:55:05,216] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:55:05,243] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:55:05,264] {logging_mixin.py:115} INFO - [2023-11-16 10:55:05,264] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:55:05,297] {logging_mixin.py:115} INFO - [2023-11-16 10:55:05,297] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:55:05,319] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.158 seconds
[2023-11-16 10:55:35,637] {processor.py:153} INFO - Started process (PID=15659) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:55:35,639] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:55:35,641] {logging_mixin.py:115} INFO - [2023-11-16 10:55:35,641] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:55:35,730] {logging_mixin.py:115} INFO - [2023-11-16 10:55:35,730] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:55:35,763] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:55:35,802] {logging_mixin.py:115} INFO - [2023-11-16 10:55:35,802] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:55:35,865] {logging_mixin.py:115} INFO - [2023-11-16 10:55:35,865] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:55:35,894] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.263 seconds
[2023-11-16 10:56:06,004] {processor.py:153} INFO - Started process (PID=15717) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:56:06,005] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:56:06,007] {logging_mixin.py:115} INFO - [2023-11-16 10:56:06,007] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:56:06,084] {logging_mixin.py:115} INFO - [2023-11-16 10:56:06,083] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:56:06,115] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:56:06,138] {logging_mixin.py:115} INFO - [2023-11-16 10:56:06,138] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:56:06,178] {logging_mixin.py:115} INFO - [2023-11-16 10:56:06,178] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:56:06,203] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.204 seconds
[2023-11-16 10:56:37,019] {processor.py:153} INFO - Started process (PID=15785) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:56:37,020] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:56:37,022] {logging_mixin.py:115} INFO - [2023-11-16 10:56:37,021] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:56:37,081] {logging_mixin.py:115} INFO - [2023-11-16 10:56:37,081] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:56:37,108] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:56:37,129] {logging_mixin.py:115} INFO - [2023-11-16 10:56:37,129] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:56:37,160] {logging_mixin.py:115} INFO - [2023-11-16 10:56:37,160] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:56:37,183] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.168 seconds
[2023-11-16 10:57:07,388] {processor.py:153} INFO - Started process (PID=15843) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:57:07,389] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:57:07,390] {logging_mixin.py:115} INFO - [2023-11-16 10:57:07,390] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:57:07,442] {logging_mixin.py:115} INFO - [2023-11-16 10:57:07,442] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:57:07,468] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:57:07,488] {logging_mixin.py:115} INFO - [2023-11-16 10:57:07,488] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:57:07,523] {logging_mixin.py:115} INFO - [2023-11-16 10:57:07,522] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:57:07,545] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 10:57:37,794] {processor.py:153} INFO - Started process (PID=15910) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:57:37,795] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:57:37,796] {logging_mixin.py:115} INFO - [2023-11-16 10:57:37,796] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:57:37,855] {logging_mixin.py:115} INFO - [2023-11-16 10:57:37,854] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:57:37,878] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:57:37,898] {logging_mixin.py:115} INFO - [2023-11-16 10:57:37,898] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:57:37,930] {logging_mixin.py:115} INFO - [2023-11-16 10:57:37,930] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:57:37,952] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 10:58:08,178] {processor.py:153} INFO - Started process (PID=15968) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:58:08,179] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:58:08,180] {logging_mixin.py:115} INFO - [2023-11-16 10:58:08,180] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:58:08,234] {logging_mixin.py:115} INFO - [2023-11-16 10:58:08,234] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:58:08,258] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:58:08,275] {logging_mixin.py:115} INFO - [2023-11-16 10:58:08,275] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:58:08,320] {logging_mixin.py:115} INFO - [2023-11-16 10:58:08,320] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:58:08,347] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.173 seconds
[2023-11-16 10:58:38,547] {processor.py:153} INFO - Started process (PID=16035) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:58:38,548] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:58:38,550] {logging_mixin.py:115} INFO - [2023-11-16 10:58:38,550] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:58:38,610] {logging_mixin.py:115} INFO - [2023-11-16 10:58:38,610] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:58:38,637] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:58:38,660] {logging_mixin.py:115} INFO - [2023-11-16 10:58:38,660] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:58:38,704] {logging_mixin.py:115} INFO - [2023-11-16 10:58:38,704] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:58:38,726] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.184 seconds
[2023-11-16 10:59:09,038] {processor.py:153} INFO - Started process (PID=16102) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:59:09,040] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:59:09,042] {logging_mixin.py:115} INFO - [2023-11-16 10:59:09,041] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:59:09,099] {logging_mixin.py:115} INFO - [2023-11-16 10:59:09,099] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:59:09,126] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:59:09,152] {logging_mixin.py:115} INFO - [2023-11-16 10:59:09,152] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:59:09,192] {logging_mixin.py:115} INFO - [2023-11-16 10:59:09,192] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:59:09,216] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.187 seconds
[2023-11-16 10:59:39,807] {processor.py:153} INFO - Started process (PID=16160) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 10:59:39,808] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 10:59:39,810] {logging_mixin.py:115} INFO - [2023-11-16 10:59:39,810] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 10:59:39,870] {logging_mixin.py:115} INFO - [2023-11-16 10:59:39,870] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 10:59:39,898] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 10:59:39,928] {logging_mixin.py:115} INFO - [2023-11-16 10:59:39,928] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 10:59:39,968] {logging_mixin.py:115} INFO - [2023-11-16 10:59:39,968] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 10:59:39,992] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.190 seconds
[2023-11-16 11:11:27,136] {processor.py:153} INFO - Started process (PID=73) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:11:27,138] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:11:27,140] {logging_mixin.py:115} INFO - [2023-11-16 11:11:27,140] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:11:27,301] {logging_mixin.py:115} INFO - [2023-11-16 11:11:27,300] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:11:27,343] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:11:27,374] {logging_mixin.py:115} INFO - [2023-11-16 11:11:27,373] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:11:27,435] {logging_mixin.py:115} INFO - [2023-11-16 11:11:27,435] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:11:27,478] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.350 seconds
[2023-11-16 11:11:58,456] {processor.py:153} INFO - Started process (PID=141) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:11:58,458] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:11:58,460] {logging_mixin.py:115} INFO - [2023-11-16 11:11:58,460] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:11:58,562] {logging_mixin.py:115} INFO - [2023-11-16 11:11:58,562] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:11:58,604] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:11:58,645] {logging_mixin.py:115} INFO - [2023-11-16 11:11:58,644] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:11:58,702] {logging_mixin.py:115} INFO - [2023-11-16 11:11:58,702] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:11:58,741] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.290 seconds
[2023-11-16 11:12:29,302] {processor.py:153} INFO - Started process (PID=199) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:12:29,304] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:12:29,306] {logging_mixin.py:115} INFO - [2023-11-16 11:12:29,305] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:12:29,396] {logging_mixin.py:115} INFO - [2023-11-16 11:12:29,396] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:12:29,448] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:12:29,482] {logging_mixin.py:115} INFO - [2023-11-16 11:12:29,482] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:12:29,539] {logging_mixin.py:115} INFO - [2023-11-16 11:12:29,539] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:12:29,576] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.278 seconds
[2023-11-16 11:13:00,316] {processor.py:153} INFO - Started process (PID=257) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:13:00,320] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:13:00,323] {logging_mixin.py:115} INFO - [2023-11-16 11:13:00,322] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:13:00,428] {logging_mixin.py:115} INFO - [2023-11-16 11:13:00,428] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:13:00,467] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:13:00,509] {logging_mixin.py:115} INFO - [2023-11-16 11:13:00,509] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:13:00,582] {logging_mixin.py:115} INFO - [2023-11-16 11:13:00,582] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:13:00,655] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.347 seconds
[2023-11-16 11:13:31,545] {processor.py:153} INFO - Started process (PID=324) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:13:31,546] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:13:31,548] {logging_mixin.py:115} INFO - [2023-11-16 11:13:31,548] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:13:31,662] {logging_mixin.py:115} INFO - [2023-11-16 11:13:31,661] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:13:31,709] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:13:31,739] {logging_mixin.py:115} INFO - [2023-11-16 11:13:31,739] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:13:31,792] {logging_mixin.py:115} INFO - [2023-11-16 11:13:31,792] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:13:31,829] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.288 seconds
[2023-11-16 11:14:02,299] {processor.py:153} INFO - Started process (PID=382) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:14:02,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:14:02,303] {logging_mixin.py:115} INFO - [2023-11-16 11:14:02,302] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:14:02,394] {logging_mixin.py:115} INFO - [2023-11-16 11:14:02,394] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:14:02,429] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:14:02,462] {logging_mixin.py:115} INFO - [2023-11-16 11:14:02,461] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:14:02,505] {logging_mixin.py:115} INFO - [2023-11-16 11:14:02,505] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:14:02,540] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.246 seconds
[2023-11-16 11:14:33,188] {processor.py:153} INFO - Started process (PID=440) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:14:33,190] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:14:33,193] {logging_mixin.py:115} INFO - [2023-11-16 11:14:33,192] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:14:33,276] {logging_mixin.py:115} INFO - [2023-11-16 11:14:33,276] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:14:33,314] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:14:33,350] {logging_mixin.py:115} INFO - [2023-11-16 11:14:33,350] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:14:33,406] {logging_mixin.py:115} INFO - [2023-11-16 11:14:33,406] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:14:33,445] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.261 seconds
[2023-11-16 11:15:03,644] {processor.py:153} INFO - Started process (PID=507) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:15:03,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:15:03,648] {logging_mixin.py:115} INFO - [2023-11-16 11:15:03,647] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:15:03,742] {logging_mixin.py:115} INFO - [2023-11-16 11:15:03,742] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:15:03,780] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:15:03,811] {logging_mixin.py:115} INFO - [2023-11-16 11:15:03,811] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:15:03,867] {logging_mixin.py:115} INFO - [2023-11-16 11:15:03,867] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:15:03,905] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.265 seconds
[2023-11-16 11:15:34,357] {processor.py:153} INFO - Started process (PID=565) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:15:34,360] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:15:34,363] {logging_mixin.py:115} INFO - [2023-11-16 11:15:34,362] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:15:34,443] {logging_mixin.py:115} INFO - [2023-11-16 11:15:34,443] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:15:34,484] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:15:34,518] {logging_mixin.py:115} INFO - [2023-11-16 11:15:34,518] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:15:34,564] {logging_mixin.py:115} INFO - [2023-11-16 11:15:34,564] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:15:34,598] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.248 seconds
[2023-11-16 11:16:05,393] {processor.py:153} INFO - Started process (PID=623) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:16:05,394] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:16:05,396] {logging_mixin.py:115} INFO - [2023-11-16 11:16:05,396] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:16:05,482] {logging_mixin.py:115} INFO - [2023-11-16 11:16:05,482] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:16:05,524] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:16:05,554] {logging_mixin.py:115} INFO - [2023-11-16 11:16:05,553] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:16:05,616] {logging_mixin.py:115} INFO - [2023-11-16 11:16:05,615] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:16:05,652] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.271 seconds
[2023-11-16 11:16:35,898] {processor.py:153} INFO - Started process (PID=691) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:16:35,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:16:35,900] {logging_mixin.py:115} INFO - [2023-11-16 11:16:35,900] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:16:35,960] {logging_mixin.py:115} INFO - [2023-11-16 11:16:35,960] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:16:35,996] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:16:36,030] {logging_mixin.py:115} INFO - [2023-11-16 11:16:36,030] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:16:36,071] {logging_mixin.py:115} INFO - [2023-11-16 11:16:36,071] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:16:36,107] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.213 seconds
[2023-11-16 11:17:06,221] {processor.py:153} INFO - Started process (PID=748) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:17:06,222] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:17:06,224] {logging_mixin.py:115} INFO - [2023-11-16 11:17:06,223] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:17:06,300] {logging_mixin.py:115} INFO - [2023-11-16 11:17:06,299] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:17:06,333] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:17:06,368] {logging_mixin.py:115} INFO - [2023-11-16 11:17:06,367] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:17:06,414] {logging_mixin.py:115} INFO - [2023-11-16 11:17:06,414] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:17:06,460] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.244 seconds
[2023-11-16 11:17:36,733] {processor.py:153} INFO - Started process (PID=806) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:17:36,735] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:17:36,736] {logging_mixin.py:115} INFO - [2023-11-16 11:17:36,736] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:17:36,821] {logging_mixin.py:115} INFO - [2023-11-16 11:17:36,820] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:17:36,854] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:17:36,883] {logging_mixin.py:115} INFO - [2023-11-16 11:17:36,883] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:17:36,954] {logging_mixin.py:115} INFO - [2023-11-16 11:17:36,954] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:17:36,999] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.271 seconds
[2023-11-16 11:18:07,217] {processor.py:153} INFO - Started process (PID=871) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:18:07,218] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:18:07,220] {logging_mixin.py:115} INFO - [2023-11-16 11:18:07,220] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:18:07,292] {logging_mixin.py:115} INFO - [2023-11-16 11:18:07,291] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:18:07,324] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:18:07,349] {logging_mixin.py:115} INFO - [2023-11-16 11:18:07,348] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:18:07,390] {logging_mixin.py:115} INFO - [2023-11-16 11:18:07,390] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:18:07,419] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.208 seconds
[2023-11-16 11:18:37,586] {processor.py:153} INFO - Started process (PID=930) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:18:37,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:18:37,589] {logging_mixin.py:115} INFO - [2023-11-16 11:18:37,589] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:18:37,678] {logging_mixin.py:115} INFO - [2023-11-16 11:18:37,678] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:18:37,718] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:18:37,755] {logging_mixin.py:115} INFO - [2023-11-16 11:18:37,755] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:18:37,816] {logging_mixin.py:115} INFO - [2023-11-16 11:18:37,816] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:18:37,857] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.278 seconds
[2023-11-16 11:19:08,513] {processor.py:153} INFO - Started process (PID=988) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:19:08,515] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:19:08,517] {logging_mixin.py:115} INFO - [2023-11-16 11:19:08,516] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:19:08,610] {logging_mixin.py:115} INFO - [2023-11-16 11:19:08,610] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:19:08,650] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:19:08,686] {logging_mixin.py:115} INFO - [2023-11-16 11:19:08,686] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:19:08,736] {logging_mixin.py:115} INFO - [2023-11-16 11:19:08,736] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:19:08,774] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.270 seconds
[2023-11-16 11:19:39,320] {processor.py:153} INFO - Started process (PID=1046) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:19:39,321] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:19:39,323] {logging_mixin.py:115} INFO - [2023-11-16 11:19:39,323] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:19:39,404] {logging_mixin.py:115} INFO - [2023-11-16 11:19:39,404] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:19:39,437] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:19:39,463] {logging_mixin.py:115} INFO - [2023-11-16 11:19:39,462] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:19:39,518] {logging_mixin.py:115} INFO - [2023-11-16 11:19:39,518] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:19:39,561] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.245 seconds
[2023-11-16 11:20:10,418] {processor.py:153} INFO - Started process (PID=1113) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:20:10,420] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:20:10,422] {logging_mixin.py:115} INFO - [2023-11-16 11:20:10,422] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:20:10,520] {logging_mixin.py:115} INFO - [2023-11-16 11:20:10,520] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:20:10,562] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:20:10,596] {logging_mixin.py:115} INFO - [2023-11-16 11:20:10,595] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:20:10,641] {logging_mixin.py:115} INFO - [2023-11-16 11:20:10,640] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:20:10,670] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.258 seconds
[2023-11-16 11:20:40,950] {processor.py:153} INFO - Started process (PID=1171) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:20:40,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:20:40,955] {logging_mixin.py:115} INFO - [2023-11-16 11:20:40,955] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:20:41,131] {logging_mixin.py:115} INFO - [2023-11-16 11:20:41,131] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:20:41,179] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:20:41,248] {logging_mixin.py:115} INFO - [2023-11-16 11:20:41,248] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:20:41,317] {logging_mixin.py:115} INFO - [2023-11-16 11:20:41,317] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:20:41,368] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.425 seconds
[2023-11-16 11:21:11,669] {processor.py:153} INFO - Started process (PID=1229) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:21:11,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:21:11,673] {logging_mixin.py:115} INFO - [2023-11-16 11:21:11,673] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:21:11,818] {logging_mixin.py:115} INFO - [2023-11-16 11:21:11,818] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:21:11,873] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:21:11,922] {logging_mixin.py:115} INFO - [2023-11-16 11:21:11,922] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:21:11,993] {logging_mixin.py:115} INFO - [2023-11-16 11:21:11,992] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:21:12,042] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.381 seconds
[2023-11-16 11:21:42,598] {processor.py:153} INFO - Started process (PID=1287) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:21:42,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:21:42,602] {logging_mixin.py:115} INFO - [2023-11-16 11:21:42,601] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:21:42,695] {logging_mixin.py:115} INFO - [2023-11-16 11:21:42,695] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:21:42,742] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:21:42,789] {logging_mixin.py:115} INFO - [2023-11-16 11:21:42,788] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:21:42,860] {logging_mixin.py:115} INFO - [2023-11-16 11:21:42,859] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:21:42,904] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.313 seconds
[2023-11-16 11:22:13,718] {processor.py:153} INFO - Started process (PID=1354) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:22:13,719] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:22:13,721] {logging_mixin.py:115} INFO - [2023-11-16 11:22:13,721] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:22:13,837] {logging_mixin.py:115} INFO - [2023-11-16 11:22:13,836] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:22:13,876] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:22:13,915] {logging_mixin.py:115} INFO - [2023-11-16 11:22:13,914] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:22:13,988] {logging_mixin.py:115} INFO - [2023-11-16 11:22:13,988] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:22:14,029] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.317 seconds
[2023-11-16 11:22:44,462] {processor.py:153} INFO - Started process (PID=1412) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:22:44,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:22:44,467] {logging_mixin.py:115} INFO - [2023-11-16 11:22:44,466] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:22:44,565] {logging_mixin.py:115} INFO - [2023-11-16 11:22:44,565] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:22:44,599] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:22:44,628] {logging_mixin.py:115} INFO - [2023-11-16 11:22:44,628] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:22:44,676] {logging_mixin.py:115} INFO - [2023-11-16 11:22:44,676] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:22:44,712] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.256 seconds
[2023-11-16 11:23:15,174] {processor.py:153} INFO - Started process (PID=1470) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:23:15,176] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:23:15,178] {logging_mixin.py:115} INFO - [2023-11-16 11:23:15,178] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:23:15,297] {logging_mixin.py:115} INFO - [2023-11-16 11:23:15,296] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:23:15,349] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:23:15,395] {logging_mixin.py:115} INFO - [2023-11-16 11:23:15,394] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:23:15,459] {logging_mixin.py:115} INFO - [2023-11-16 11:23:15,459] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:23:15,501] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.334 seconds
[2023-11-16 11:23:45,705] {processor.py:153} INFO - Started process (PID=1537) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:23:45,710] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:23:45,713] {logging_mixin.py:115} INFO - [2023-11-16 11:23:45,712] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:23:45,832] {logging_mixin.py:115} INFO - [2023-11-16 11:23:45,832] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:23:45,873] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:23:45,914] {logging_mixin.py:115} INFO - [2023-11-16 11:23:45,914] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:23:45,985] {logging_mixin.py:115} INFO - [2023-11-16 11:23:45,985] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:23:46,024] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.327 seconds
[2023-11-16 11:24:16,402] {processor.py:153} INFO - Started process (PID=1596) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:24:16,404] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:24:16,406] {logging_mixin.py:115} INFO - [2023-11-16 11:24:16,405] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:24:16,497] {logging_mixin.py:115} INFO - [2023-11-16 11:24:16,496] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:24:16,538] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:24:16,574] {logging_mixin.py:115} INFO - [2023-11-16 11:24:16,574] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:24:16,631] {logging_mixin.py:115} INFO - [2023-11-16 11:24:16,631] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:24:16,684] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.289 seconds
[2023-11-16 11:24:47,257] {processor.py:153} INFO - Started process (PID=1653) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:24:47,259] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:24:47,262] {logging_mixin.py:115} INFO - [2023-11-16 11:24:47,262] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:24:47,376] {logging_mixin.py:115} INFO - [2023-11-16 11:24:47,376] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:24:47,421] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:24:47,468] {logging_mixin.py:115} INFO - [2023-11-16 11:24:47,467] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:24:47,540] {logging_mixin.py:115} INFO - [2023-11-16 11:24:47,539] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:24:47,571] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.323 seconds
[2023-11-16 11:25:17,746] {processor.py:153} INFO - Started process (PID=1712) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:25:17,747] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:25:17,749] {logging_mixin.py:115} INFO - [2023-11-16 11:25:17,749] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:25:17,853] {logging_mixin.py:115} INFO - [2023-11-16 11:25:17,853] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:25:17,893] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:25:17,935] {logging_mixin.py:115} INFO - [2023-11-16 11:25:17,934] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:25:18,009] {logging_mixin.py:115} INFO - [2023-11-16 11:25:18,008] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:25:18,053] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.312 seconds
[2023-11-16 11:25:48,184] {processor.py:153} INFO - Started process (PID=1778) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:25:48,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:25:48,188] {logging_mixin.py:115} INFO - [2023-11-16 11:25:48,188] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:25:48,328] {logging_mixin.py:115} INFO - [2023-11-16 11:25:48,328] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:25:48,398] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:25:48,455] {logging_mixin.py:115} INFO - [2023-11-16 11:25:48,455] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:25:48,562] {logging_mixin.py:115} INFO - [2023-11-16 11:25:48,562] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:25:48,615] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.437 seconds
[2023-11-16 11:26:18,712] {processor.py:153} INFO - Started process (PID=1839) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:26:18,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:26:18,719] {logging_mixin.py:115} INFO - [2023-11-16 11:26:18,719] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:26:18,806] {logging_mixin.py:115} INFO - [2023-11-16 11:26:18,806] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:26:18,842] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:26:18,879] {logging_mixin.py:115} INFO - [2023-11-16 11:26:18,879] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:26:18,960] {logging_mixin.py:115} INFO - [2023-11-16 11:26:18,960] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:26:18,996] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.293 seconds
[2023-11-16 11:26:49,825] {processor.py:153} INFO - Started process (PID=1896) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:26:49,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:26:49,829] {logging_mixin.py:115} INFO - [2023-11-16 11:26:49,828] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:26:49,917] {logging_mixin.py:115} INFO - [2023-11-16 11:26:49,916] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:26:49,955] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:26:49,986] {logging_mixin.py:115} INFO - [2023-11-16 11:26:49,986] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:26:50,035] {logging_mixin.py:115} INFO - [2023-11-16 11:26:50,034] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:26:50,061] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.243 seconds
[2023-11-16 11:27:20,966] {processor.py:153} INFO - Started process (PID=1954) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:27:20,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:27:20,969] {logging_mixin.py:115} INFO - [2023-11-16 11:27:20,969] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:27:21,047] {logging_mixin.py:115} INFO - [2023-11-16 11:27:21,046] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:27:21,087] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:27:21,113] {logging_mixin.py:115} INFO - [2023-11-16 11:27:21,113] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:27:21,179] {logging_mixin.py:115} INFO - [2023-11-16 11:27:21,179] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:27:21,214] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.255 seconds
[2023-11-16 11:27:52,140] {processor.py:153} INFO - Started process (PID=2021) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:27:52,141] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:27:52,144] {logging_mixin.py:115} INFO - [2023-11-16 11:27:52,144] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:27:52,235] {logging_mixin.py:115} INFO - [2023-11-16 11:27:52,235] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:27:52,273] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:27:52,306] {logging_mixin.py:115} INFO - [2023-11-16 11:27:52,306] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:27:52,361] {logging_mixin.py:115} INFO - [2023-11-16 11:27:52,361] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:27:52,396] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.262 seconds
[2023-11-16 11:28:23,227] {processor.py:153} INFO - Started process (PID=2079) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:28:23,228] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:28:23,230] {logging_mixin.py:115} INFO - [2023-11-16 11:28:23,230] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:28:23,292] {logging_mixin.py:115} INFO - [2023-11-16 11:28:23,292] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:28:23,320] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:28:23,344] {logging_mixin.py:115} INFO - [2023-11-16 11:28:23,344] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:28:23,388] {logging_mixin.py:115} INFO - [2023-11-16 11:28:23,388] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:28:23,417] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.193 seconds
[2023-11-16 11:28:54,252] {processor.py:153} INFO - Started process (PID=2137) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:28:54,254] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:28:54,255] {logging_mixin.py:115} INFO - [2023-11-16 11:28:54,255] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:28:54,323] {logging_mixin.py:115} INFO - [2023-11-16 11:28:54,323] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:28:54,355] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:28:54,380] {logging_mixin.py:115} INFO - [2023-11-16 11:28:54,379] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:28:54,425] {logging_mixin.py:115} INFO - [2023-11-16 11:28:54,424] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:28:54,456] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.208 seconds
[2023-11-16 11:29:24,566] {processor.py:153} INFO - Started process (PID=2196) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:29:24,568] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:29:24,569] {logging_mixin.py:115} INFO - [2023-11-16 11:29:24,569] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:29:24,647] {logging_mixin.py:115} INFO - [2023-11-16 11:29:24,646] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:29:24,682] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:29:24,715] {logging_mixin.py:115} INFO - [2023-11-16 11:29:24,714] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:29:24,779] {logging_mixin.py:115} INFO - [2023-11-16 11:29:24,779] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:29:24,806] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.246 seconds
[2023-11-16 11:29:55,354] {processor.py:153} INFO - Started process (PID=2262) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:29:55,356] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:29:55,357] {logging_mixin.py:115} INFO - [2023-11-16 11:29:55,357] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:29:55,426] {logging_mixin.py:115} INFO - [2023-11-16 11:29:55,426] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:29:55,462] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:29:55,490] {logging_mixin.py:115} INFO - [2023-11-16 11:29:55,490] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:29:55,537] {logging_mixin.py:115} INFO - [2023-11-16 11:29:55,537] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:29:55,566] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 11:30:25,638] {processor.py:153} INFO - Started process (PID=2320) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:30:25,640] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:30:25,642] {logging_mixin.py:115} INFO - [2023-11-16 11:30:25,642] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:30:25,729] {logging_mixin.py:115} INFO - [2023-11-16 11:30:25,729] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:30:25,774] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:30:25,810] {logging_mixin.py:115} INFO - [2023-11-16 11:30:25,810] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:30:25,886] {logging_mixin.py:115} INFO - [2023-11-16 11:30:25,886] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:30:25,920] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.291 seconds
[2023-11-16 11:30:56,244] {processor.py:153} INFO - Started process (PID=2379) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:30:56,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:30:56,248] {logging_mixin.py:115} INFO - [2023-11-16 11:30:56,248] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:30:56,340] {logging_mixin.py:115} INFO - [2023-11-16 11:30:56,340] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:30:56,375] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:30:56,409] {logging_mixin.py:115} INFO - [2023-11-16 11:30:56,408] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:30:56,457] {logging_mixin.py:115} INFO - [2023-11-16 11:30:56,457] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:30:56,486] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.247 seconds
[2023-11-16 11:31:27,086] {processor.py:153} INFO - Started process (PID=2445) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:31:27,088] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:31:27,090] {logging_mixin.py:115} INFO - [2023-11-16 11:31:27,090] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:31:27,211] {logging_mixin.py:115} INFO - [2023-11-16 11:31:27,211] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:31:27,249] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:31:27,286] {logging_mixin.py:115} INFO - [2023-11-16 11:31:27,285] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:31:27,348] {logging_mixin.py:115} INFO - [2023-11-16 11:31:27,347] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:31:27,377] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.302 seconds
[2023-11-16 11:31:37,720] {processor.py:153} INFO - Started process (PID=2483) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:31:37,722] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:31:37,725] {logging_mixin.py:115} INFO - [2023-11-16 11:31:37,725] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:31:37,847] {logging_mixin.py:115} INFO - [2023-11-16 11:31:37,837] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:31:37,849] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:31:37,912] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.196 seconds
[2023-11-16 11:32:08,145] {processor.py:153} INFO - Started process (PID=2551) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:32:08,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:32:08,149] {logging_mixin.py:115} INFO - [2023-11-16 11:32:08,149] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:32:08,200] {logging_mixin.py:115} INFO - [2023-11-16 11:32:08,192] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:32:08,205] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:32:08,269] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.131 seconds
[2023-11-16 11:32:39,094] {processor.py:153} INFO - Started process (PID=2611) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:32:39,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:32:39,097] {logging_mixin.py:115} INFO - [2023-11-16 11:32:39,097] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:32:39,157] {logging_mixin.py:115} INFO - [2023-11-16 11:32:39,150] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:32:39,160] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:32:39,224] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.134 seconds
[2023-11-16 11:33:09,752] {processor.py:153} INFO - Started process (PID=2669) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:33:09,754] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:33:09,756] {logging_mixin.py:115} INFO - [2023-11-16 11:33:09,756] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:33:09,811] {logging_mixin.py:115} INFO - [2023-11-16 11:33:09,802] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:33:09,814] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:33:09,880] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.137 seconds
[2023-11-16 11:33:40,250] {processor.py:153} INFO - Started process (PID=2734) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:33:40,251] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:33:40,253] {logging_mixin.py:115} INFO - [2023-11-16 11:33:40,253] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:33:40,312] {logging_mixin.py:115} INFO - [2023-11-16 11:33:40,304] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:33:40,315] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:33:40,365] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.119 seconds
[2023-11-16 11:34:11,247] {processor.py:153} INFO - Started process (PID=2794) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:34:11,249] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:34:11,251] {logging_mixin.py:115} INFO - [2023-11-16 11:34:11,250] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:34:11,305] {logging_mixin.py:115} INFO - [2023-11-16 11:34:11,295] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:34:11,310] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:34:11,366] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.123 seconds
[2023-11-16 11:34:41,882] {processor.py:153} INFO - Started process (PID=2852) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:34:41,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:34:41,889] {logging_mixin.py:115} INFO - [2023-11-16 11:34:41,889] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:34:41,946] {logging_mixin.py:115} INFO - [2023-11-16 11:34:41,939] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:34:41,949] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:34:41,985] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.109 seconds
[2023-11-16 11:35:12,668] {processor.py:153} INFO - Started process (PID=2911) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:12,670] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:35:12,672] {logging_mixin.py:115} INFO - [2023-11-16 11:35:12,672] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:12,736] {logging_mixin.py:115} INFO - [2023-11-16 11:35:12,726] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:35:12,739] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:12,808] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.149 seconds
[2023-11-16 11:35:43,187] {processor.py:153} INFO - Started process (PID=2978) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:43,189] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:35:43,191] {logging_mixin.py:115} INFO - [2023-11-16 11:35:43,190] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:43,252] {logging_mixin.py:115} INFO - [2023-11-16 11:35:43,244] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 14, in <module>
    import fake_useragent
ModuleNotFoundError: No module named 'fake_useragent'
[2023-11-16 11:35:43,256] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:43,308] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.125 seconds
[2023-11-16 11:35:54,518] {processor.py:153} INFO - Started process (PID=2979) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:54,519] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:35:54,521] {logging_mixin.py:115} INFO - [2023-11-16 11:35:54,521] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:54,669] {logging_mixin.py:115} INFO - [2023-11-16 11:35:54,668] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:35:54,705] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:35:54,740] {logging_mixin.py:115} INFO - [2023-11-16 11:35:54,740] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:35:54,796] {logging_mixin.py:115} INFO - [2023-11-16 11:35:54,795] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:35:54,846] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.333 seconds
[2023-11-16 11:36:25,722] {processor.py:153} INFO - Started process (PID=3045) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:36:25,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:36:25,725] {logging_mixin.py:115} INFO - [2023-11-16 11:36:25,725] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:36:25,797] {logging_mixin.py:115} INFO - [2023-11-16 11:36:25,797] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:36:25,836] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:36:25,870] {logging_mixin.py:115} INFO - [2023-11-16 11:36:25,869] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:36:25,916] {logging_mixin.py:115} INFO - [2023-11-16 11:36:25,916] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:36:25,938] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.221 seconds
[2023-11-16 11:36:56,056] {processor.py:153} INFO - Started process (PID=3103) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:36:56,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:36:56,059] {logging_mixin.py:115} INFO - [2023-11-16 11:36:56,059] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:36:56,150] {logging_mixin.py:115} INFO - [2023-11-16 11:36:56,150] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:36:56,189] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:36:56,231] {logging_mixin.py:115} INFO - [2023-11-16 11:36:56,231] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:36:56,283] {logging_mixin.py:115} INFO - [2023-11-16 11:36:56,283] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:36:56,338] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.288 seconds
[2023-11-16 11:37:26,991] {processor.py:153} INFO - Started process (PID=3161) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:37:26,992] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:37:26,994] {logging_mixin.py:115} INFO - [2023-11-16 11:37:26,994] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:37:27,076] {logging_mixin.py:115} INFO - [2023-11-16 11:37:27,075] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:37:27,117] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:37:27,159] {logging_mixin.py:115} INFO - [2023-11-16 11:37:27,159] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:37:27,251] {logging_mixin.py:115} INFO - [2023-11-16 11:37:27,251] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:37:27,299] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.312 seconds
[2023-11-16 11:37:57,762] {processor.py:153} INFO - Started process (PID=3228) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:37:57,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:37:57,771] {logging_mixin.py:115} INFO - [2023-11-16 11:37:57,771] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:37:57,895] {logging_mixin.py:115} INFO - [2023-11-16 11:37:57,895] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:37:57,933] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:37:57,968] {logging_mixin.py:115} INFO - [2023-11-16 11:37:57,968] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:37:58,024] {logging_mixin.py:115} INFO - [2023-11-16 11:37:58,024] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:37:58,064] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.314 seconds
[2023-11-16 11:38:29,040] {processor.py:153} INFO - Started process (PID=3286) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:38:29,042] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:38:29,044] {logging_mixin.py:115} INFO - [2023-11-16 11:38:29,043] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:38:29,165] {logging_mixin.py:115} INFO - [2023-11-16 11:38:29,164] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:38:29,226] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:38:29,352] {logging_mixin.py:115} INFO - [2023-11-16 11:38:29,352] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:38:29,369] {logging_mixin.py:115} INFO - [2023-11-16 11:38:29,369] {dag.py:2439} INFO - Creating ORM DAG for etl_hh
[2023-11-16 11:38:29,399] {logging_mixin.py:115} INFO - [2023-11-16 11:38:29,398] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:38:29,438] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.403 seconds
[2023-11-16 11:39:00,264] {processor.py:153} INFO - Started process (PID=3343) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:39:00,265] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:39:00,268] {logging_mixin.py:115} INFO - [2023-11-16 11:39:00,267] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:39:00,362] {logging_mixin.py:115} INFO - [2023-11-16 11:39:00,362] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:39:00,410] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:39:00,454] {logging_mixin.py:115} INFO - [2023-11-16 11:39:00,454] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:39:00,527] {logging_mixin.py:115} INFO - [2023-11-16 11:39:00,527] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:39:00,572] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.317 seconds
[2023-11-16 11:39:31,599] {processor.py:153} INFO - Started process (PID=3401) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:39:31,600] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:39:31,602] {logging_mixin.py:115} INFO - [2023-11-16 11:39:31,602] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:39:31,664] {logging_mixin.py:115} INFO - [2023-11-16 11:39:31,664] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:39:31,695] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:39:31,727] {logging_mixin.py:115} INFO - [2023-11-16 11:39:31,726] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:39:31,816] {logging_mixin.py:115} INFO - [2023-11-16 11:39:31,816] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:39:31,866] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.272 seconds
[2023-11-16 11:40:02,267] {processor.py:153} INFO - Started process (PID=3469) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:40:02,268] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:40:02,270] {logging_mixin.py:115} INFO - [2023-11-16 11:40:02,270] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:40:02,361] {logging_mixin.py:115} INFO - [2023-11-16 11:40:02,361] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:40:02,400] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:40:02,433] {logging_mixin.py:115} INFO - [2023-11-16 11:40:02,433] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:40:02,480] {logging_mixin.py:115} INFO - [2023-11-16 11:40:02,480] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:40:02,506] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.245 seconds
[2023-11-16 11:40:32,863] {processor.py:153} INFO - Started process (PID=3527) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:40:32,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:40:32,865] {logging_mixin.py:115} INFO - [2023-11-16 11:40:32,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:40:32,928] {logging_mixin.py:115} INFO - [2023-11-16 11:40:32,928] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:40:32,960] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:40:32,985] {logging_mixin.py:115} INFO - [2023-11-16 11:40:32,985] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:40:33,046] {logging_mixin.py:115} INFO - [2023-11-16 11:40:33,046] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:40:33,104] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.246 seconds
[2023-11-16 11:41:03,829] {processor.py:153} INFO - Started process (PID=3585) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:41:03,833] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:41:03,835] {logging_mixin.py:115} INFO - [2023-11-16 11:41:03,835] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:41:03,902] {logging_mixin.py:115} INFO - [2023-11-16 11:41:03,902] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:41:03,940] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:41:03,982] {logging_mixin.py:115} INFO - [2023-11-16 11:41:03,982] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:41:04,035] {logging_mixin.py:115} INFO - [2023-11-16 11:41:04,034] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:41:04,075] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.255 seconds
[2023-11-16 11:41:34,511] {processor.py:153} INFO - Started process (PID=3653) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:41:34,513] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:41:34,514] {logging_mixin.py:115} INFO - [2023-11-16 11:41:34,514] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:41:34,596] {logging_mixin.py:115} INFO - [2023-11-16 11:41:34,595] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:41:34,634] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:41:34,663] {logging_mixin.py:115} INFO - [2023-11-16 11:41:34,663] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:41:34,707] {logging_mixin.py:115} INFO - [2023-11-16 11:41:34,707] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:41:34,741] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.234 seconds
[2023-11-16 11:42:04,988] {processor.py:153} INFO - Started process (PID=3711) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:42:04,990] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:42:04,991] {logging_mixin.py:115} INFO - [2023-11-16 11:42:04,991] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:42:05,085] {logging_mixin.py:115} INFO - [2023-11-16 11:42:05,085] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:42:05,128] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:42:05,168] {logging_mixin.py:115} INFO - [2023-11-16 11:42:05,168] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:42:05,239] {logging_mixin.py:115} INFO - [2023-11-16 11:42:05,239] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:42:05,276] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.295 seconds
[2023-11-16 11:42:35,699] {processor.py:153} INFO - Started process (PID=3769) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:42:35,702] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:42:35,704] {logging_mixin.py:115} INFO - [2023-11-16 11:42:35,704] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:42:35,807] {logging_mixin.py:115} INFO - [2023-11-16 11:42:35,807] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:42:35,849] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:42:35,895] {logging_mixin.py:115} INFO - [2023-11-16 11:42:35,895] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:42:36,002] {logging_mixin.py:115} INFO - [2023-11-16 11:42:36,002] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:42:36,053] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.363 seconds
[2023-11-16 11:43:06,198] {processor.py:153} INFO - Started process (PID=3827) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:43:06,200] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:43:06,202] {logging_mixin.py:115} INFO - [2023-11-16 11:43:06,202] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:43:06,306] {logging_mixin.py:115} INFO - [2023-11-16 11:43:06,306] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:43:06,353] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:43:06,389] {logging_mixin.py:115} INFO - [2023-11-16 11:43:06,389] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:43:06,453] {logging_mixin.py:115} INFO - [2023-11-16 11:43:06,452] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:43:06,503] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.312 seconds
[2023-11-16 11:43:36,841] {processor.py:153} INFO - Started process (PID=3894) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:43:36,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:43:36,843] {logging_mixin.py:115} INFO - [2023-11-16 11:43:36,843] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:43:36,963] {logging_mixin.py:115} INFO - [2023-11-16 11:43:36,962] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:43:37,001] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:43:37,032] {logging_mixin.py:115} INFO - [2023-11-16 11:43:37,032] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:43:37,083] {logging_mixin.py:115} INFO - [2023-11-16 11:43:37,083] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:43:37,138] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.302 seconds
[2023-11-16 11:44:08,019] {processor.py:153} INFO - Started process (PID=3952) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:44:08,021] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:44:08,023] {logging_mixin.py:115} INFO - [2023-11-16 11:44:08,023] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:44:08,118] {logging_mixin.py:115} INFO - [2023-11-16 11:44:08,118] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:44:08,161] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:44:08,189] {logging_mixin.py:115} INFO - [2023-11-16 11:44:08,189] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:44:08,246] {logging_mixin.py:115} INFO - [2023-11-16 11:44:08,246] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:44:08,297] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.282 seconds
[2023-11-16 11:44:38,755] {processor.py:153} INFO - Started process (PID=4010) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:44:38,756] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:44:38,758] {logging_mixin.py:115} INFO - [2023-11-16 11:44:38,758] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:44:38,826] {logging_mixin.py:115} INFO - [2023-11-16 11:44:38,826] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:44:38,859] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:44:38,887] {logging_mixin.py:115} INFO - [2023-11-16 11:44:38,887] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:44:38,935] {logging_mixin.py:115} INFO - [2023-11-16 11:44:38,935] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:44:38,970] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.225 seconds
[2023-11-16 11:45:09,312] {processor.py:153} INFO - Started process (PID=4077) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:45:09,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:45:09,315] {logging_mixin.py:115} INFO - [2023-11-16 11:45:09,315] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:45:09,413] {logging_mixin.py:115} INFO - [2023-11-16 11:45:09,412] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:45:09,448] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:45:09,483] {logging_mixin.py:115} INFO - [2023-11-16 11:45:09,483] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:45:09,531] {logging_mixin.py:115} INFO - [2023-11-16 11:45:09,531] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:45:09,557] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.250 seconds
[2023-11-16 11:45:39,659] {processor.py:153} INFO - Started process (PID=4135) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:45:39,660] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:45:39,662] {logging_mixin.py:115} INFO - [2023-11-16 11:45:39,662] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:45:39,738] {logging_mixin.py:115} INFO - [2023-11-16 11:45:39,738] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:45:39,772] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:45:39,801] {logging_mixin.py:115} INFO - [2023-11-16 11:45:39,801] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:45:39,846] {logging_mixin.py:115} INFO - [2023-11-16 11:45:39,845] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:45:39,883] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.229 seconds
[2023-11-16 11:46:10,628] {processor.py:153} INFO - Started process (PID=4193) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:46:10,630] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:46:10,632] {logging_mixin.py:115} INFO - [2023-11-16 11:46:10,632] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:46:10,737] {logging_mixin.py:115} INFO - [2023-11-16 11:46:10,737] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:46:10,795] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:46:10,830] {logging_mixin.py:115} INFO - [2023-11-16 11:46:10,830] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:46:10,881] {logging_mixin.py:115} INFO - [2023-11-16 11:46:10,880] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:46:10,915] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.294 seconds
[2023-11-16 11:46:41,419] {processor.py:153} INFO - Started process (PID=4251) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:46:41,421] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:46:41,422] {logging_mixin.py:115} INFO - [2023-11-16 11:46:41,422] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:46:41,482] {logging_mixin.py:115} INFO - [2023-11-16 11:46:41,482] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:46:41,527] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:46:41,567] {logging_mixin.py:115} INFO - [2023-11-16 11:46:41,567] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:46:41,621] {logging_mixin.py:115} INFO - [2023-11-16 11:46:41,621] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:46:41,658] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.244 seconds
[2023-11-16 11:47:11,764] {processor.py:153} INFO - Started process (PID=4318) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:47:11,766] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:47:11,768] {logging_mixin.py:115} INFO - [2023-11-16 11:47:11,768] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:47:11,846] {logging_mixin.py:115} INFO - [2023-11-16 11:47:11,846] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:47:11,887] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:47:11,935] {logging_mixin.py:115} INFO - [2023-11-16 11:47:11,935] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:47:11,980] {logging_mixin.py:115} INFO - [2023-11-16 11:47:11,980] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:47:12,004] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.244 seconds
[2023-11-16 11:47:42,103] {processor.py:153} INFO - Started process (PID=4376) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:47:42,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:47:42,107] {logging_mixin.py:115} INFO - [2023-11-16 11:47:42,107] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:47:42,208] {logging_mixin.py:115} INFO - [2023-11-16 11:47:42,207] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:47:42,256] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:47:42,300] {logging_mixin.py:115} INFO - [2023-11-16 11:47:42,300] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:47:42,366] {logging_mixin.py:115} INFO - [2023-11-16 11:47:42,366] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:47:42,405] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.310 seconds
[2023-11-16 11:48:12,972] {processor.py:153} INFO - Started process (PID=4434) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:48:12,975] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:48:12,977] {logging_mixin.py:115} INFO - [2023-11-16 11:48:12,977] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:48:13,087] {logging_mixin.py:115} INFO - [2023-11-16 11:48:13,087] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:48:13,127] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:48:13,163] {logging_mixin.py:115} INFO - [2023-11-16 11:48:13,163] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:48:13,208] {logging_mixin.py:115} INFO - [2023-11-16 11:48:13,208] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:48:13,247] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.281 seconds
[2023-11-16 11:48:43,696] {processor.py:153} INFO - Started process (PID=4492) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:48:43,698] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:48:43,700] {logging_mixin.py:115} INFO - [2023-11-16 11:48:43,700] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:48:43,787] {logging_mixin.py:115} INFO - [2023-11-16 11:48:43,787] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:48:43,828] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:48:43,872] {logging_mixin.py:115} INFO - [2023-11-16 11:48:43,872] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:48:43,939] {logging_mixin.py:115} INFO - [2023-11-16 11:48:43,939] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:48:43,995] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.312 seconds
[2023-11-16 11:49:14,210] {processor.py:153} INFO - Started process (PID=4559) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:49:14,211] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:49:14,213] {logging_mixin.py:115} INFO - [2023-11-16 11:49:14,212] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:49:14,296] {logging_mixin.py:115} INFO - [2023-11-16 11:49:14,296] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:49:14,342] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:49:14,391] {logging_mixin.py:115} INFO - [2023-11-16 11:49:14,390] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:49:14,456] {logging_mixin.py:115} INFO - [2023-11-16 11:49:14,455] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:49:14,514] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.309 seconds
[2023-11-16 11:49:44,662] {processor.py:153} INFO - Started process (PID=4617) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:49:44,664] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:49:44,665] {logging_mixin.py:115} INFO - [2023-11-16 11:49:44,665] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:49:44,731] {logging_mixin.py:115} INFO - [2023-11-16 11:49:44,731] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:49:44,764] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:49:44,796] {logging_mixin.py:115} INFO - [2023-11-16 11:49:44,796] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:49:44,840] {logging_mixin.py:115} INFO - [2023-11-16 11:49:44,839] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:49:44,863] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.206 seconds
[2023-11-16 11:50:14,968] {processor.py:153} INFO - Started process (PID=4675) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:50:14,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:50:14,972] {logging_mixin.py:115} INFO - [2023-11-16 11:50:14,972] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:50:15,088] {logging_mixin.py:115} INFO - [2023-11-16 11:50:15,088] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:50:15,126] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:50:15,157] {logging_mixin.py:115} INFO - [2023-11-16 11:50:15,157] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:50:15,209] {logging_mixin.py:115} INFO - [2023-11-16 11:50:15,209] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:50:15,234] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.277 seconds
[2023-11-16 11:50:45,528] {processor.py:153} INFO - Started process (PID=4740) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:50:45,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:50:45,531] {logging_mixin.py:115} INFO - [2023-11-16 11:50:45,531] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:50:45,609] {logging_mixin.py:115} INFO - [2023-11-16 11:50:45,608] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:50:45,645] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:50:45,690] {logging_mixin.py:115} INFO - [2023-11-16 11:50:45,689] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:50:45,742] {logging_mixin.py:115} INFO - [2023-11-16 11:50:45,742] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:50:45,782] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.258 seconds
[2023-11-16 11:51:16,006] {processor.py:153} INFO - Started process (PID=4800) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:51:16,008] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:51:16,010] {logging_mixin.py:115} INFO - [2023-11-16 11:51:16,010] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:51:16,105] {logging_mixin.py:115} INFO - [2023-11-16 11:51:16,105] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:51:16,142] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:51:16,180] {logging_mixin.py:115} INFO - [2023-11-16 11:51:16,180] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:51:16,229] {logging_mixin.py:115} INFO - [2023-11-16 11:51:16,228] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:51:16,263] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.264 seconds
[2023-11-16 11:51:46,523] {processor.py:153} INFO - Started process (PID=4858) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:51:46,525] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:51:46,526] {logging_mixin.py:115} INFO - [2023-11-16 11:51:46,526] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:51:46,596] {logging_mixin.py:115} INFO - [2023-11-16 11:51:46,596] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:51:46,631] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:51:46,663] {logging_mixin.py:115} INFO - [2023-11-16 11:51:46,663] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:51:46,702] {logging_mixin.py:115} INFO - [2023-11-16 11:51:46,702] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:51:46,737] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 11:52:16,872] {processor.py:153} INFO - Started process (PID=4914) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:52:16,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:52:16,877] {logging_mixin.py:115} INFO - [2023-11-16 11:52:16,877] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:52:16,984] {logging_mixin.py:115} INFO - [2023-11-16 11:52:16,984] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:52:17,034] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:52:17,077] {logging_mixin.py:115} INFO - [2023-11-16 11:52:17,077] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:52:17,147] {logging_mixin.py:115} INFO - [2023-11-16 11:52:17,147] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:52:17,184] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.318 seconds
[2023-11-16 11:52:47,745] {processor.py:153} INFO - Started process (PID=4982) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:52:47,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:52:47,747] {logging_mixin.py:115} INFO - [2023-11-16 11:52:47,747] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:52:47,822] {logging_mixin.py:115} INFO - [2023-11-16 11:52:47,822] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:52:47,855] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:52:47,882] {logging_mixin.py:115} INFO - [2023-11-16 11:52:47,882] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:52:47,925] {logging_mixin.py:115} INFO - [2023-11-16 11:52:47,925] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:52:47,964] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.224 seconds
[2023-11-16 11:53:18,269] {processor.py:153} INFO - Started process (PID=5040) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:53:18,271] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:53:18,273] {logging_mixin.py:115} INFO - [2023-11-16 11:53:18,273] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:53:18,384] {logging_mixin.py:115} INFO - [2023-11-16 11:53:18,384] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:53:18,441] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:53:18,484] {logging_mixin.py:115} INFO - [2023-11-16 11:53:18,483] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:53:18,544] {logging_mixin.py:115} INFO - [2023-11-16 11:53:18,544] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:53:18,577] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.317 seconds
[2023-11-16 11:53:49,195] {processor.py:153} INFO - Started process (PID=5098) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:53:49,197] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:53:49,199] {logging_mixin.py:115} INFO - [2023-11-16 11:53:49,199] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:53:49,279] {logging_mixin.py:115} INFO - [2023-11-16 11:53:49,279] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:53:49,318] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:53:49,346] {logging_mixin.py:115} INFO - [2023-11-16 11:53:49,346] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:53:49,390] {logging_mixin.py:115} INFO - [2023-11-16 11:53:49,390] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:53:49,427] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.240 seconds
[2023-11-16 11:54:19,714] {processor.py:153} INFO - Started process (PID=5165) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:54:19,717] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:54:19,718] {logging_mixin.py:115} INFO - [2023-11-16 11:54:19,718] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:54:19,835] {logging_mixin.py:115} INFO - [2023-11-16 11:54:19,834] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:54:19,875] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:54:19,921] {logging_mixin.py:115} INFO - [2023-11-16 11:54:19,921] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:54:19,978] {logging_mixin.py:115} INFO - [2023-11-16 11:54:19,978] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:54:20,020] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.313 seconds
[2023-11-16 11:54:50,653] {processor.py:153} INFO - Started process (PID=5223) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:54:50,654] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:54:50,655] {logging_mixin.py:115} INFO - [2023-11-16 11:54:50,655] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:54:50,739] {logging_mixin.py:115} INFO - [2023-11-16 11:54:50,738] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:54:50,773] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:54:50,800] {logging_mixin.py:115} INFO - [2023-11-16 11:54:50,800] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:54:50,843] {logging_mixin.py:115} INFO - [2023-11-16 11:54:50,843] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:54:50,878] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.230 seconds
[2023-11-16 11:55:21,290] {processor.py:153} INFO - Started process (PID=5281) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:55:21,292] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:55:21,295] {logging_mixin.py:115} INFO - [2023-11-16 11:55:21,295] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:55:21,412] {logging_mixin.py:115} INFO - [2023-11-16 11:55:21,412] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:55:21,470] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:55:21,521] {logging_mixin.py:115} INFO - [2023-11-16 11:55:21,521] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:55:21,597] {logging_mixin.py:115} INFO - [2023-11-16 11:55:21,597] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:55:21,639] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.357 seconds
[2023-11-16 11:55:52,221] {processor.py:153} INFO - Started process (PID=5339) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:55:52,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:55:52,225] {logging_mixin.py:115} INFO - [2023-11-16 11:55:52,225] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:55:52,322] {logging_mixin.py:115} INFO - [2023-11-16 11:55:52,321] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:55:52,358] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:55:52,403] {logging_mixin.py:115} INFO - [2023-11-16 11:55:52,402] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:55:52,459] {logging_mixin.py:115} INFO - [2023-11-16 11:55:52,458] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:55:52,500] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.289 seconds
[2023-11-16 11:56:23,325] {processor.py:153} INFO - Started process (PID=5405) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:56:23,327] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:56:23,329] {logging_mixin.py:115} INFO - [2023-11-16 11:56:23,329] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:56:23,432] {logging_mixin.py:115} INFO - [2023-11-16 11:56:23,432] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:56:23,470] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:56:23,504] {logging_mixin.py:115} INFO - [2023-11-16 11:56:23,504] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:56:23,571] {logging_mixin.py:115} INFO - [2023-11-16 11:56:23,571] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:56:23,623] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.304 seconds
[2023-11-16 11:56:54,396] {processor.py:153} INFO - Started process (PID=5463) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:56:54,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:56:54,399] {logging_mixin.py:115} INFO - [2023-11-16 11:56:54,399] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:56:54,465] {logging_mixin.py:115} INFO - [2023-11-16 11:56:54,465] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:56:54,496] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:56:54,526] {logging_mixin.py:115} INFO - [2023-11-16 11:56:54,525] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:56:54,579] {logging_mixin.py:115} INFO - [2023-11-16 11:56:54,579] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:56:54,614] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.224 seconds
[2023-11-16 11:57:24,719] {processor.py:153} INFO - Started process (PID=5521) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:57:24,721] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:57:24,723] {logging_mixin.py:115} INFO - [2023-11-16 11:57:24,723] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:57:24,828] {logging_mixin.py:115} INFO - [2023-11-16 11:57:24,827] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:57:24,860] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:57:24,891] {logging_mixin.py:115} INFO - [2023-11-16 11:57:24,890] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:57:24,945] {logging_mixin.py:115} INFO - [2023-11-16 11:57:24,945] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:57:24,993] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.281 seconds
[2023-11-16 11:57:55,479] {processor.py:153} INFO - Started process (PID=5579) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:57:55,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:57:55,483] {logging_mixin.py:115} INFO - [2023-11-16 11:57:55,482] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:57:55,595] {logging_mixin.py:115} INFO - [2023-11-16 11:57:55,594] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:57:55,648] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:57:55,692] {logging_mixin.py:115} INFO - [2023-11-16 11:57:55,692] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:57:55,761] {logging_mixin.py:115} INFO - [2023-11-16 11:57:55,761] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:57:55,810] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.339 seconds
[2023-11-16 11:58:26,000] {processor.py:153} INFO - Started process (PID=5637) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:58:26,002] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:58:26,004] {logging_mixin.py:115} INFO - [2023-11-16 11:58:26,004] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:58:26,078] {logging_mixin.py:115} INFO - [2023-11-16 11:58:26,078] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:58:26,128] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:58:26,183] {logging_mixin.py:115} INFO - [2023-11-16 11:58:26,182] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:58:26,233] {logging_mixin.py:115} INFO - [2023-11-16 11:58:26,233] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:58:26,258] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.262 seconds
[2023-11-16 11:58:56,654] {processor.py:153} INFO - Started process (PID=5705) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:58:56,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:58:56,660] {logging_mixin.py:115} INFO - [2023-11-16 11:58:56,659] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:58:56,775] {logging_mixin.py:115} INFO - [2023-11-16 11:58:56,775] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:58:56,813] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:58:56,852] {logging_mixin.py:115} INFO - [2023-11-16 11:58:56,852] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:58:56,912] {logging_mixin.py:115} INFO - [2023-11-16 11:58:56,912] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:58:56,955] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.311 seconds
[2023-11-16 11:59:27,079] {processor.py:153} INFO - Started process (PID=5763) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:59:27,080] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:59:27,082] {logging_mixin.py:115} INFO - [2023-11-16 11:59:27,082] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:59:27,167] {logging_mixin.py:115} INFO - [2023-11-16 11:59:27,167] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:59:27,208] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:59:27,252] {logging_mixin.py:115} INFO - [2023-11-16 11:59:27,252] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:59:27,316] {logging_mixin.py:115} INFO - [2023-11-16 11:59:27,315] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:59:27,352] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.278 seconds
[2023-11-16 11:59:58,100] {processor.py:153} INFO - Started process (PID=5821) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 11:59:58,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 11:59:58,104] {logging_mixin.py:115} INFO - [2023-11-16 11:59:58,104] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 11:59:58,194] {logging_mixin.py:115} INFO - [2023-11-16 11:59:58,194] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 11:59:58,255] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 11:59:58,298] {logging_mixin.py:115} INFO - [2023-11-16 11:59:58,297] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 11:59:58,359] {logging_mixin.py:115} INFO - [2023-11-16 11:59:58,359] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 11:59:58,396] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.302 seconds
[2023-11-16 12:00:28,841] {processor.py:153} INFO - Started process (PID=5879) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:00:28,843] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:00:28,844] {logging_mixin.py:115} INFO - [2023-11-16 12:00:28,844] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:00:28,919] {logging_mixin.py:115} INFO - [2023-11-16 12:00:28,919] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:00:28,986] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:00:29,040] {logging_mixin.py:115} INFO - [2023-11-16 12:00:29,040] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:00:29,138] {logging_mixin.py:115} INFO - [2023-11-16 12:00:29,137] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:00:29,166] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.331 seconds
[2023-11-16 12:00:59,436] {processor.py:153} INFO - Started process (PID=5946) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:00:59,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:00:59,441] {logging_mixin.py:115} INFO - [2023-11-16 12:00:59,440] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:00:59,529] {logging_mixin.py:115} INFO - [2023-11-16 12:00:59,528] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:00:59,566] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:00:59,600] {logging_mixin.py:115} INFO - [2023-11-16 12:00:59,600] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:00:59,649] {logging_mixin.py:115} INFO - [2023-11-16 12:00:59,649] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:00:59,681] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.250 seconds
[2023-11-16 12:01:30,126] {processor.py:153} INFO - Started process (PID=6004) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:01:30,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:01:30,142] {logging_mixin.py:115} INFO - [2023-11-16 12:01:30,141] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:01:30,265] {logging_mixin.py:115} INFO - [2023-11-16 12:01:30,264] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:01:30,305] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:01:30,339] {logging_mixin.py:115} INFO - [2023-11-16 12:01:30,338] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:01:30,397] {logging_mixin.py:115} INFO - [2023-11-16 12:01:30,397] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:01:30,440] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.322 seconds
[2023-11-16 12:02:00,760] {processor.py:153} INFO - Started process (PID=6062) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:02:00,763] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:02:00,765] {logging_mixin.py:115} INFO - [2023-11-16 12:02:00,764] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:02:00,855] {logging_mixin.py:115} INFO - [2023-11-16 12:02:00,855] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:02:00,894] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:02:00,931] {logging_mixin.py:115} INFO - [2023-11-16 12:02:00,931] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:02:00,989] {logging_mixin.py:115} INFO - [2023-11-16 12:02:00,989] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:02:01,032] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.279 seconds
[2023-11-16 12:02:31,790] {processor.py:153} INFO - Started process (PID=6120) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:02:31,791] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:02:31,793] {logging_mixin.py:115} INFO - [2023-11-16 12:02:31,793] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:02:31,913] {logging_mixin.py:115} INFO - [2023-11-16 12:02:31,913] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:02:31,957] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:02:31,995] {logging_mixin.py:115} INFO - [2023-11-16 12:02:31,994] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:02:32,062] {logging_mixin.py:115} INFO - [2023-11-16 12:02:32,061] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:02:32,114] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.332 seconds
[2023-11-16 12:03:02,303] {processor.py:153} INFO - Started process (PID=6187) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:03:02,305] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:03:02,307] {logging_mixin.py:115} INFO - [2023-11-16 12:03:02,307] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:03:02,422] {logging_mixin.py:115} INFO - [2023-11-16 12:03:02,422] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:03:02,463] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:03:02,501] {logging_mixin.py:115} INFO - [2023-11-16 12:03:02,501] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:03:02,566] {logging_mixin.py:115} INFO - [2023-11-16 12:03:02,566] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:03:02,614] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.319 seconds
[2023-11-16 12:03:32,898] {processor.py:153} INFO - Started process (PID=6245) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:03:32,900] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:03:32,903] {logging_mixin.py:115} INFO - [2023-11-16 12:03:32,903] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:03:33,018] {logging_mixin.py:115} INFO - [2023-11-16 12:03:33,017] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:03:33,074] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:03:33,105] {logging_mixin.py:115} INFO - [2023-11-16 12:03:33,105] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:03:33,153] {logging_mixin.py:115} INFO - [2023-11-16 12:03:33,153] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:03:33,195] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.306 seconds
[2023-11-16 12:04:03,391] {processor.py:153} INFO - Started process (PID=6303) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:04:03,393] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:04:03,395] {logging_mixin.py:115} INFO - [2023-11-16 12:04:03,395] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:04:03,503] {logging_mixin.py:115} INFO - [2023-11-16 12:04:03,503] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:04:03,544] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:04:03,579] {logging_mixin.py:115} INFO - [2023-11-16 12:04:03,579] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:04:03,631] {logging_mixin.py:115} INFO - [2023-11-16 12:04:03,631] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:04:03,655] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.271 seconds
[2023-11-16 12:04:33,785] {processor.py:153} INFO - Started process (PID=6361) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:04:33,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:04:33,788] {logging_mixin.py:115} INFO - [2023-11-16 12:04:33,788] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:04:33,870] {logging_mixin.py:115} INFO - [2023-11-16 12:04:33,869] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:04:33,911] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:04:33,950] {logging_mixin.py:115} INFO - [2023-11-16 12:04:33,950] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:04:34,003] {logging_mixin.py:115} INFO - [2023-11-16 12:04:34,002] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:04:34,046] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.266 seconds
[2023-11-16 12:05:04,491] {processor.py:153} INFO - Started process (PID=6419) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:05:04,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:05:04,494] {logging_mixin.py:115} INFO - [2023-11-16 12:05:04,494] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:05:04,562] {logging_mixin.py:115} INFO - [2023-11-16 12:05:04,562] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:05:04,592] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:05:04,620] {logging_mixin.py:115} INFO - [2023-11-16 12:05:04,620] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:05:04,672] {logging_mixin.py:115} INFO - [2023-11-16 12:05:04,672] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:05:04,712] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.226 seconds
[2023-11-16 12:05:34,814] {processor.py:153} INFO - Started process (PID=6486) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:05:34,816] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:05:34,818] {logging_mixin.py:115} INFO - [2023-11-16 12:05:34,817] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:05:34,900] {logging_mixin.py:115} INFO - [2023-11-16 12:05:34,900] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:05:34,945] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:05:34,982] {logging_mixin.py:115} INFO - [2023-11-16 12:05:34,982] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:05:35,029] {logging_mixin.py:115} INFO - [2023-11-16 12:05:35,028] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:05:35,068] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.259 seconds
[2023-11-16 12:06:05,646] {processor.py:153} INFO - Started process (PID=6545) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:06:05,648] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:06:05,650] {logging_mixin.py:115} INFO - [2023-11-16 12:06:05,649] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:06:05,721] {logging_mixin.py:115} INFO - [2023-11-16 12:06:05,721] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:06:05,756] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:06:05,782] {logging_mixin.py:115} INFO - [2023-11-16 12:06:05,782] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:06:05,847] {logging_mixin.py:115} INFO - [2023-11-16 12:06:05,847] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:06:05,888] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.250 seconds
[2023-11-16 12:06:36,748] {processor.py:153} INFO - Started process (PID=6603) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:06:36,750] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:06:36,753] {logging_mixin.py:115} INFO - [2023-11-16 12:06:36,752] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:06:36,888] {logging_mixin.py:115} INFO - [2023-11-16 12:06:36,888] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:06:36,931] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:06:36,969] {logging_mixin.py:115} INFO - [2023-11-16 12:06:36,969] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:06:37,035] {logging_mixin.py:115} INFO - [2023-11-16 12:06:37,035] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:06:37,080] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.338 seconds
[2023-11-16 12:07:07,627] {processor.py:153} INFO - Started process (PID=6670) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:07:07,629] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:07:07,630] {logging_mixin.py:115} INFO - [2023-11-16 12:07:07,630] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:07:07,709] {logging_mixin.py:115} INFO - [2023-11-16 12:07:07,709] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:07:07,742] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:07:07,772] {logging_mixin.py:115} INFO - [2023-11-16 12:07:07,771] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:07:07,815] {logging_mixin.py:115} INFO - [2023-11-16 12:07:07,814] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:07:07,860] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.239 seconds
[2023-11-16 12:07:37,991] {processor.py:153} INFO - Started process (PID=6728) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:07:37,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:07:37,995] {logging_mixin.py:115} INFO - [2023-11-16 12:07:37,995] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:07:38,075] {logging_mixin.py:115} INFO - [2023-11-16 12:07:38,074] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:07:38,117] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:07:38,146] {logging_mixin.py:115} INFO - [2023-11-16 12:07:38,146] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:07:38,192] {logging_mixin.py:115} INFO - [2023-11-16 12:07:38,192] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:07:38,228] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.244 seconds
[2023-11-16 12:08:08,770] {processor.py:153} INFO - Started process (PID=6786) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:08:08,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:08:08,773] {logging_mixin.py:115} INFO - [2023-11-16 12:08:08,773] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:08:08,862] {logging_mixin.py:115} INFO - [2023-11-16 12:08:08,862] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:08:08,907] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:08:08,935] {logging_mixin.py:115} INFO - [2023-11-16 12:08:08,934] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:08:08,977] {logging_mixin.py:115} INFO - [2023-11-16 12:08:08,977] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:08:09,005] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.239 seconds
[2023-11-16 12:08:39,340] {processor.py:153} INFO - Started process (PID=6852) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:08:39,341] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:08:39,342] {logging_mixin.py:115} INFO - [2023-11-16 12:08:39,342] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:08:39,431] {logging_mixin.py:115} INFO - [2023-11-16 12:08:39,431] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:08:39,464] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:08:39,497] {logging_mixin.py:115} INFO - [2023-11-16 12:08:39,497] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:08:39,552] {logging_mixin.py:115} INFO - [2023-11-16 12:08:39,552] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:08:39,592] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.258 seconds
[2023-11-16 12:09:10,611] {processor.py:153} INFO - Started process (PID=6910) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:09:10,613] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:09:10,615] {logging_mixin.py:115} INFO - [2023-11-16 12:09:10,615] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:09:10,726] {logging_mixin.py:115} INFO - [2023-11-16 12:09:10,726] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:09:10,777] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:09:10,816] {logging_mixin.py:115} INFO - [2023-11-16 12:09:10,815] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:09:10,886] {logging_mixin.py:115} INFO - [2023-11-16 12:09:10,886] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:09:10,933] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.329 seconds
[2023-11-16 12:09:41,131] {processor.py:153} INFO - Started process (PID=6968) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:09:41,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:09:41,135] {logging_mixin.py:115} INFO - [2023-11-16 12:09:41,135] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:09:41,227] {logging_mixin.py:115} INFO - [2023-11-16 12:09:41,227] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:09:41,271] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:09:41,309] {logging_mixin.py:115} INFO - [2023-11-16 12:09:41,309] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:09:41,363] {logging_mixin.py:115} INFO - [2023-11-16 12:09:41,363] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:09:41,392] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.273 seconds
[2023-11-16 12:10:11,616] {processor.py:153} INFO - Started process (PID=7033) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:10:11,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:10:11,624] {logging_mixin.py:115} INFO - [2023-11-16 12:10:11,623] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:10:11,708] {logging_mixin.py:115} INFO - [2023-11-16 12:10:11,708] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:10:11,742] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:10:11,779] {logging_mixin.py:115} INFO - [2023-11-16 12:10:11,778] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:10:11,857] {logging_mixin.py:115} INFO - [2023-11-16 12:10:11,856] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:10:11,903] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.295 seconds
[2023-11-16 12:10:42,036] {processor.py:153} INFO - Started process (PID=7093) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:10:42,037] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:10:42,039] {logging_mixin.py:115} INFO - [2023-11-16 12:10:42,039] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:10:42,123] {logging_mixin.py:115} INFO - [2023-11-16 12:10:42,123] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:10:42,159] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:10:42,197] {logging_mixin.py:115} INFO - [2023-11-16 12:10:42,197] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:10:42,256] {logging_mixin.py:115} INFO - [2023-11-16 12:10:42,256] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:10:42,313] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.282 seconds
[2023-11-16 12:11:12,445] {processor.py:153} INFO - Started process (PID=7151) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:11:12,447] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:11:12,448] {logging_mixin.py:115} INFO - [2023-11-16 12:11:12,448] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:11:12,520] {logging_mixin.py:115} INFO - [2023-11-16 12:11:12,520] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:11:12,571] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:11:12,608] {logging_mixin.py:115} INFO - [2023-11-16 12:11:12,609] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:11:12,664] {logging_mixin.py:115} INFO - [2023-11-16 12:11:12,663] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:11:12,701] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.265 seconds
[2023-11-16 12:11:43,436] {processor.py:153} INFO - Started process (PID=7209) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:11:43,438] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:11:43,440] {logging_mixin.py:115} INFO - [2023-11-16 12:11:43,440] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:11:43,578] {logging_mixin.py:115} INFO - [2023-11-16 12:11:43,578] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:11:43,615] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:11:43,646] {logging_mixin.py:115} INFO - [2023-11-16 12:11:43,646] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:11:43,686] {logging_mixin.py:115} INFO - [2023-11-16 12:11:43,686] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:11:43,722] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.295 seconds
[2023-11-16 12:12:14,094] {processor.py:153} INFO - Started process (PID=7267) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:12:14,096] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:12:14,098] {logging_mixin.py:115} INFO - [2023-11-16 12:12:14,098] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:12:14,218] {logging_mixin.py:115} INFO - [2023-11-16 12:12:14,218] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:12:14,265] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:12:14,302] {logging_mixin.py:115} INFO - [2023-11-16 12:12:14,302] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:12:14,360] {logging_mixin.py:115} INFO - [2023-11-16 12:12:14,359] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:12:14,403] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.319 seconds
[2023-11-16 12:12:45,271] {processor.py:153} INFO - Started process (PID=7334) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:12:45,272] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:12:45,274] {logging_mixin.py:115} INFO - [2023-11-16 12:12:45,274] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:12:45,352] {logging_mixin.py:115} INFO - [2023-11-16 12:12:45,352] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:12:45,397] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:12:45,426] {logging_mixin.py:115} INFO - [2023-11-16 12:12:45,426] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:12:45,474] {logging_mixin.py:115} INFO - [2023-11-16 12:12:45,474] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:12:45,514] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.248 seconds
[2023-11-16 12:13:16,056] {processor.py:153} INFO - Started process (PID=7392) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:13:16,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:13:16,059] {logging_mixin.py:115} INFO - [2023-11-16 12:13:16,059] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:13:16,129] {logging_mixin.py:115} INFO - [2023-11-16 12:13:16,129] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:13:16,164] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:13:16,188] {logging_mixin.py:115} INFO - [2023-11-16 12:13:16,188] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:13:16,233] {logging_mixin.py:115} INFO - [2023-11-16 12:13:16,233] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:13:16,258] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.208 seconds
[2023-11-16 12:13:46,595] {processor.py:153} INFO - Started process (PID=7448) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:13:46,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:13:46,601] {logging_mixin.py:115} INFO - [2023-11-16 12:13:46,601] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:13:46,701] {logging_mixin.py:115} INFO - [2023-11-16 12:13:46,701] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:13:46,736] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:13:46,770] {logging_mixin.py:115} INFO - [2023-11-16 12:13:46,770] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:13:46,813] {logging_mixin.py:115} INFO - [2023-11-16 12:13:46,813] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:13:46,845] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.257 seconds
[2023-11-16 12:14:17,811] {processor.py:153} INFO - Started process (PID=7515) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:14:17,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:14:17,815] {logging_mixin.py:115} INFO - [2023-11-16 12:14:17,815] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:14:17,896] {logging_mixin.py:115} INFO - [2023-11-16 12:14:17,896] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:14:17,930] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:14:17,957] {logging_mixin.py:115} INFO - [2023-11-16 12:14:17,957] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:14:18,005] {logging_mixin.py:115} INFO - [2023-11-16 12:14:18,005] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:14:18,033] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.231 seconds
[2023-11-16 12:14:48,342] {processor.py:153} INFO - Started process (PID=7573) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:14:48,343] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:14:48,345] {logging_mixin.py:115} INFO - [2023-11-16 12:14:48,345] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:14:48,421] {logging_mixin.py:115} INFO - [2023-11-16 12:14:48,421] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:14:48,462] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:14:48,494] {logging_mixin.py:115} INFO - [2023-11-16 12:14:48,493] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:14:48,545] {logging_mixin.py:115} INFO - [2023-11-16 12:14:48,545] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:14:48,576] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.239 seconds
[2023-11-16 12:15:18,835] {processor.py:153} INFO - Started process (PID=7631) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:15:18,837] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:15:18,840] {logging_mixin.py:115} INFO - [2023-11-16 12:15:18,840] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:15:18,927] {logging_mixin.py:115} INFO - [2023-11-16 12:15:18,927] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:15:18,969] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:15:19,014] {logging_mixin.py:115} INFO - [2023-11-16 12:15:19,014] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:15:19,066] {logging_mixin.py:115} INFO - [2023-11-16 12:15:19,066] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:15:19,105] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.280 seconds
[2023-11-16 12:15:49,360] {processor.py:153} INFO - Started process (PID=7698) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:15:49,362] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:15:49,364] {logging_mixin.py:115} INFO - [2023-11-16 12:15:49,364] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:15:49,445] {logging_mixin.py:115} INFO - [2023-11-16 12:15:49,445] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:15:49,500] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:15:49,527] {logging_mixin.py:115} INFO - [2023-11-16 12:15:49,526] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:15:49,576] {logging_mixin.py:115} INFO - [2023-11-16 12:15:49,576] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:15:49,613] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.258 seconds
[2023-11-16 12:16:19,836] {processor.py:153} INFO - Started process (PID=7756) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:16:19,837] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:16:19,840] {logging_mixin.py:115} INFO - [2023-11-16 12:16:19,839] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:16:19,917] {logging_mixin.py:115} INFO - [2023-11-16 12:16:19,917] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:16:19,949] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:16:19,975] {logging_mixin.py:115} INFO - [2023-11-16 12:16:19,975] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:16:20,021] {logging_mixin.py:115} INFO - [2023-11-16 12:16:20,021] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:16:20,047] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.219 seconds
[2023-11-16 12:16:50,767] {processor.py:153} INFO - Started process (PID=7814) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:16:50,769] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:16:50,771] {logging_mixin.py:115} INFO - [2023-11-16 12:16:50,770] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:16:50,901] {logging_mixin.py:115} INFO - [2023-11-16 12:16:50,901] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:16:50,948] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:16:51,024] {logging_mixin.py:115} INFO - [2023-11-16 12:16:51,024] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:16:51,093] {logging_mixin.py:115} INFO - [2023-11-16 12:16:51,093] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:16:51,124] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.365 seconds
[2023-11-16 12:17:21,218] {processor.py:153} INFO - Started process (PID=7882) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:17:21,220] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:17:21,222] {logging_mixin.py:115} INFO - [2023-11-16 12:17:21,221] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:17:21,322] {logging_mixin.py:115} INFO - [2023-11-16 12:17:21,322] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:17:21,358] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:17:21,388] {logging_mixin.py:115} INFO - [2023-11-16 12:17:21,388] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:17:21,445] {logging_mixin.py:115} INFO - [2023-11-16 12:17:21,445] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:17:21,477] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.264 seconds
[2023-11-16 12:17:52,055] {processor.py:153} INFO - Started process (PID=7940) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:17:52,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:17:52,058] {logging_mixin.py:115} INFO - [2023-11-16 12:17:52,058] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:17:52,126] {logging_mixin.py:115} INFO - [2023-11-16 12:17:52,126] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:17:52,158] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:17:52,183] {logging_mixin.py:115} INFO - [2023-11-16 12:17:52,183] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:17:52,234] {logging_mixin.py:115} INFO - [2023-11-16 12:17:52,234] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:17:52,268] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.217 seconds
[2023-11-16 12:18:22,539] {processor.py:153} INFO - Started process (PID=7998) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:18:22,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:18:22,543] {logging_mixin.py:115} INFO - [2023-11-16 12:18:22,543] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:18:22,625] {logging_mixin.py:115} INFO - [2023-11-16 12:18:22,625] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:18:22,660] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:18:22,698] {logging_mixin.py:115} INFO - [2023-11-16 12:18:22,697] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:18:22,754] {logging_mixin.py:115} INFO - [2023-11-16 12:18:22,753] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:18:22,786] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.255 seconds
[2023-11-16 12:18:53,478] {processor.py:153} INFO - Started process (PID=8056) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:18:53,480] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:18:53,482] {logging_mixin.py:115} INFO - [2023-11-16 12:18:53,482] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:18:53,608] {logging_mixin.py:115} INFO - [2023-11-16 12:18:53,608] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:18:53,649] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:18:53,681] {logging_mixin.py:115} INFO - [2023-11-16 12:18:53,681] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:18:53,746] {logging_mixin.py:115} INFO - [2023-11-16 12:18:53,746] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:18:53,783] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.312 seconds
[2023-11-16 12:19:24,382] {processor.py:153} INFO - Started process (PID=8124) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:19:24,384] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:19:24,386] {logging_mixin.py:115} INFO - [2023-11-16 12:19:24,386] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:19:24,499] {logging_mixin.py:115} INFO - [2023-11-16 12:19:24,499] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:19:24,539] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:19:24,572] {logging_mixin.py:115} INFO - [2023-11-16 12:19:24,572] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:19:24,639] {logging_mixin.py:115} INFO - [2023-11-16 12:19:24,639] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:19:24,679] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.305 seconds
[2023-11-16 12:19:55,103] {processor.py:153} INFO - Started process (PID=8182) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:19:55,105] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:19:55,106] {logging_mixin.py:115} INFO - [2023-11-16 12:19:55,106] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:19:55,205] {logging_mixin.py:115} INFO - [2023-11-16 12:19:55,205] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:19:55,243] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:19:55,277] {logging_mixin.py:115} INFO - [2023-11-16 12:19:55,276] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:19:55,329] {logging_mixin.py:115} INFO - [2023-11-16 12:19:55,329] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:19:55,362] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.266 seconds
[2023-11-16 12:20:26,241] {processor.py:153} INFO - Started process (PID=8240) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:20:26,242] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:20:26,244] {logging_mixin.py:115} INFO - [2023-11-16 12:20:26,244] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:20:26,324] {logging_mixin.py:115} INFO - [2023-11-16 12:20:26,324] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:20:26,357] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:20:26,389] {logging_mixin.py:115} INFO - [2023-11-16 12:20:26,388] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:20:26,440] {logging_mixin.py:115} INFO - [2023-11-16 12:20:26,439] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:20:26,473] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.240 seconds
[2023-11-16 12:20:57,004] {processor.py:153} INFO - Started process (PID=8308) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:20:57,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:20:57,008] {logging_mixin.py:115} INFO - [2023-11-16 12:20:57,008] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:20:57,101] {logging_mixin.py:115} INFO - [2023-11-16 12:20:57,101] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:20:57,140] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:20:57,182] {logging_mixin.py:115} INFO - [2023-11-16 12:20:57,181] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:20:57,238] {logging_mixin.py:115} INFO - [2023-11-16 12:20:57,238] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:20:57,272] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.280 seconds
[2023-11-16 12:21:27,513] {processor.py:153} INFO - Started process (PID=8367) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:21:27,514] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:21:27,517] {logging_mixin.py:115} INFO - [2023-11-16 12:21:27,516] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:21:27,600] {logging_mixin.py:115} INFO - [2023-11-16 12:21:27,600] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:21:27,632] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:21:27,659] {logging_mixin.py:115} INFO - [2023-11-16 12:21:27,658] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:21:27,699] {logging_mixin.py:115} INFO - [2023-11-16 12:21:27,699] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:21:27,730] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.224 seconds
[2023-11-16 12:21:58,330] {processor.py:153} INFO - Started process (PID=8425) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:21:58,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:21:58,334] {logging_mixin.py:115} INFO - [2023-11-16 12:21:58,334] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:21:58,433] {logging_mixin.py:115} INFO - [2023-11-16 12:21:58,433] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:21:58,472] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:21:58,507] {logging_mixin.py:115} INFO - [2023-11-16 12:21:58,507] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:21:58,557] {logging_mixin.py:115} INFO - [2023-11-16 12:21:58,557] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:21:58,586] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.261 seconds
[2023-11-16 12:22:28,727] {processor.py:153} INFO - Started process (PID=8483) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:22:28,729] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:22:28,730] {logging_mixin.py:115} INFO - [2023-11-16 12:22:28,730] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:22:28,847] {logging_mixin.py:115} INFO - [2023-11-16 12:22:28,847] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:22:28,883] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:22:28,923] {logging_mixin.py:115} INFO - [2023-11-16 12:22:28,923] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:22:29,014] {logging_mixin.py:115} INFO - [2023-11-16 12:22:29,014] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:22:29,050] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.331 seconds
[2023-11-16 12:22:59,465] {processor.py:153} INFO - Started process (PID=8551) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:22:59,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:22:59,468] {logging_mixin.py:115} INFO - [2023-11-16 12:22:59,468] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:22:59,574] {logging_mixin.py:115} INFO - [2023-11-16 12:22:59,573] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:22:59,611] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:22:59,644] {logging_mixin.py:115} INFO - [2023-11-16 12:22:59,644] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:22:59,688] {logging_mixin.py:115} INFO - [2023-11-16 12:22:59,688] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:22:59,716] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.255 seconds
[2023-11-16 12:23:29,968] {processor.py:153} INFO - Started process (PID=8610) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:23:29,970] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:23:29,971] {logging_mixin.py:115} INFO - [2023-11-16 12:23:29,971] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:23:30,043] {logging_mixin.py:115} INFO - [2023-11-16 12:23:30,043] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:23:30,076] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:23:30,106] {logging_mixin.py:115} INFO - [2023-11-16 12:23:30,105] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:23:30,154] {logging_mixin.py:115} INFO - [2023-11-16 12:23:30,153] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:23:30,187] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.223 seconds
[2023-11-16 12:24:00,379] {processor.py:153} INFO - Started process (PID=8668) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:24:00,381] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:24:00,384] {logging_mixin.py:115} INFO - [2023-11-16 12:24:00,383] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:24:00,466] {logging_mixin.py:115} INFO - [2023-11-16 12:24:00,465] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:24:00,504] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:24:00,536] {logging_mixin.py:115} INFO - [2023-11-16 12:24:00,535] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:24:00,583] {logging_mixin.py:115} INFO - [2023-11-16 12:24:00,582] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:24:00,614] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.244 seconds
[2023-11-16 12:24:31,100] {processor.py:153} INFO - Started process (PID=8727) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:24:31,102] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:24:31,104] {logging_mixin.py:115} INFO - [2023-11-16 12:24:31,104] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:24:31,234] {logging_mixin.py:115} INFO - [2023-11-16 12:24:31,234] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:24:31,281] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:24:31,333] {logging_mixin.py:115} INFO - [2023-11-16 12:24:31,332] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:24:31,402] {logging_mixin.py:115} INFO - [2023-11-16 12:24:31,402] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:24:31,437] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.347 seconds
[2023-11-16 12:25:01,736] {processor.py:153} INFO - Started process (PID=8795) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:25:01,738] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:25:01,741] {logging_mixin.py:115} INFO - [2023-11-16 12:25:01,740] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:25:01,918] {logging_mixin.py:115} INFO - [2023-11-16 12:25:01,917] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:25:01,990] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:25:02,023] {logging_mixin.py:115} INFO - [2023-11-16 12:25:02,023] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:25:02,106] {logging_mixin.py:115} INFO - [2023-11-16 12:25:02,106] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:25:02,145] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.418 seconds
[2023-11-16 12:25:32,432] {processor.py:153} INFO - Started process (PID=8853) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:25:32,433] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:25:32,434] {logging_mixin.py:115} INFO - [2023-11-16 12:25:32,434] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:25:32,525] {logging_mixin.py:115} INFO - [2023-11-16 12:25:32,525] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:25:32,572] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:25:32,611] {logging_mixin.py:115} INFO - [2023-11-16 12:25:32,611] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:25:32,667] {logging_mixin.py:115} INFO - [2023-11-16 12:25:32,667] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:25:32,699] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.272 seconds
[2023-11-16 12:26:03,116] {processor.py:153} INFO - Started process (PID=8911) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:26:03,118] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:26:03,121] {logging_mixin.py:115} INFO - [2023-11-16 12:26:03,120] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:26:03,240] {logging_mixin.py:115} INFO - [2023-11-16 12:26:03,240] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:26:03,306] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:26:03,355] {logging_mixin.py:115} INFO - [2023-11-16 12:26:03,355] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:26:03,425] {logging_mixin.py:115} INFO - [2023-11-16 12:26:03,425] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:26:03,478] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.372 seconds
[2023-11-16 12:26:33,941] {processor.py:153} INFO - Started process (PID=8976) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:26:33,942] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:26:33,944] {logging_mixin.py:115} INFO - [2023-11-16 12:26:33,944] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:26:34,019] {logging_mixin.py:115} INFO - [2023-11-16 12:26:34,018] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:26:34,054] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:26:34,091] {logging_mixin.py:115} INFO - [2023-11-16 12:26:34,091] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:26:34,149] {logging_mixin.py:115} INFO - [2023-11-16 12:26:34,148] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:26:34,186] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.250 seconds
[2023-11-16 12:27:04,276] {processor.py:153} INFO - Started process (PID=9036) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:27:04,287] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:27:04,289] {logging_mixin.py:115} INFO - [2023-11-16 12:27:04,289] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:27:04,378] {logging_mixin.py:115} INFO - [2023-11-16 12:27:04,377] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:27:04,413] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:27:04,453] {logging_mixin.py:115} INFO - [2023-11-16 12:27:04,453] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:27:04,495] {logging_mixin.py:115} INFO - [2023-11-16 12:27:04,495] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:27:04,523] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.255 seconds
[2023-11-16 12:27:35,171] {processor.py:153} INFO - Started process (PID=9094) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:27:35,172] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:27:35,174] {logging_mixin.py:115} INFO - [2023-11-16 12:27:35,174] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:27:35,254] {logging_mixin.py:115} INFO - [2023-11-16 12:27:35,253] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:27:35,287] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:27:35,319] {logging_mixin.py:115} INFO - [2023-11-16 12:27:35,319] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:27:35,372] {logging_mixin.py:115} INFO - [2023-11-16 12:27:35,372] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:27:35,407] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.244 seconds
[2023-11-16 12:28:05,601] {processor.py:153} INFO - Started process (PID=9152) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:28:05,605] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:28:05,607] {logging_mixin.py:115} INFO - [2023-11-16 12:28:05,607] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:28:05,688] {logging_mixin.py:115} INFO - [2023-11-16 12:28:05,688] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:28:05,721] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:28:05,747] {logging_mixin.py:115} INFO - [2023-11-16 12:28:05,746] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:28:05,789] {logging_mixin.py:115} INFO - [2023-11-16 12:28:05,789] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:28:05,822] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.226 seconds
[2023-11-16 12:28:36,043] {processor.py:153} INFO - Started process (PID=9219) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:28:36,045] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:28:36,047] {logging_mixin.py:115} INFO - [2023-11-16 12:28:36,046] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:28:36,161] {logging_mixin.py:115} INFO - [2023-11-16 12:28:36,161] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:28:36,198] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:28:36,234] {logging_mixin.py:115} INFO - [2023-11-16 12:28:36,234] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:28:36,293] {logging_mixin.py:115} INFO - [2023-11-16 12:28:36,293] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:28:36,332] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.297 seconds
[2023-11-16 12:29:06,813] {processor.py:153} INFO - Started process (PID=9277) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:29:06,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:29:06,817] {logging_mixin.py:115} INFO - [2023-11-16 12:29:06,817] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:29:06,957] {logging_mixin.py:115} INFO - [2023-11-16 12:29:06,956] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:29:07,014] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:29:07,050] {logging_mixin.py:115} INFO - [2023-11-16 12:29:07,049] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:29:07,110] {logging_mixin.py:115} INFO - [2023-11-16 12:29:07,110] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:29:07,150] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.349 seconds
[2023-11-16 12:29:37,279] {processor.py:153} INFO - Started process (PID=9335) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:29:37,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:29:37,283] {logging_mixin.py:115} INFO - [2023-11-16 12:29:37,282] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:29:37,380] {logging_mixin.py:115} INFO - [2023-11-16 12:29:37,380] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:29:37,417] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:29:37,448] {logging_mixin.py:115} INFO - [2023-11-16 12:29:37,448] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:29:37,493] {logging_mixin.py:115} INFO - [2023-11-16 12:29:37,492] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:29:37,522] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.250 seconds
[2023-11-16 12:30:08,330] {processor.py:153} INFO - Started process (PID=9393) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:30:08,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:30:08,335] {logging_mixin.py:115} INFO - [2023-11-16 12:30:08,334] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:30:08,463] {logging_mixin.py:115} INFO - [2023-11-16 12:30:08,463] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:30:08,516] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:30:08,557] {logging_mixin.py:115} INFO - [2023-11-16 12:30:08,556] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:30:08,616] {logging_mixin.py:115} INFO - [2023-11-16 12:30:08,615] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:30:08,666] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.340 seconds
[2023-11-16 12:30:39,458] {processor.py:153} INFO - Started process (PID=9460) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:30:39,461] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:30:39,463] {logging_mixin.py:115} INFO - [2023-11-16 12:30:39,463] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:30:39,577] {logging_mixin.py:115} INFO - [2023-11-16 12:30:39,577] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:30:39,623] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:30:39,658] {logging_mixin.py:115} INFO - [2023-11-16 12:30:39,658] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:30:39,714] {logging_mixin.py:115} INFO - [2023-11-16 12:30:39,714] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:30:39,756] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.305 seconds
[2023-11-16 12:31:10,349] {processor.py:153} INFO - Started process (PID=9518) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:31:10,351] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:31:10,354] {logging_mixin.py:115} INFO - [2023-11-16 12:31:10,354] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:31:10,462] {logging_mixin.py:115} INFO - [2023-11-16 12:31:10,462] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:31:10,508] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:31:10,539] {logging_mixin.py:115} INFO - [2023-11-16 12:31:10,539] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:31:10,596] {logging_mixin.py:115} INFO - [2023-11-16 12:31:10,595] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:31:10,637] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.296 seconds
[2023-11-16 12:31:41,171] {processor.py:153} INFO - Started process (PID=9577) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:31:41,173] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:31:41,175] {logging_mixin.py:115} INFO - [2023-11-16 12:31:41,174] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:31:41,256] {logging_mixin.py:115} INFO - [2023-11-16 12:31:41,256] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:31:41,289] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:31:41,324] {logging_mixin.py:115} INFO - [2023-11-16 12:31:41,324] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:31:41,374] {logging_mixin.py:115} INFO - [2023-11-16 12:31:41,374] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:31:41,409] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.243 seconds
[2023-11-16 12:32:11,679] {processor.py:153} INFO - Started process (PID=9644) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:32:11,682] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:32:11,688] {logging_mixin.py:115} INFO - [2023-11-16 12:32:11,688] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:32:11,866] {logging_mixin.py:115} INFO - [2023-11-16 12:32:11,866] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:32:11,912] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:32:11,944] {logging_mixin.py:115} INFO - [2023-11-16 12:32:11,944] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:32:12,009] {logging_mixin.py:115} INFO - [2023-11-16 12:32:12,009] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:32:12,046] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.377 seconds
[2023-11-16 12:32:43,056] {processor.py:153} INFO - Started process (PID=9702) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:32:43,057] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:32:43,059] {logging_mixin.py:115} INFO - [2023-11-16 12:32:43,059] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:32:43,154] {logging_mixin.py:115} INFO - [2023-11-16 12:32:43,154] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:32:43,194] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:32:43,224] {logging_mixin.py:115} INFO - [2023-11-16 12:32:43,224] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:32:43,280] {logging_mixin.py:115} INFO - [2023-11-16 12:32:43,280] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:32:43,315] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.264 seconds
[2023-11-16 12:33:13,823] {processor.py:153} INFO - Started process (PID=9760) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:33:13,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:33:13,830] {logging_mixin.py:115} INFO - [2023-11-16 12:33:13,830] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:33:13,915] {logging_mixin.py:115} INFO - [2023-11-16 12:33:13,915] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:33:13,949] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:33:13,981] {logging_mixin.py:115} INFO - [2023-11-16 12:33:13,981] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:33:14,037] {logging_mixin.py:115} INFO - [2023-11-16 12:33:14,037] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:33:14,070] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.269 seconds
[2023-11-16 12:33:44,811] {processor.py:153} INFO - Started process (PID=9819) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:33:44,813] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:33:44,815] {logging_mixin.py:115} INFO - [2023-11-16 12:33:44,815] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:33:44,904] {logging_mixin.py:115} INFO - [2023-11-16 12:33:44,904] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:33:44,935] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:33:44,972] {logging_mixin.py:115} INFO - [2023-11-16 12:33:44,972] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:33:45,016] {logging_mixin.py:115} INFO - [2023-11-16 12:33:45,016] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:33:45,048] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.245 seconds
[2023-11-16 12:34:15,174] {processor.py:153} INFO - Started process (PID=9886) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:34:15,176] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:34:15,177] {logging_mixin.py:115} INFO - [2023-11-16 12:34:15,177] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:34:15,276] {logging_mixin.py:115} INFO - [2023-11-16 12:34:15,276] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:34:15,354] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:34:15,386] {logging_mixin.py:115} INFO - [2023-11-16 12:34:15,386] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:34:15,437] {logging_mixin.py:115} INFO - [2023-11-16 12:34:15,436] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:34:15,467] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.297 seconds
[2023-11-16 12:34:45,773] {processor.py:153} INFO - Started process (PID=9945) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:34:45,775] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:34:45,777] {logging_mixin.py:115} INFO - [2023-11-16 12:34:45,776] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:34:45,857] {logging_mixin.py:115} INFO - [2023-11-16 12:34:45,857] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:34:45,895] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:34:45,930] {logging_mixin.py:115} INFO - [2023-11-16 12:34:45,930] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:34:45,984] {logging_mixin.py:115} INFO - [2023-11-16 12:34:45,984] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:34:46,012] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.246 seconds
[2023-11-16 12:35:16,151] {processor.py:153} INFO - Started process (PID=10003) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:35:16,152] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:35:16,154] {logging_mixin.py:115} INFO - [2023-11-16 12:35:16,154] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:35:16,233] {logging_mixin.py:115} INFO - [2023-11-16 12:35:16,233] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:35:16,271] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:35:16,301] {logging_mixin.py:115} INFO - [2023-11-16 12:35:16,301] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:35:16,346] {logging_mixin.py:115} INFO - [2023-11-16 12:35:16,345] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:35:16,378] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.232 seconds
[2023-11-16 12:35:46,827] {processor.py:153} INFO - Started process (PID=10070) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:35:46,828] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:35:46,830] {logging_mixin.py:115} INFO - [2023-11-16 12:35:46,830] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:35:46,924] {logging_mixin.py:115} INFO - [2023-11-16 12:35:46,924] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:35:46,961] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:35:47,015] {logging_mixin.py:115} INFO - [2023-11-16 12:35:47,015] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:35:47,092] {logging_mixin.py:115} INFO - [2023-11-16 12:35:47,091] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:35:47,151] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.331 seconds
[2023-11-16 12:36:18,124] {processor.py:153} INFO - Started process (PID=10128) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:36:18,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:36:18,128] {logging_mixin.py:115} INFO - [2023-11-16 12:36:18,128] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:36:18,216] {logging_mixin.py:115} INFO - [2023-11-16 12:36:18,215] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:36:18,252] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:36:18,279] {logging_mixin.py:115} INFO - [2023-11-16 12:36:18,279] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:36:18,324] {logging_mixin.py:115} INFO - [2023-11-16 12:36:18,324] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:36:18,352] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.240 seconds
[2023-11-16 12:36:49,279] {processor.py:153} INFO - Started process (PID=10186) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:36:49,281] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:36:49,283] {logging_mixin.py:115} INFO - [2023-11-16 12:36:49,282] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:36:49,371] {logging_mixin.py:115} INFO - [2023-11-16 12:36:49,371] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:36:49,402] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:36:49,430] {logging_mixin.py:115} INFO - [2023-11-16 12:36:49,430] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:36:49,510] {logging_mixin.py:115} INFO - [2023-11-16 12:36:49,510] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:36:49,546] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.272 seconds
[2023-11-16 12:37:20,507] {processor.py:153} INFO - Started process (PID=10254) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:37:20,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:37:20,509] {logging_mixin.py:115} INFO - [2023-11-16 12:37:20,509] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:37:20,655] {logging_mixin.py:115} INFO - [2023-11-16 12:37:20,655] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:37:20,689] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:37:20,725] {logging_mixin.py:115} INFO - [2023-11-16 12:37:20,725] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:37:20,773] {logging_mixin.py:115} INFO - [2023-11-16 12:37:20,773] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:37:20,797] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.304 seconds
[2023-11-16 12:37:50,949] {processor.py:153} INFO - Started process (PID=10311) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:37:50,951] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:37:50,953] {logging_mixin.py:115} INFO - [2023-11-16 12:37:50,953] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:37:51,026] {logging_mixin.py:115} INFO - [2023-11-16 12:37:51,025] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:37:51,053] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:37:51,079] {logging_mixin.py:115} INFO - [2023-11-16 12:37:51,079] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:37:51,114] {logging_mixin.py:115} INFO - [2023-11-16 12:37:51,114] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:37:51,140] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.200 seconds
[2023-11-16 12:38:21,800] {processor.py:153} INFO - Started process (PID=10369) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:38:21,801] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:38:21,803] {logging_mixin.py:115} INFO - [2023-11-16 12:38:21,803] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:38:21,877] {logging_mixin.py:115} INFO - [2023-11-16 12:38:21,877] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:38:21,907] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:38:21,934] {logging_mixin.py:115} INFO - [2023-11-16 12:38:21,933] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:38:21,978] {logging_mixin.py:115} INFO - [2023-11-16 12:38:21,978] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:38:22,014] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.222 seconds
[2023-11-16 12:38:52,110] {processor.py:153} INFO - Started process (PID=10435) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:38:52,112] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:38:52,115] {logging_mixin.py:115} INFO - [2023-11-16 12:38:52,114] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:38:52,206] {logging_mixin.py:115} INFO - [2023-11-16 12:38:52,206] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:38:52,245] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:38:52,283] {logging_mixin.py:115} INFO - [2023-11-16 12:38:52,283] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:38:52,339] {logging_mixin.py:115} INFO - [2023-11-16 12:38:52,338] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:38:52,379] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.278 seconds
[2023-11-16 12:39:22,781] {processor.py:153} INFO - Started process (PID=10494) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:39:22,783] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:39:22,786] {logging_mixin.py:115} INFO - [2023-11-16 12:39:22,786] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:39:22,880] {logging_mixin.py:115} INFO - [2023-11-16 12:39:22,880] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:39:22,916] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:39:22,950] {logging_mixin.py:115} INFO - [2023-11-16 12:39:22,949] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:39:22,999] {logging_mixin.py:115} INFO - [2023-11-16 12:39:22,998] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:39:23,031] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.256 seconds
[2023-11-16 12:39:53,522] {processor.py:153} INFO - Started process (PID=10552) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:39:53,524] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:39:53,525] {logging_mixin.py:115} INFO - [2023-11-16 12:39:53,525] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:39:53,621] {logging_mixin.py:115} INFO - [2023-11-16 12:39:53,621] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:39:53,659] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:39:53,692] {logging_mixin.py:115} INFO - [2023-11-16 12:39:53,691] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:39:53,747] {logging_mixin.py:115} INFO - [2023-11-16 12:39:53,747] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:39:53,807] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.292 seconds
[2023-11-16 12:40:24,442] {processor.py:153} INFO - Started process (PID=10611) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:40:24,444] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:40:24,445] {logging_mixin.py:115} INFO - [2023-11-16 12:40:24,445] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:40:24,528] {logging_mixin.py:115} INFO - [2023-11-16 12:40:24,528] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:40:24,561] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:40:24,592] {logging_mixin.py:115} INFO - [2023-11-16 12:40:24,591] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:40:24,636] {logging_mixin.py:115} INFO - [2023-11-16 12:40:24,635] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:40:24,666] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.228 seconds
[2023-11-16 12:40:55,134] {processor.py:153} INFO - Started process (PID=10677) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:40:55,136] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:40:55,137] {logging_mixin.py:115} INFO - [2023-11-16 12:40:55,137] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:40:55,225] {logging_mixin.py:115} INFO - [2023-11-16 12:40:55,225] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:40:55,257] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:40:55,287] {logging_mixin.py:115} INFO - [2023-11-16 12:40:55,287] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:40:55,353] {logging_mixin.py:115} INFO - [2023-11-16 12:40:55,352] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:40:55,392] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.264 seconds
[2023-11-16 12:41:25,785] {processor.py:153} INFO - Started process (PID=10735) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:41:25,786] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:41:25,787] {logging_mixin.py:115} INFO - [2023-11-16 12:41:25,787] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:41:25,902] {logging_mixin.py:115} INFO - [2023-11-16 12:41:25,902] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:41:25,934] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:41:25,963] {logging_mixin.py:115} INFO - [2023-11-16 12:41:25,963] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:41:26,008] {logging_mixin.py:115} INFO - [2023-11-16 12:41:26,008] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:41:26,037] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.257 seconds
[2023-11-16 12:41:56,772] {processor.py:153} INFO - Started process (PID=10793) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:41:56,773] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:41:56,775] {logging_mixin.py:115} INFO - [2023-11-16 12:41:56,775] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:41:56,848] {logging_mixin.py:115} INFO - [2023-11-16 12:41:56,848] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:41:56,894] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:41:56,924] {logging_mixin.py:115} INFO - [2023-11-16 12:41:56,924] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:41:56,986] {logging_mixin.py:115} INFO - [2023-11-16 12:41:56,986] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:41:57,019] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.253 seconds
[2023-11-16 12:42:27,587] {processor.py:153} INFO - Started process (PID=10860) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:42:27,588] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:42:27,589] {logging_mixin.py:115} INFO - [2023-11-16 12:42:27,589] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:42:27,639] {logging_mixin.py:115} INFO - [2023-11-16 12:42:27,639] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:42:27,665] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:42:27,685] {logging_mixin.py:115} INFO - [2023-11-16 12:42:27,684] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:42:27,715] {logging_mixin.py:115} INFO - [2023-11-16 12:42:27,715] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:42:27,736] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.153 seconds
[2023-11-16 12:42:57,797] {processor.py:153} INFO - Started process (PID=10918) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:42:57,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:42:57,799] {logging_mixin.py:115} INFO - [2023-11-16 12:42:57,799] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:42:57,866] {logging_mixin.py:115} INFO - [2023-11-16 12:42:57,865] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:42:57,892] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:42:57,914] {logging_mixin.py:115} INFO - [2023-11-16 12:42:57,914] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:42:57,952] {logging_mixin.py:115} INFO - [2023-11-16 12:42:57,951] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:42:57,974] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.180 seconds
[2023-11-16 12:43:28,434] {processor.py:153} INFO - Started process (PID=10985) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:43:28,435] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:43:28,436] {logging_mixin.py:115} INFO - [2023-11-16 12:43:28,436] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:43:28,489] {logging_mixin.py:115} INFO - [2023-11-16 12:43:28,489] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:43:28,516] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:43:28,540] {logging_mixin.py:115} INFO - [2023-11-16 12:43:28,540] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:43:28,576] {logging_mixin.py:115} INFO - [2023-11-16 12:43:28,575] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:43:28,597] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.167 seconds
[2023-11-16 12:43:59,292] {processor.py:153} INFO - Started process (PID=11052) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:43:59,293] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:43:59,294] {logging_mixin.py:115} INFO - [2023-11-16 12:43:59,294] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:43:59,367] {logging_mixin.py:115} INFO - [2023-11-16 12:43:59,367] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:43:59,396] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:43:59,418] {logging_mixin.py:115} INFO - [2023-11-16 12:43:59,418] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:43:59,452] {logging_mixin.py:115} INFO - [2023-11-16 12:43:59,452] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:43:59,482] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.194 seconds
[2023-11-16 12:44:29,758] {processor.py:153} INFO - Started process (PID=11110) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:44:29,759] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:44:29,760] {logging_mixin.py:115} INFO - [2023-11-16 12:44:29,760] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:44:29,817] {logging_mixin.py:115} INFO - [2023-11-16 12:44:29,817] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:44:29,843] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:44:29,863] {logging_mixin.py:115} INFO - [2023-11-16 12:44:29,863] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:44:29,895] {logging_mixin.py:115} INFO - [2023-11-16 12:44:29,895] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:44:29,917] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 12:44:59,963] {processor.py:153} INFO - Started process (PID=11177) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:44:59,964] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:44:59,965] {logging_mixin.py:115} INFO - [2023-11-16 12:44:59,965] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:45:00,022] {logging_mixin.py:115} INFO - [2023-11-16 12:45:00,022] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:45:00,047] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:45:00,067] {logging_mixin.py:115} INFO - [2023-11-16 12:45:00,067] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:45:00,103] {logging_mixin.py:115} INFO - [2023-11-16 12:45:00,103] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:45:00,124] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 12:45:30,680] {processor.py:153} INFO - Started process (PID=11235) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:45:30,681] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:45:30,682] {logging_mixin.py:115} INFO - [2023-11-16 12:45:30,682] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:45:30,739] {logging_mixin.py:115} INFO - [2023-11-16 12:45:30,739] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:45:30,766] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:45:30,787] {logging_mixin.py:115} INFO - [2023-11-16 12:45:30,786] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:45:30,828] {logging_mixin.py:115} INFO - [2023-11-16 12:45:30,828] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:45:30,853] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.177 seconds
[2023-11-16 12:46:01,448] {processor.py:153} INFO - Started process (PID=11302) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:46:01,450] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:46:01,451] {logging_mixin.py:115} INFO - [2023-11-16 12:46:01,451] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:46:01,511] {logging_mixin.py:115} INFO - [2023-11-16 12:46:01,511] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:46:01,538] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:46:01,561] {logging_mixin.py:115} INFO - [2023-11-16 12:46:01,561] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:46:01,599] {logging_mixin.py:115} INFO - [2023-11-16 12:46:01,599] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:46:01,625] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.181 seconds
[2023-11-16 12:46:31,863] {processor.py:153} INFO - Started process (PID=11362) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:46:31,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:46:31,865] {logging_mixin.py:115} INFO - [2023-11-16 12:46:31,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:46:31,921] {logging_mixin.py:115} INFO - [2023-11-16 12:46:31,921] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:46:31,951] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:46:31,978] {logging_mixin.py:115} INFO - [2023-11-16 12:46:31,978] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:46:32,026] {logging_mixin.py:115} INFO - [2023-11-16 12:46:32,026] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:46:32,052] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.193 seconds
[2023-11-16 12:47:02,244] {processor.py:153} INFO - Started process (PID=11429) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:47:02,250] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:47:02,255] {logging_mixin.py:115} INFO - [2023-11-16 12:47:02,254] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:47:02,381] {logging_mixin.py:115} INFO - [2023-11-16 12:47:02,381] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:47:02,424] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:47:02,471] {logging_mixin.py:115} INFO - [2023-11-16 12:47:02,471] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:47:02,529] {logging_mixin.py:115} INFO - [2023-11-16 12:47:02,528] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:47:02,562] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.335 seconds
[2023-11-16 12:47:32,632] {processor.py:153} INFO - Started process (PID=11487) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:47:32,633] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:47:32,634] {logging_mixin.py:115} INFO - [2023-11-16 12:47:32,634] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:47:32,692] {logging_mixin.py:115} INFO - [2023-11-16 12:47:32,692] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:47:32,717] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:47:32,740] {logging_mixin.py:115} INFO - [2023-11-16 12:47:32,740] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:47:32,772] {logging_mixin.py:115} INFO - [2023-11-16 12:47:32,772] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:47:32,794] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.166 seconds
[2023-11-16 12:48:03,023] {processor.py:153} INFO - Started process (PID=11545) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:48:03,024] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:48:03,025] {logging_mixin.py:115} INFO - [2023-11-16 12:48:03,025] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:48:03,095] {logging_mixin.py:115} INFO - [2023-11-16 12:48:03,095] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:48:03,120] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:48:03,141] {logging_mixin.py:115} INFO - [2023-11-16 12:48:03,141] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:48:03,176] {logging_mixin.py:115} INFO - [2023-11-16 12:48:03,176] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:48:03,197] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.177 seconds
[2023-11-16 12:48:33,562] {processor.py:153} INFO - Started process (PID=11612) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:48:33,563] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:48:33,564] {logging_mixin.py:115} INFO - [2023-11-16 12:48:33,564] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:48:33,613] {logging_mixin.py:115} INFO - [2023-11-16 12:48:33,613] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:48:33,640] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:48:33,661] {logging_mixin.py:115} INFO - [2023-11-16 12:48:33,661] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:48:33,693] {logging_mixin.py:115} INFO - [2023-11-16 12:48:33,693] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:48:33,714] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 12:49:03,874] {processor.py:153} INFO - Started process (PID=11671) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:49:03,875] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:49:03,876] {logging_mixin.py:115} INFO - [2023-11-16 12:49:03,876] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:49:03,930] {logging_mixin.py:115} INFO - [2023-11-16 12:49:03,930] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:49:03,955] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:49:03,975] {logging_mixin.py:115} INFO - [2023-11-16 12:49:03,975] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:49:04,005] {logging_mixin.py:115} INFO - [2023-11-16 12:49:04,005] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:49:04,025] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.155 seconds
[2023-11-16 12:49:34,890] {processor.py:153} INFO - Started process (PID=11738) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:49:34,891] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:49:34,893] {logging_mixin.py:115} INFO - [2023-11-16 12:49:34,892] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:49:34,945] {logging_mixin.py:115} INFO - [2023-11-16 12:49:34,945] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:49:34,971] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:49:34,993] {logging_mixin.py:115} INFO - [2023-11-16 12:49:34,993] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:49:35,029] {logging_mixin.py:115} INFO - [2023-11-16 12:49:35,028] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:49:35,065] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.179 seconds
[2023-11-16 12:50:05,463] {processor.py:153} INFO - Started process (PID=11805) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:50:05,464] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:50:05,465] {logging_mixin.py:115} INFO - [2023-11-16 12:50:05,465] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:50:05,520] {logging_mixin.py:115} INFO - [2023-11-16 12:50:05,520] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:50:05,548] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:50:05,567] {logging_mixin.py:115} INFO - [2023-11-16 12:50:05,566] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:50:05,602] {logging_mixin.py:115} INFO - [2023-11-16 12:50:05,602] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:50:05,626] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.168 seconds
[2023-11-16 12:50:36,014] {processor.py:153} INFO - Started process (PID=11863) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:50:36,015] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:50:36,016] {logging_mixin.py:115} INFO - [2023-11-16 12:50:36,016] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:50:36,071] {logging_mixin.py:115} INFO - [2023-11-16 12:50:36,071] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:50:36,095] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:50:36,114] {logging_mixin.py:115} INFO - [2023-11-16 12:50:36,114] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:50:36,149] {logging_mixin.py:115} INFO - [2023-11-16 12:50:36,149] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:50:36,171] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 12:51:06,397] {processor.py:153} INFO - Started process (PID=11930) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:51:06,398] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:51:06,399] {logging_mixin.py:115} INFO - [2023-11-16 12:51:06,399] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:51:06,449] {logging_mixin.py:115} INFO - [2023-11-16 12:51:06,449] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:51:06,474] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:51:06,495] {logging_mixin.py:115} INFO - [2023-11-16 12:51:06,495] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:51:06,527] {logging_mixin.py:115} INFO - [2023-11-16 12:51:06,527] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:51:06,549] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 12:51:37,051] {processor.py:153} INFO - Started process (PID=11988) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:51:37,052] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:51:37,054] {logging_mixin.py:115} INFO - [2023-11-16 12:51:37,053] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:51:37,108] {logging_mixin.py:115} INFO - [2023-11-16 12:51:37,108] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:51:37,133] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:51:37,156] {logging_mixin.py:115} INFO - [2023-11-16 12:51:37,156] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:51:37,203] {logging_mixin.py:115} INFO - [2023-11-16 12:51:37,203] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:51:37,229] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.182 seconds
[2023-11-16 12:52:07,468] {processor.py:153} INFO - Started process (PID=12055) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:52:07,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:52:07,470] {logging_mixin.py:115} INFO - [2023-11-16 12:52:07,470] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:52:07,535] {logging_mixin.py:115} INFO - [2023-11-16 12:52:07,535] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:52:07,559] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:52:07,581] {logging_mixin.py:115} INFO - [2023-11-16 12:52:07,580] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:52:07,613] {logging_mixin.py:115} INFO - [2023-11-16 12:52:07,613] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:52:07,635] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.172 seconds
[2023-11-16 12:52:38,005] {processor.py:153} INFO - Started process (PID=12113) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:52:38,006] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:52:38,008] {logging_mixin.py:115} INFO - [2023-11-16 12:52:38,008] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:52:38,062] {logging_mixin.py:115} INFO - [2023-11-16 12:52:38,062] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:52:38,091] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:52:38,113] {logging_mixin.py:115} INFO - [2023-11-16 12:52:38,113] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:52:38,145] {logging_mixin.py:115} INFO - [2023-11-16 12:52:38,145] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:52:38,168] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.167 seconds
[2023-11-16 12:53:08,357] {processor.py:153} INFO - Started process (PID=12180) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:53:08,359] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:53:08,360] {logging_mixin.py:115} INFO - [2023-11-16 12:53:08,360] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:53:08,415] {logging_mixin.py:115} INFO - [2023-11-16 12:53:08,415] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:53:08,442] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:53:08,463] {logging_mixin.py:115} INFO - [2023-11-16 12:53:08,463] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:53:08,509] {logging_mixin.py:115} INFO - [2023-11-16 12:53:08,508] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:53:08,534] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.180 seconds
[2023-11-16 12:53:38,783] {processor.py:153} INFO - Started process (PID=12238) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:53:38,784] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:53:38,786] {logging_mixin.py:115} INFO - [2023-11-16 12:53:38,785] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:53:38,850] {logging_mixin.py:115} INFO - [2023-11-16 12:53:38,850] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:53:38,878] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:53:38,903] {logging_mixin.py:115} INFO - [2023-11-16 12:53:38,902] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:53:38,944] {logging_mixin.py:115} INFO - [2023-11-16 12:53:38,944] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:53:38,970] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.191 seconds
[2023-11-16 12:54:09,133] {processor.py:153} INFO - Started process (PID=12306) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:54:09,134] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:54:09,137] {logging_mixin.py:115} INFO - [2023-11-16 12:54:09,136] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:54:09,194] {logging_mixin.py:115} INFO - [2023-11-16 12:54:09,194] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:54:09,222] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:54:09,243] {logging_mixin.py:115} INFO - [2023-11-16 12:54:09,243] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:54:09,281] {logging_mixin.py:115} INFO - [2023-11-16 12:54:09,281] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:54:09,305] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.176 seconds
[2023-11-16 12:54:39,449] {processor.py:153} INFO - Started process (PID=12370) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:54:39,451] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:54:39,452] {logging_mixin.py:115} INFO - [2023-11-16 12:54:39,452] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:54:39,520] {logging_mixin.py:115} INFO - [2023-11-16 12:54:39,520] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:54:39,547] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:54:39,571] {logging_mixin.py:115} INFO - [2023-11-16 12:54:39,571] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:54:39,611] {logging_mixin.py:115} INFO - [2023-11-16 12:54:39,611] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:54:39,634] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.189 seconds
[2023-11-16 12:55:09,766] {processor.py:153} INFO - Started process (PID=12430) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:55:09,767] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:55:09,768] {logging_mixin.py:115} INFO - [2023-11-16 12:55:09,768] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:55:09,826] {logging_mixin.py:115} INFO - [2023-11-16 12:55:09,826] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:55:09,852] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:55:09,872] {logging_mixin.py:115} INFO - [2023-11-16 12:55:09,872] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:55:09,909] {logging_mixin.py:115} INFO - [2023-11-16 12:55:09,909] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:55:09,935] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.173 seconds
[2023-11-16 12:55:39,994] {processor.py:153} INFO - Started process (PID=12498) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:55:39,995] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:55:39,996] {logging_mixin.py:115} INFO - [2023-11-16 12:55:39,996] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:55:40,055] {logging_mixin.py:115} INFO - [2023-11-16 12:55:40,055] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:55:40,084] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:55:40,118] {logging_mixin.py:115} INFO - [2023-11-16 12:55:40,117] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:55:40,164] {logging_mixin.py:115} INFO - [2023-11-16 12:55:40,164] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:55:40,196] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.206 seconds
[2023-11-16 12:56:10,502] {processor.py:153} INFO - Started process (PID=12556) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:56:10,503] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:56:10,504] {logging_mixin.py:115} INFO - [2023-11-16 12:56:10,504] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:56:10,560] {logging_mixin.py:115} INFO - [2023-11-16 12:56:10,560] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:56:10,586] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:56:10,609] {logging_mixin.py:115} INFO - [2023-11-16 12:56:10,609] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:56:10,656] {logging_mixin.py:115} INFO - [2023-11-16 12:56:10,656] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:56:10,682] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 12:56:40,822] {processor.py:153} INFO - Started process (PID=12623) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:56:40,824] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:56:40,825] {logging_mixin.py:115} INFO - [2023-11-16 12:56:40,825] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:56:40,886] {logging_mixin.py:115} INFO - [2023-11-16 12:56:40,886] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:56:40,914] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:56:40,937] {logging_mixin.py:115} INFO - [2023-11-16 12:56:40,937] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:56:40,972] {logging_mixin.py:115} INFO - [2023-11-16 12:56:40,972] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:56:41,003] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.184 seconds
[2023-11-16 12:57:11,197] {processor.py:153} INFO - Started process (PID=12681) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:57:11,198] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:57:11,199] {logging_mixin.py:115} INFO - [2023-11-16 12:57:11,199] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:57:11,258] {logging_mixin.py:115} INFO - [2023-11-16 12:57:11,257] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:57:11,283] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:57:11,309] {logging_mixin.py:115} INFO - [2023-11-16 12:57:11,309] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:57:11,345] {logging_mixin.py:115} INFO - [2023-11-16 12:57:11,345] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:57:11,370] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.176 seconds
[2023-11-16 12:57:41,517] {processor.py:153} INFO - Started process (PID=12747) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:57:41,518] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:57:41,520] {logging_mixin.py:115} INFO - [2023-11-16 12:57:41,520] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:57:41,575] {logging_mixin.py:115} INFO - [2023-11-16 12:57:41,575] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:57:41,602] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:57:41,624] {logging_mixin.py:115} INFO - [2023-11-16 12:57:41,624] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:57:41,672] {logging_mixin.py:115} INFO - [2023-11-16 12:57:41,672] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:57:41,694] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.181 seconds
[2023-11-16 12:58:12,021] {processor.py:153} INFO - Started process (PID=12805) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:58:12,022] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:58:12,024] {logging_mixin.py:115} INFO - [2023-11-16 12:58:12,023] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:58:12,081] {logging_mixin.py:115} INFO - [2023-11-16 12:58:12,080] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:58:12,104] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:58:12,127] {logging_mixin.py:115} INFO - [2023-11-16 12:58:12,126] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:58:12,164] {logging_mixin.py:115} INFO - [2023-11-16 12:58:12,163] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:58:12,187] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.169 seconds
[2023-11-16 12:58:42,357] {processor.py:153} INFO - Started process (PID=12872) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:58:42,358] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:58:42,359] {logging_mixin.py:115} INFO - [2023-11-16 12:58:42,359] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:58:42,413] {logging_mixin.py:115} INFO - [2023-11-16 12:58:42,412] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:58:42,440] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:58:42,460] {logging_mixin.py:115} INFO - [2023-11-16 12:58:42,460] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:58:42,497] {logging_mixin.py:115} INFO - [2023-11-16 12:58:42,497] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:58:42,521] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.170 seconds
[2023-11-16 12:59:12,952] {processor.py:153} INFO - Started process (PID=12930) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:59:12,953] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:59:12,955] {logging_mixin.py:115} INFO - [2023-11-16 12:59:12,954] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:59:13,013] {logging_mixin.py:115} INFO - [2023-11-16 12:59:13,013] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:59:13,039] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:59:13,066] {logging_mixin.py:115} INFO - [2023-11-16 12:59:13,066] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:59:13,101] {logging_mixin.py:115} INFO - [2023-11-16 12:59:13,101] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:59:13,123] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.174 seconds
[2023-11-16 12:59:43,256] {processor.py:153} INFO - Started process (PID=12997) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 12:59:43,257] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 12:59:43,259] {logging_mixin.py:115} INFO - [2023-11-16 12:59:43,258] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 12:59:43,312] {logging_mixin.py:115} INFO - [2023-11-16 12:59:43,311] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 12:59:43,337] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 12:59:43,358] {logging_mixin.py:115} INFO - [2023-11-16 12:59:43,357] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 12:59:43,394] {logging_mixin.py:115} INFO - [2023-11-16 12:59:43,393] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 12:59:43,416] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 13:00:13,530] {processor.py:153} INFO - Started process (PID=13055) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:00:13,531] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:00:13,532] {logging_mixin.py:115} INFO - [2023-11-16 13:00:13,532] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:00:13,596] {logging_mixin.py:115} INFO - [2023-11-16 13:00:13,596] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:00:13,622] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:00:13,645] {logging_mixin.py:115} INFO - [2023-11-16 13:00:13,645] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:00:13,685] {logging_mixin.py:115} INFO - [2023-11-16 13:00:13,685] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:00:13,709] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.182 seconds
[2023-11-16 13:00:44,066] {processor.py:153} INFO - Started process (PID=13122) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:00:44,067] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:00:44,068] {logging_mixin.py:115} INFO - [2023-11-16 13:00:44,068] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:00:44,119] {logging_mixin.py:115} INFO - [2023-11-16 13:00:44,119] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:00:44,144] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:00:44,165] {logging_mixin.py:115} INFO - [2023-11-16 13:00:44,165] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:00:44,197] {logging_mixin.py:115} INFO - [2023-11-16 13:00:44,197] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:00:44,219] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 13:01:14,699] {processor.py:153} INFO - Started process (PID=13187) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:01:14,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:01:14,702] {logging_mixin.py:115} INFO - [2023-11-16 13:01:14,702] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:01:14,763] {logging_mixin.py:115} INFO - [2023-11-16 13:01:14,763] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:01:14,791] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:01:14,818] {logging_mixin.py:115} INFO - [2023-11-16 13:01:14,818] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:01:14,861] {logging_mixin.py:115} INFO - [2023-11-16 13:01:14,861] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:01:14,906] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.210 seconds
[2023-11-16 13:01:44,970] {processor.py:153} INFO - Started process (PID=13245) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:01:44,971] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:01:44,973] {logging_mixin.py:115} INFO - [2023-11-16 13:01:44,973] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:01:45,024] {logging_mixin.py:115} INFO - [2023-11-16 13:01:45,024] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:01:45,066] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:01:45,086] {logging_mixin.py:115} INFO - [2023-11-16 13:01:45,086] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:01:45,120] {logging_mixin.py:115} INFO - [2023-11-16 13:01:45,120] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:01:45,142] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.176 seconds
[2023-11-16 13:02:15,830] {processor.py:153} INFO - Started process (PID=13312) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:02:15,831] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:02:15,832] {logging_mixin.py:115} INFO - [2023-11-16 13:02:15,832] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:02:15,929] {logging_mixin.py:115} INFO - [2023-11-16 13:02:15,929] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:02:15,956] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:02:15,981] {logging_mixin.py:115} INFO - [2023-11-16 13:02:15,981] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:02:16,025] {logging_mixin.py:115} INFO - [2023-11-16 13:02:16,024] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:02:16,046] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.221 seconds
[2023-11-16 13:02:46,525] {processor.py:153} INFO - Started process (PID=13370) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:02:46,526] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:02:46,527] {logging_mixin.py:115} INFO - [2023-11-16 13:02:46,527] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:02:46,581] {logging_mixin.py:115} INFO - [2023-11-16 13:02:46,581] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:02:46,607] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:02:46,626] {logging_mixin.py:115} INFO - [2023-11-16 13:02:46,626] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:02:46,660] {logging_mixin.py:115} INFO - [2023-11-16 13:02:46,659] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:02:46,682] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 13:03:17,351] {processor.py:153} INFO - Started process (PID=13436) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:03:17,352] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:03:17,353] {logging_mixin.py:115} INFO - [2023-11-16 13:03:17,353] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:03:17,407] {logging_mixin.py:115} INFO - [2023-11-16 13:03:17,407] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:03:17,436] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:03:17,459] {logging_mixin.py:115} INFO - [2023-11-16 13:03:17,458] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:03:17,494] {logging_mixin.py:115} INFO - [2023-11-16 13:03:17,494] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:03:17,519] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.172 seconds
[2023-11-16 13:03:47,902] {processor.py:153} INFO - Started process (PID=13494) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:03:47,903] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:03:47,904] {logging_mixin.py:115} INFO - [2023-11-16 13:03:47,904] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:03:47,969] {logging_mixin.py:115} INFO - [2023-11-16 13:03:47,969] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:03:48,001] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:03:48,026] {logging_mixin.py:115} INFO - [2023-11-16 13:03:48,026] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:03:48,063] {logging_mixin.py:115} INFO - [2023-11-16 13:03:48,063] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:03:48,086] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.188 seconds
[2023-11-16 13:04:18,298] {processor.py:153} INFO - Started process (PID=13561) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:04:18,299] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:04:18,300] {logging_mixin.py:115} INFO - [2023-11-16 13:04:18,300] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:04:18,380] {logging_mixin.py:115} INFO - [2023-11-16 13:04:18,380] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:04:18,408] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:04:18,433] {logging_mixin.py:115} INFO - [2023-11-16 13:04:18,433] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:04:18,473] {logging_mixin.py:115} INFO - [2023-11-16 13:04:18,473] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:04:18,497] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.204 seconds
[2023-11-16 13:04:48,645] {processor.py:153} INFO - Started process (PID=13619) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:04:48,646] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:04:48,647] {logging_mixin.py:115} INFO - [2023-11-16 13:04:48,647] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:04:48,712] {logging_mixin.py:115} INFO - [2023-11-16 13:04:48,712] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:04:48,742] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:04:48,781] {logging_mixin.py:115} INFO - [2023-11-16 13:04:48,780] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:04:48,828] {logging_mixin.py:115} INFO - [2023-11-16 13:04:48,828] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:04:48,863] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.222 seconds
[2023-11-16 13:05:19,152] {processor.py:153} INFO - Started process (PID=13686) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:05:19,153] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:05:19,155] {logging_mixin.py:115} INFO - [2023-11-16 13:05:19,155] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:05:19,231] {logging_mixin.py:115} INFO - [2023-11-16 13:05:19,231] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:05:19,261] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:05:19,285] {logging_mixin.py:115} INFO - [2023-11-16 13:05:19,285] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:05:19,321] {logging_mixin.py:115} INFO - [2023-11-16 13:05:19,321] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:05:19,345] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.199 seconds
[2023-11-16 13:05:50,070] {processor.py:153} INFO - Started process (PID=13753) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:05:50,073] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:05:50,076] {logging_mixin.py:115} INFO - [2023-11-16 13:05:50,076] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:05:50,136] {logging_mixin.py:115} INFO - [2023-11-16 13:05:50,136] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:05:50,166] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:05:50,189] {logging_mixin.py:115} INFO - [2023-11-16 13:05:50,189] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:05:50,226] {logging_mixin.py:115} INFO - [2023-11-16 13:05:50,226] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:05:50,253] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.187 seconds
[2023-11-16 13:06:20,892] {processor.py:153} INFO - Started process (PID=13811) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:06:20,893] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:06:20,894] {logging_mixin.py:115} INFO - [2023-11-16 13:06:20,894] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:06:20,953] {logging_mixin.py:115} INFO - [2023-11-16 13:06:20,953] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:06:20,978] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:06:21,004] {logging_mixin.py:115} INFO - [2023-11-16 13:06:21,004] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:06:21,043] {logging_mixin.py:115} INFO - [2023-11-16 13:06:21,043] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:06:21,066] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.178 seconds
[2023-11-16 13:06:51,905] {processor.py:153} INFO - Started process (PID=13878) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:06:51,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:06:51,908] {logging_mixin.py:115} INFO - [2023-11-16 13:06:51,907] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:06:51,965] {logging_mixin.py:115} INFO - [2023-11-16 13:06:51,965] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:06:51,992] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:06:52,013] {logging_mixin.py:115} INFO - [2023-11-16 13:06:52,013] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:06:52,045] {logging_mixin.py:115} INFO - [2023-11-16 13:06:52,045] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:06:52,072] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.172 seconds
[2023-11-16 13:07:22,222] {processor.py:153} INFO - Started process (PID=13936) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:07:22,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:07:22,226] {logging_mixin.py:115} INFO - [2023-11-16 13:07:22,226] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:07:22,297] {logging_mixin.py:115} INFO - [2023-11-16 13:07:22,297] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:07:22,327] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:07:22,349] {logging_mixin.py:115} INFO - [2023-11-16 13:07:22,349] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:07:22,386] {logging_mixin.py:115} INFO - [2023-11-16 13:07:22,386] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:07:22,411] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.193 seconds
[2023-11-16 13:07:52,519] {processor.py:153} INFO - Started process (PID=14003) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:07:52,520] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:07:52,522] {logging_mixin.py:115} INFO - [2023-11-16 13:07:52,522] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:07:52,609] {logging_mixin.py:115} INFO - [2023-11-16 13:07:52,609] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:07:52,634] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:07:52,655] {logging_mixin.py:115} INFO - [2023-11-16 13:07:52,654] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:07:52,691] {logging_mixin.py:115} INFO - [2023-11-16 13:07:52,690] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:07:52,717] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.201 seconds
[2023-11-16 13:08:23,589] {processor.py:153} INFO - Started process (PID=14061) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:08:23,591] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:08:23,592] {logging_mixin.py:115} INFO - [2023-11-16 13:08:23,592] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:08:23,669] {logging_mixin.py:115} INFO - [2023-11-16 13:08:23,669] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:08:23,703] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:08:23,744] {logging_mixin.py:115} INFO - [2023-11-16 13:08:23,743] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:08:23,832] {logging_mixin.py:115} INFO - [2023-11-16 13:08:23,831] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:08:23,866] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.280 seconds
[2023-11-16 13:08:54,060] {processor.py:153} INFO - Started process (PID=14128) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:08:54,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:08:54,063] {logging_mixin.py:115} INFO - [2023-11-16 13:08:54,063] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:08:54,115] {logging_mixin.py:115} INFO - [2023-11-16 13:08:54,115] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:08:54,140] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:08:54,183] {logging_mixin.py:115} INFO - [2023-11-16 13:08:54,183] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:08:54,243] {logging_mixin.py:115} INFO - [2023-11-16 13:08:54,242] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:08:54,265] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.209 seconds
[2023-11-16 13:09:24,369] {processor.py:153} INFO - Started process (PID=14186) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:09:24,370] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:09:24,372] {logging_mixin.py:115} INFO - [2023-11-16 13:09:24,372] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:09:24,431] {logging_mixin.py:115} INFO - [2023-11-16 13:09:24,431] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:09:24,459] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:09:24,481] {logging_mixin.py:115} INFO - [2023-11-16 13:09:24,481] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:09:24,518] {logging_mixin.py:115} INFO - [2023-11-16 13:09:24,518] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:09:24,544] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.178 seconds
[2023-11-16 13:09:55,394] {processor.py:153} INFO - Started process (PID=14254) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:09:55,395] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:09:55,397] {logging_mixin.py:115} INFO - [2023-11-16 13:09:55,396] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:09:55,454] {logging_mixin.py:115} INFO - [2023-11-16 13:09:55,454] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:09:55,480] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:09:55,504] {logging_mixin.py:115} INFO - [2023-11-16 13:09:55,504] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:09:55,544] {logging_mixin.py:115} INFO - [2023-11-16 13:09:55,544] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:09:55,573] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.186 seconds
[2023-11-16 13:10:26,250] {processor.py:153} INFO - Started process (PID=14321) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:10:26,252] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:10:26,253] {logging_mixin.py:115} INFO - [2023-11-16 13:10:26,253] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:10:26,308] {logging_mixin.py:115} INFO - [2023-11-16 13:10:26,308] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:10:26,334] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:10:26,356] {logging_mixin.py:115} INFO - [2023-11-16 13:10:26,356] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:10:26,393] {logging_mixin.py:115} INFO - [2023-11-16 13:10:26,392] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:10:26,418] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.173 seconds
[2023-11-16 13:10:56,712] {processor.py:153} INFO - Started process (PID=14379) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:10:56,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:10:56,714] {logging_mixin.py:115} INFO - [2023-11-16 13:10:56,714] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:10:56,771] {logging_mixin.py:115} INFO - [2023-11-16 13:10:56,771] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:10:56,798] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:10:56,821] {logging_mixin.py:115} INFO - [2023-11-16 13:10:56,821] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:10:56,856] {logging_mixin.py:115} INFO - [2023-11-16 13:10:56,856] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:10:56,883] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.175 seconds
[2023-11-16 13:11:27,421] {processor.py:153} INFO - Started process (PID=14447) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:11:27,422] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:11:27,423] {logging_mixin.py:115} INFO - [2023-11-16 13:11:27,423] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:11:27,499] {logging_mixin.py:115} INFO - [2023-11-16 13:11:27,499] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:11:27,528] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:11:27,550] {logging_mixin.py:115} INFO - [2023-11-16 13:11:27,550] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:11:27,591] {logging_mixin.py:115} INFO - [2023-11-16 13:11:27,590] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:11:27,614] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.207 seconds
[2023-11-16 13:11:58,109] {processor.py:153} INFO - Started process (PID=14505) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:11:58,111] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:11:58,114] {logging_mixin.py:115} INFO - [2023-11-16 13:11:58,113] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:11:58,177] {logging_mixin.py:115} INFO - [2023-11-16 13:11:58,176] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:11:58,204] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:11:58,226] {logging_mixin.py:115} INFO - [2023-11-16 13:11:58,226] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:11:58,264] {logging_mixin.py:115} INFO - [2023-11-16 13:11:58,264] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:11:58,294] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.188 seconds
[2023-11-16 13:12:28,931] {processor.py:153} INFO - Started process (PID=14572) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:12:28,932] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:12:28,933] {logging_mixin.py:115} INFO - [2023-11-16 13:12:28,933] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:12:28,989] {logging_mixin.py:115} INFO - [2023-11-16 13:12:28,989] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:12:29,016] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:12:29,034] {logging_mixin.py:115} INFO - [2023-11-16 13:12:29,034] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:12:29,078] {logging_mixin.py:115} INFO - [2023-11-16 13:12:29,077] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:12:29,101] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.174 seconds
[2023-11-16 13:12:59,159] {processor.py:153} INFO - Started process (PID=14630) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:12:59,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:12:59,162] {logging_mixin.py:115} INFO - [2023-11-16 13:12:59,162] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:12:59,223] {logging_mixin.py:115} INFO - [2023-11-16 13:12:59,223] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:12:59,251] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:12:59,272] {logging_mixin.py:115} INFO - [2023-11-16 13:12:59,271] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:12:59,305] {logging_mixin.py:115} INFO - [2023-11-16 13:12:59,305] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:12:59,331] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.176 seconds
[2023-11-16 13:13:29,394] {processor.py:153} INFO - Started process (PID=14697) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:13:29,395] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:13:29,396] {logging_mixin.py:115} INFO - [2023-11-16 13:13:29,396] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:13:29,462] {logging_mixin.py:115} INFO - [2023-11-16 13:13:29,462] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:13:29,490] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:13:29,511] {logging_mixin.py:115} INFO - [2023-11-16 13:13:29,511] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:13:29,546] {logging_mixin.py:115} INFO - [2023-11-16 13:13:29,545] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:13:29,569] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.179 seconds
[2023-11-16 13:13:59,887] {processor.py:153} INFO - Started process (PID=14755) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:13:59,888] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:13:59,890] {logging_mixin.py:115} INFO - [2023-11-16 13:13:59,890] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:14:00,002] {logging_mixin.py:115} INFO - [2023-11-16 13:14:00,002] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:14:00,069] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:14:00,101] {logging_mixin.py:115} INFO - [2023-11-16 13:14:00,101] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:14:00,165] {logging_mixin.py:115} INFO - [2023-11-16 13:14:00,164] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:14:00,201] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.320 seconds
[2023-11-16 13:14:30,862] {processor.py:153} INFO - Started process (PID=14822) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:14:30,863] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:14:30,865] {logging_mixin.py:115} INFO - [2023-11-16 13:14:30,864] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:14:30,917] {logging_mixin.py:115} INFO - [2023-11-16 13:14:30,916] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:14:30,941] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:14:30,962] {logging_mixin.py:115} INFO - [2023-11-16 13:14:30,962] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:14:30,995] {logging_mixin.py:115} INFO - [2023-11-16 13:14:30,995] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:14:31,017] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.160 seconds
[2023-11-16 13:15:01,638] {processor.py:153} INFO - Started process (PID=14889) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:15:01,641] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:15:01,645] {logging_mixin.py:115} INFO - [2023-11-16 13:15:01,644] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:15:01,723] {logging_mixin.py:115} INFO - [2023-11-16 13:15:01,723] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:15:01,749] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:15:01,774] {logging_mixin.py:115} INFO - [2023-11-16 13:15:01,774] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:15:01,812] {logging_mixin.py:115} INFO - [2023-11-16 13:15:01,812] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:15:01,836] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.208 seconds
[2023-11-16 13:15:32,167] {processor.py:153} INFO - Started process (PID=14947) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:15:32,168] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:15:32,169] {logging_mixin.py:115} INFO - [2023-11-16 13:15:32,169] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:15:32,220] {logging_mixin.py:115} INFO - [2023-11-16 13:15:32,220] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:15:32,246] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:15:32,266] {logging_mixin.py:115} INFO - [2023-11-16 13:15:32,265] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:15:32,298] {logging_mixin.py:115} INFO - [2023-11-16 13:15:32,298] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:15:32,320] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.157 seconds
[2023-11-16 13:16:02,466] {processor.py:153} INFO - Started process (PID=15014) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:16:02,467] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:16:02,469] {logging_mixin.py:115} INFO - [2023-11-16 13:16:02,469] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:16:02,541] {logging_mixin.py:115} INFO - [2023-11-16 13:16:02,541] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:16:02,567] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:16:02,596] {logging_mixin.py:115} INFO - [2023-11-16 13:16:02,595] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:16:02,640] {logging_mixin.py:115} INFO - [2023-11-16 13:16:02,639] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:16:02,677] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.215 seconds
[2023-11-16 13:16:32,778] {processor.py:153} INFO - Started process (PID=15072) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:16:32,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:16:32,780] {logging_mixin.py:115} INFO - [2023-11-16 13:16:32,780] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:16:32,839] {logging_mixin.py:115} INFO - [2023-11-16 13:16:32,839] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:16:32,868] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:16:32,890] {logging_mixin.py:115} INFO - [2023-11-16 13:16:32,890] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:16:32,930] {logging_mixin.py:115} INFO - [2023-11-16 13:16:32,930] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:16:32,957] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 13:17:03,413] {processor.py:153} INFO - Started process (PID=15139) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:17:03,414] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:17:03,416] {logging_mixin.py:115} INFO - [2023-11-16 13:17:03,416] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:17:03,480] {logging_mixin.py:115} INFO - [2023-11-16 13:17:03,479] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:17:03,506] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:17:03,531] {logging_mixin.py:115} INFO - [2023-11-16 13:17:03,531] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:17:03,574] {logging_mixin.py:115} INFO - [2023-11-16 13:17:03,574] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:17:03,601] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.191 seconds
[2023-11-16 13:17:34,042] {processor.py:153} INFO - Started process (PID=15197) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:17:34,043] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:17:34,044] {logging_mixin.py:115} INFO - [2023-11-16 13:17:34,044] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:17:34,100] {logging_mixin.py:115} INFO - [2023-11-16 13:17:34,099] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:17:34,125] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:17:34,144] {logging_mixin.py:115} INFO - [2023-11-16 13:17:34,144] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:17:34,175] {logging_mixin.py:115} INFO - [2023-11-16 13:17:34,175] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:17:34,197] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.159 seconds
[2023-11-16 13:18:04,479] {processor.py:153} INFO - Started process (PID=15264) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:18:04,481] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:18:04,483] {logging_mixin.py:115} INFO - [2023-11-16 13:18:04,483] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:18:04,557] {logging_mixin.py:115} INFO - [2023-11-16 13:18:04,557] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:18:04,583] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:18:04,605] {logging_mixin.py:115} INFO - [2023-11-16 13:18:04,605] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:18:04,641] {logging_mixin.py:115} INFO - [2023-11-16 13:18:04,640] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:18:04,664] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.190 seconds
[2023-11-16 13:18:34,841] {processor.py:153} INFO - Started process (PID=15322) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:18:34,842] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:18:34,843] {logging_mixin.py:115} INFO - [2023-11-16 13:18:34,843] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:18:34,895] {logging_mixin.py:115} INFO - [2023-11-16 13:18:34,895] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:18:34,921] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:18:34,943] {logging_mixin.py:115} INFO - [2023-11-16 13:18:34,943] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:18:34,997] {logging_mixin.py:115} INFO - [2023-11-16 13:18:34,996] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:18:35,021] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.184 seconds
[2023-11-16 13:19:05,369] {processor.py:153} INFO - Started process (PID=15389) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:19:05,370] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:19:05,371] {logging_mixin.py:115} INFO - [2023-11-16 13:19:05,371] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:19:05,426] {logging_mixin.py:115} INFO - [2023-11-16 13:19:05,426] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:19:05,453] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:19:05,472] {logging_mixin.py:115} INFO - [2023-11-16 13:19:05,472] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:19:05,517] {logging_mixin.py:115} INFO - [2023-11-16 13:19:05,517] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:19:05,554] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.188 seconds
[2023-11-16 13:19:36,108] {processor.py:153} INFO - Started process (PID=15456) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:19:36,109] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:19:36,111] {logging_mixin.py:115} INFO - [2023-11-16 13:19:36,110] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:19:36,190] {logging_mixin.py:115} INFO - [2023-11-16 13:19:36,190] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:19:36,219] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:19:36,253] {logging_mixin.py:115} INFO - [2023-11-16 13:19:36,252] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:19:36,333] {logging_mixin.py:115} INFO - [2023-11-16 13:19:36,333] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:19:36,376] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.274 seconds
[2023-11-16 13:20:06,580] {processor.py:153} INFO - Started process (PID=15515) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:20:06,582] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:20:06,583] {logging_mixin.py:115} INFO - [2023-11-16 13:20:06,583] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:20:06,639] {logging_mixin.py:115} INFO - [2023-11-16 13:20:06,639] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:20:06,665] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:20:06,684] {logging_mixin.py:115} INFO - [2023-11-16 13:20:06,684] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:20:06,717] {logging_mixin.py:115} INFO - [2023-11-16 13:20:06,717] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:20:06,738] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.163 seconds
[2023-11-16 13:20:36,809] {processor.py:153} INFO - Started process (PID=15582) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:20:36,810] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:20:36,811] {logging_mixin.py:115} INFO - [2023-11-16 13:20:36,811] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:20:36,856] {logging_mixin.py:115} INFO - [2023-11-16 13:20:36,856] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:20:36,881] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:20:36,899] {logging_mixin.py:115} INFO - [2023-11-16 13:20:36,899] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:20:36,930] {logging_mixin.py:115} INFO - [2023-11-16 13:20:36,930] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:20:36,948] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.142 seconds
[2023-11-16 13:21:07,145] {processor.py:153} INFO - Started process (PID=15640) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:21:07,147] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:21:07,148] {logging_mixin.py:115} INFO - [2023-11-16 13:21:07,148] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:21:07,211] {logging_mixin.py:115} INFO - [2023-11-16 13:21:07,211] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:21:07,237] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:21:07,259] {logging_mixin.py:115} INFO - [2023-11-16 13:21:07,258] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:21:07,297] {logging_mixin.py:115} INFO - [2023-11-16 13:21:07,297] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:21:07,320] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.181 seconds
[2023-11-16 13:21:38,186] {processor.py:153} INFO - Started process (PID=15707) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:21:38,187] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:21:38,189] {logging_mixin.py:115} INFO - [2023-11-16 13:21:38,189] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:21:38,244] {logging_mixin.py:115} INFO - [2023-11-16 13:21:38,244] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:21:38,273] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:21:38,294] {logging_mixin.py:115} INFO - [2023-11-16 13:21:38,294] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:21:38,332] {logging_mixin.py:115} INFO - [2023-11-16 13:21:38,331] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:21:38,353] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.170 seconds
[2023-11-16 13:22:08,592] {processor.py:153} INFO - Started process (PID=15766) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:22:08,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:22:08,594] {logging_mixin.py:115} INFO - [2023-11-16 13:22:08,594] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:22:08,644] {logging_mixin.py:115} INFO - [2023-11-16 13:22:08,644] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:22:08,670] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:22:08,690] {logging_mixin.py:115} INFO - [2023-11-16 13:22:08,689] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:22:08,719] {logging_mixin.py:115} INFO - [2023-11-16 13:22:08,718] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:22:08,741] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.153 seconds
[2023-11-16 13:22:38,957] {processor.py:153} INFO - Started process (PID=15833) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:22:38,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:22:38,960] {logging_mixin.py:115} INFO - [2023-11-16 13:22:38,960] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:22:39,042] {logging_mixin.py:115} INFO - [2023-11-16 13:22:39,041] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:22:39,074] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:22:39,110] {logging_mixin.py:115} INFO - [2023-11-16 13:22:39,110] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:22:39,156] {logging_mixin.py:115} INFO - [2023-11-16 13:22:39,155] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:22:39,179] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.231 seconds
[2023-11-16 13:23:09,723] {processor.py:153} INFO - Started process (PID=15891) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:23:09,724] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:23:09,726] {logging_mixin.py:115} INFO - [2023-11-16 13:23:09,726] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:23:09,786] {logging_mixin.py:115} INFO - [2023-11-16 13:23:09,785] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:23:09,813] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:23:09,835] {logging_mixin.py:115} INFO - [2023-11-16 13:23:09,835] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:23:09,878] {logging_mixin.py:115} INFO - [2023-11-16 13:23:09,878] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:23:09,901] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.184 seconds
[2023-11-16 13:23:40,387] {processor.py:153} INFO - Started process (PID=15958) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:23:40,388] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:23:40,390] {logging_mixin.py:115} INFO - [2023-11-16 13:23:40,389] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:23:40,441] {logging_mixin.py:115} INFO - [2023-11-16 13:23:40,441] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:23:40,465] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:23:40,483] {logging_mixin.py:115} INFO - [2023-11-16 13:23:40,483] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:23:40,514] {logging_mixin.py:115} INFO - [2023-11-16 13:23:40,514] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:23:40,538] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.155 seconds
[2023-11-16 13:24:10,593] {processor.py:153} INFO - Started process (PID=16025) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:24:10,594] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:24:10,595] {logging_mixin.py:115} INFO - [2023-11-16 13:24:10,595] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:24:10,649] {logging_mixin.py:115} INFO - [2023-11-16 13:24:10,649] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:24:10,675] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:24:10,698] {logging_mixin.py:115} INFO - [2023-11-16 13:24:10,698] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:24:10,744] {logging_mixin.py:115} INFO - [2023-11-16 13:24:10,744] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:24:10,771] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.182 seconds
[2023-11-16 13:24:41,084] {processor.py:153} INFO - Started process (PID=16083) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:24:41,085] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:24:41,086] {logging_mixin.py:115} INFO - [2023-11-16 13:24:41,085] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:24:41,136] {logging_mixin.py:115} INFO - [2023-11-16 13:24:41,136] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:24:41,161] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:24:41,183] {logging_mixin.py:115} INFO - [2023-11-16 13:24:41,183] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:24:41,221] {logging_mixin.py:115} INFO - [2023-11-16 13:24:41,221] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:24:41,247] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.167 seconds
[2023-11-16 13:25:11,308] {processor.py:153} INFO - Started process (PID=16151) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:25:11,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:25:11,311] {logging_mixin.py:115} INFO - [2023-11-16 13:25:11,310] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:25:11,367] {logging_mixin.py:115} INFO - [2023-11-16 13:25:11,366] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:25:11,393] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:25:11,414] {logging_mixin.py:115} INFO - [2023-11-16 13:25:11,413] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:25:11,453] {logging_mixin.py:115} INFO - [2023-11-16 13:25:11,453] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:25:11,475] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.171 seconds
[2023-11-16 13:25:41,617] {processor.py:153} INFO - Started process (PID=16209) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:25:41,618] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:25:41,619] {logging_mixin.py:115} INFO - [2023-11-16 13:25:41,619] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:25:41,683] {logging_mixin.py:115} INFO - [2023-11-16 13:25:41,682] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:25:41,709] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:25:41,733] {logging_mixin.py:115} INFO - [2023-11-16 13:25:41,732] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:25:41,775] {logging_mixin.py:115} INFO - [2023-11-16 13:25:41,775] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:25:41,798] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.186 seconds
[2023-11-16 13:26:11,899] {processor.py:153} INFO - Started process (PID=16276) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:26:11,899] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:26:11,900] {logging_mixin.py:115} INFO - [2023-11-16 13:26:11,900] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:26:11,946] {logging_mixin.py:115} INFO - [2023-11-16 13:26:11,946] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:26:11,970] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:26:11,987] {logging_mixin.py:115} INFO - [2023-11-16 13:26:11,987] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:26:12,015] {logging_mixin.py:115} INFO - [2023-11-16 13:26:12,015] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:26:12,033] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.138 seconds
[2023-11-16 13:26:42,308] {processor.py:153} INFO - Started process (PID=16333) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:26:42,309] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:26:42,311] {logging_mixin.py:115} INFO - [2023-11-16 13:26:42,310] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:26:42,359] {logging_mixin.py:115} INFO - [2023-11-16 13:26:42,358] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:26:42,383] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:26:42,402] {logging_mixin.py:115} INFO - [2023-11-16 13:26:42,402] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:26:42,435] {logging_mixin.py:115} INFO - [2023-11-16 13:26:42,435] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:26:42,456] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.151 seconds
[2023-11-16 13:27:12,615] {processor.py:153} INFO - Started process (PID=16400) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:27:12,616] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:27:12,618] {logging_mixin.py:115} INFO - [2023-11-16 13:27:12,618] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:27:12,668] {logging_mixin.py:115} INFO - [2023-11-16 13:27:12,668] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:27:12,692] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:27:12,711] {logging_mixin.py:115} INFO - [2023-11-16 13:27:12,711] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:27:12,743] {logging_mixin.py:115} INFO - [2023-11-16 13:27:12,743] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:27:12,767] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 13:27:42,846] {processor.py:153} INFO - Started process (PID=16458) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:27:42,847] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:27:42,848] {logging_mixin.py:115} INFO - [2023-11-16 13:27:42,848] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:27:42,897] {logging_mixin.py:115} INFO - [2023-11-16 13:27:42,897] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:27:42,921] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:27:42,940] {logging_mixin.py:115} INFO - [2023-11-16 13:27:42,940] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:27:42,977] {logging_mixin.py:115} INFO - [2023-11-16 13:27:42,977] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:27:43,000] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.159 seconds
[2023-11-16 13:28:13,159] {processor.py:153} INFO - Started process (PID=16525) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:28:13,160] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:28:13,161] {logging_mixin.py:115} INFO - [2023-11-16 13:28:13,161] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:28:13,211] {logging_mixin.py:115} INFO - [2023-11-16 13:28:13,211] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:28:13,236] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:28:13,257] {logging_mixin.py:115} INFO - [2023-11-16 13:28:13,257] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:28:13,292] {logging_mixin.py:115} INFO - [2023-11-16 13:28:13,292] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:28:13,315] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 13:28:43,394] {processor.py:153} INFO - Started process (PID=16592) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:28:43,395] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:28:43,397] {logging_mixin.py:115} INFO - [2023-11-16 13:28:43,397] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:28:43,453] {logging_mixin.py:115} INFO - [2023-11-16 13:28:43,453] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:28:43,481] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:28:43,503] {logging_mixin.py:115} INFO - [2023-11-16 13:28:43,503] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:28:43,542] {logging_mixin.py:115} INFO - [2023-11-16 13:28:43,542] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:28:43,566] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.184 seconds
[2023-11-16 13:29:13,622] {processor.py:153} INFO - Started process (PID=16648) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:29:13,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:29:13,624] {logging_mixin.py:115} INFO - [2023-11-16 13:29:13,624] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:29:13,680] {logging_mixin.py:115} INFO - [2023-11-16 13:29:13,680] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:29:13,705] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:29:13,725] {logging_mixin.py:115} INFO - [2023-11-16 13:29:13,725] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:29:13,759] {logging_mixin.py:115} INFO - [2023-11-16 13:29:13,759] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:29:13,781] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 13:29:44,031] {processor.py:153} INFO - Started process (PID=16715) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:29:44,032] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:29:44,033] {logging_mixin.py:115} INFO - [2023-11-16 13:29:44,033] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:29:44,083] {logging_mixin.py:115} INFO - [2023-11-16 13:29:44,083] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:29:44,110] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:29:44,132] {logging_mixin.py:115} INFO - [2023-11-16 13:29:44,132] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:29:44,173] {logging_mixin.py:115} INFO - [2023-11-16 13:29:44,173] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:29:44,201] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.174 seconds
[2023-11-16 13:30:14,404] {processor.py:153} INFO - Started process (PID=16773) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:30:14,406] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:30:14,408] {logging_mixin.py:115} INFO - [2023-11-16 13:30:14,408] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:30:14,473] {logging_mixin.py:115} INFO - [2023-11-16 13:30:14,473] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:30:14,500] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:30:14,525] {logging_mixin.py:115} INFO - [2023-11-16 13:30:14,525] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:30:14,559] {logging_mixin.py:115} INFO - [2023-11-16 13:30:14,559] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:30:14,581] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.183 seconds
[2023-11-16 13:30:44,697] {processor.py:153} INFO - Started process (PID=16840) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:30:44,698] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:30:44,699] {logging_mixin.py:115} INFO - [2023-11-16 13:30:44,699] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:30:44,754] {logging_mixin.py:115} INFO - [2023-11-16 13:30:44,753] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:30:44,779] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:30:44,798] {logging_mixin.py:115} INFO - [2023-11-16 13:30:44,798] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:30:44,833] {logging_mixin.py:115} INFO - [2023-11-16 13:30:44,833] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:30:44,857] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 13:31:15,138] {processor.py:153} INFO - Started process (PID=16898) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:31:15,139] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:31:15,140] {logging_mixin.py:115} INFO - [2023-11-16 13:31:15,140] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:31:15,190] {logging_mixin.py:115} INFO - [2023-11-16 13:31:15,190] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:31:15,216] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:31:15,237] {logging_mixin.py:115} INFO - [2023-11-16 13:31:15,237] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:31:15,271] {logging_mixin.py:115} INFO - [2023-11-16 13:31:15,271] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:31:15,293] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.160 seconds
[2023-11-16 13:31:45,528] {processor.py:153} INFO - Started process (PID=16965) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:31:45,530] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:31:45,531] {logging_mixin.py:115} INFO - [2023-11-16 13:31:45,531] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:31:45,580] {logging_mixin.py:115} INFO - [2023-11-16 13:31:45,579] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:31:45,609] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:31:45,628] {logging_mixin.py:115} INFO - [2023-11-16 13:31:45,628] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:31:45,665] {logging_mixin.py:115} INFO - [2023-11-16 13:31:45,665] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:31:45,687] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.163 seconds
[2023-11-16 13:32:15,925] {processor.py:153} INFO - Started process (PID=17032) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:32:15,926] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:32:15,928] {logging_mixin.py:115} INFO - [2023-11-16 13:32:15,928] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:32:15,987] {logging_mixin.py:115} INFO - [2023-11-16 13:32:15,987] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:32:16,016] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:32:16,040] {logging_mixin.py:115} INFO - [2023-11-16 13:32:16,040] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:32:16,079] {logging_mixin.py:115} INFO - [2023-11-16 13:32:16,079] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:32:16,103] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.182 seconds
[2023-11-16 13:32:46,411] {processor.py:153} INFO - Started process (PID=17090) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:32:46,412] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:32:46,413] {logging_mixin.py:115} INFO - [2023-11-16 13:32:46,413] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:32:46,473] {logging_mixin.py:115} INFO - [2023-11-16 13:32:46,473] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:32:46,499] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:32:46,521] {logging_mixin.py:115} INFO - [2023-11-16 13:32:46,520] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:32:46,554] {logging_mixin.py:115} INFO - [2023-11-16 13:32:46,554] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:32:46,578] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.171 seconds
[2023-11-16 13:33:16,698] {processor.py:153} INFO - Started process (PID=17157) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:33:16,700] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:33:16,702] {logging_mixin.py:115} INFO - [2023-11-16 13:33:16,702] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:33:16,751] {logging_mixin.py:115} INFO - [2023-11-16 13:33:16,751] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:33:16,778] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:33:16,799] {logging_mixin.py:115} INFO - [2023-11-16 13:33:16,799] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:33:16,832] {logging_mixin.py:115} INFO - [2023-11-16 13:33:16,832] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:33:16,854] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.161 seconds
[2023-11-16 13:33:47,331] {processor.py:153} INFO - Started process (PID=17215) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:33:47,332] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:33:47,334] {logging_mixin.py:115} INFO - [2023-11-16 13:33:47,334] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:33:47,386] {logging_mixin.py:115} INFO - [2023-11-16 13:33:47,385] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:33:47,414] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:33:47,436] {logging_mixin.py:115} INFO - [2023-11-16 13:33:47,436] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:33:47,471] {logging_mixin.py:115} INFO - [2023-11-16 13:33:47,471] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:33:47,495] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.168 seconds
[2023-11-16 13:34:17,670] {processor.py:153} INFO - Started process (PID=17283) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:34:17,671] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:34:17,673] {logging_mixin.py:115} INFO - [2023-11-16 13:34:17,673] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:34:17,726] {logging_mixin.py:115} INFO - [2023-11-16 13:34:17,726] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:34:17,751] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:34:17,771] {logging_mixin.py:115} INFO - [2023-11-16 13:34:17,771] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:34:17,805] {logging_mixin.py:115} INFO - [2023-11-16 13:34:17,805] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:34:17,828] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.162 seconds
[2023-11-16 13:34:48,178] {processor.py:153} INFO - Started process (PID=17341) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:34:48,179] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:34:48,180] {logging_mixin.py:115} INFO - [2023-11-16 13:34:48,180] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:34:48,232] {logging_mixin.py:115} INFO - [2023-11-16 13:34:48,232] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:34:48,259] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:34:48,279] {logging_mixin.py:115} INFO - [2023-11-16 13:34:48,279] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:34:48,319] {logging_mixin.py:115} INFO - [2023-11-16 13:34:48,319] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:34:48,340] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.167 seconds
[2023-11-16 13:35:19,016] {processor.py:153} INFO - Started process (PID=17408) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:35:19,017] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:35:19,018] {logging_mixin.py:115} INFO - [2023-11-16 13:35:19,018] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:35:19,069] {logging_mixin.py:115} INFO - [2023-11-16 13:35:19,069] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:35:19,094] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:35:19,114] {logging_mixin.py:115} INFO - [2023-11-16 13:35:19,113] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:35:19,146] {logging_mixin.py:115} INFO - [2023-11-16 13:35:19,146] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:35:19,170] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.158 seconds
[2023-11-16 13:35:49,360] {processor.py:153} INFO - Started process (PID=17473) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:35:49,362] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:35:49,363] {logging_mixin.py:115} INFO - [2023-11-16 13:35:49,363] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:35:49,419] {logging_mixin.py:115} INFO - [2023-11-16 13:35:49,419] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:35:49,446] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:35:49,468] {logging_mixin.py:115} INFO - [2023-11-16 13:35:49,468] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:35:49,502] {logging_mixin.py:115} INFO - [2023-11-16 13:35:49,502] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:35:49,522] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.166 seconds
[2023-11-16 13:36:20,360] {processor.py:153} INFO - Started process (PID=17533) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:36:20,361] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:36:20,363] {logging_mixin.py:115} INFO - [2023-11-16 13:36:20,363] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:36:20,418] {logging_mixin.py:115} INFO - [2023-11-16 13:36:20,418] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:36:20,445] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:36:20,467] {logging_mixin.py:115} INFO - [2023-11-16 13:36:20,467] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:36:20,500] {logging_mixin.py:115} INFO - [2023-11-16 13:36:20,500] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:36:20,520] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 13:36:50,845] {processor.py:153} INFO - Started process (PID=17600) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:36:50,847] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:36:50,848] {logging_mixin.py:115} INFO - [2023-11-16 13:36:50,848] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:36:50,907] {logging_mixin.py:115} INFO - [2023-11-16 13:36:50,907] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:36:50,936] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:36:50,962] {logging_mixin.py:115} INFO - [2023-11-16 13:36:50,962] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:36:50,999] {logging_mixin.py:115} INFO - [2023-11-16 13:36:50,999] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:36:51,021] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.180 seconds
[2023-11-16 13:37:21,317] {processor.py:153} INFO - Started process (PID=17658) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:37:21,318] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:37:21,319] {logging_mixin.py:115} INFO - [2023-11-16 13:37:21,319] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:37:21,370] {logging_mixin.py:115} INFO - [2023-11-16 13:37:21,369] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:37:21,396] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:37:21,416] {logging_mixin.py:115} INFO - [2023-11-16 13:37:21,416] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:37:21,451] {logging_mixin.py:115} INFO - [2023-11-16 13:37:21,451] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:37:21,475] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.163 seconds
[2023-11-16 13:37:52,234] {processor.py:153} INFO - Started process (PID=17725) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:37:52,236] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:37:52,237] {logging_mixin.py:115} INFO - [2023-11-16 13:37:52,237] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:37:52,295] {logging_mixin.py:115} INFO - [2023-11-16 13:37:52,295] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:37:52,328] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:37:52,362] {logging_mixin.py:115} INFO - [2023-11-16 13:37:52,362] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:37:52,405] {logging_mixin.py:115} INFO - [2023-11-16 13:37:52,405] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:37:52,434] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.204 seconds
[2023-11-16 13:38:22,590] {processor.py:153} INFO - Started process (PID=17785) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:38:22,592] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:38:22,593] {logging_mixin.py:115} INFO - [2023-11-16 13:38:22,593] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:38:22,642] {logging_mixin.py:115} INFO - [2023-11-16 13:38:22,641] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:38:22,667] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:38:22,688] {logging_mixin.py:115} INFO - [2023-11-16 13:38:22,688] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:38:22,726] {logging_mixin.py:115} INFO - [2023-11-16 13:38:22,726] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:38:22,749] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 13:38:52,921] {processor.py:153} INFO - Started process (PID=17852) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:38:52,922] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:38:52,923] {logging_mixin.py:115} INFO - [2023-11-16 13:38:52,923] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:38:52,982] {logging_mixin.py:115} INFO - [2023-11-16 13:38:52,982] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:38:53,009] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:38:53,032] {logging_mixin.py:115} INFO - [2023-11-16 13:38:53,031] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:38:53,067] {logging_mixin.py:115} INFO - [2023-11-16 13:38:53,067] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:38:53,092] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.175 seconds
[2023-11-16 13:39:23,301] {processor.py:153} INFO - Started process (PID=17911) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:39:23,302] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:39:23,303] {logging_mixin.py:115} INFO - [2023-11-16 13:39:23,303] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:39:23,353] {logging_mixin.py:115} INFO - [2023-11-16 13:39:23,353] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:39:23,381] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:39:23,405] {logging_mixin.py:115} INFO - [2023-11-16 13:39:23,404] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:39:23,442] {logging_mixin.py:115} INFO - [2023-11-16 13:39:23,442] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:39:23,466] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.170 seconds
[2023-11-16 13:39:53,655] {processor.py:153} INFO - Started process (PID=17979) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:39:53,657] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:39:53,658] {logging_mixin.py:115} INFO - [2023-11-16 13:39:53,658] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:39:53,713] {logging_mixin.py:115} INFO - [2023-11-16 13:39:53,713] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:39:53,739] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:39:53,759] {logging_mixin.py:115} INFO - [2023-11-16 13:39:53,759] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:39:53,792] {logging_mixin.py:115} INFO - [2023-11-16 13:39:53,792] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:39:53,817] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.167 seconds
[2023-11-16 13:40:23,895] {processor.py:153} INFO - Started process (PID=18035) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:40:23,896] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:40:23,897] {logging_mixin.py:115} INFO - [2023-11-16 13:40:23,897] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:40:23,951] {logging_mixin.py:115} INFO - [2023-11-16 13:40:23,951] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:40:23,977] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:40:23,997] {logging_mixin.py:115} INFO - [2023-11-16 13:40:23,996] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:40:24,028] {logging_mixin.py:115} INFO - [2023-11-16 13:40:24,028] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:40:24,055] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.164 seconds
[2023-11-16 13:40:54,332] {processor.py:153} INFO - Started process (PID=18102) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:40:54,334] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:40:54,335] {logging_mixin.py:115} INFO - [2023-11-16 13:40:54,335] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:40:54,391] {logging_mixin.py:115} INFO - [2023-11-16 13:40:54,390] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:40:54,417] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:40:54,437] {logging_mixin.py:115} INFO - [2023-11-16 13:40:54,437] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:40:54,472] {logging_mixin.py:115} INFO - [2023-11-16 13:40:54,472] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:40:54,493] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.165 seconds
[2023-11-16 13:41:24,674] {processor.py:153} INFO - Started process (PID=18169) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:41:24,676] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:41:24,677] {logging_mixin.py:115} INFO - [2023-11-16 13:41:24,677] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:41:24,740] {logging_mixin.py:115} INFO - [2023-11-16 13:41:24,740] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:41:24,768] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:41:24,800] {logging_mixin.py:115} INFO - [2023-11-16 13:41:24,799] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:41:24,845] {logging_mixin.py:115} INFO - [2023-11-16 13:41:24,845] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:41:24,872] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.203 seconds
[2023-11-16 13:41:55,424] {processor.py:153} INFO - Started process (PID=18227) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:41:55,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:41:55,426] {logging_mixin.py:115} INFO - [2023-11-16 13:41:55,426] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:41:55,478] {logging_mixin.py:115} INFO - [2023-11-16 13:41:55,478] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:41:55,503] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:41:55,529] {logging_mixin.py:115} INFO - [2023-11-16 13:41:55,529] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:41:55,564] {logging_mixin.py:115} INFO - [2023-11-16 13:41:55,564] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:41:55,587] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.167 seconds
[2023-11-16 13:42:25,813] {processor.py:153} INFO - Started process (PID=18294) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:42:25,814] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:42:25,815] {logging_mixin.py:115} INFO - [2023-11-16 13:42:25,815] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:42:25,879] {logging_mixin.py:115} INFO - [2023-11-16 13:42:25,879] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:42:25,907] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:42:25,930] {logging_mixin.py:115} INFO - [2023-11-16 13:42:25,930] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:42:25,964] {logging_mixin.py:115} INFO - [2023-11-16 13:42:25,964] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:42:25,989] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.180 seconds
[2023-11-16 13:42:56,165] {processor.py:153} INFO - Started process (PID=18353) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:42:56,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:42:56,168] {logging_mixin.py:115} INFO - [2023-11-16 13:42:56,167] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:42:56,222] {logging_mixin.py:115} INFO - [2023-11-16 13:42:56,222] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:42:56,249] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:42:56,276] {logging_mixin.py:115} INFO - [2023-11-16 13:42:56,276] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:42:56,312] {logging_mixin.py:115} INFO - [2023-11-16 13:42:56,312] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:42:56,343] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.182 seconds
[2023-11-16 13:43:26,489] {processor.py:153} INFO - Started process (PID=18420) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:43:26,490] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:43:26,491] {logging_mixin.py:115} INFO - [2023-11-16 13:43:26,491] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:43:26,544] {logging_mixin.py:115} INFO - [2023-11-16 13:43:26,544] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:43:26,572] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:43:26,595] {logging_mixin.py:115} INFO - [2023-11-16 13:43:26,594] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:43:26,637] {logging_mixin.py:115} INFO - [2023-11-16 13:43:26,637] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:43:26,659] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.174 seconds
[2023-11-16 13:43:57,297] {processor.py:153} INFO - Started process (PID=18477) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:43:57,298] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:43:57,300] {logging_mixin.py:115} INFO - [2023-11-16 13:43:57,299] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:43:57,359] {logging_mixin.py:115} INFO - [2023-11-16 13:43:57,359] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:43:57,384] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:43:57,402] {logging_mixin.py:115} INFO - [2023-11-16 13:43:57,402] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:43:57,433] {logging_mixin.py:115} INFO - [2023-11-16 13:43:57,432] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:43:57,455] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.162 seconds
[2023-11-16 13:44:27,577] {processor.py:153} INFO - Started process (PID=18544) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:44:27,578] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:44:27,580] {logging_mixin.py:115} INFO - [2023-11-16 13:44:27,579] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:44:27,655] {logging_mixin.py:115} INFO - [2023-11-16 13:44:27,655] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:44:27,685] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:44:27,713] {logging_mixin.py:115} INFO - [2023-11-16 13:44:27,713] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:44:27,764] {logging_mixin.py:115} INFO - [2023-11-16 13:44:27,764] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:44:27,789] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 13:44:57,869] {processor.py:153} INFO - Started process (PID=18609) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:44:57,870] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:44:57,872] {logging_mixin.py:115} INFO - [2023-11-16 13:44:57,872] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:44:57,936] {logging_mixin.py:115} INFO - [2023-11-16 13:44:57,936] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:44:57,961] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:44:57,987] {logging_mixin.py:115} INFO - [2023-11-16 13:44:57,987] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:44:58,021] {logging_mixin.py:115} INFO - [2023-11-16 13:44:58,021] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:44:58,041] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.178 seconds
[2023-11-16 13:45:28,207] {processor.py:153} INFO - Started process (PID=18669) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:45:28,208] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:45:28,209] {logging_mixin.py:115} INFO - [2023-11-16 13:45:28,209] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:45:28,259] {logging_mixin.py:115} INFO - [2023-11-16 13:45:28,259] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:45:28,289] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:45:28,309] {logging_mixin.py:115} INFO - [2023-11-16 13:45:28,309] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:45:28,351] {logging_mixin.py:115} INFO - [2023-11-16 13:45:28,351] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:45:28,372] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.168 seconds
[2023-11-16 13:45:58,625] {processor.py:153} INFO - Started process (PID=18736) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:45:58,626] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:45:58,627] {logging_mixin.py:115} INFO - [2023-11-16 13:45:58,627] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:45:58,677] {logging_mixin.py:115} INFO - [2023-11-16 13:45:58,676] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:45:58,701] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:45:58,724] {logging_mixin.py:115} INFO - [2023-11-16 13:45:58,724] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:45:58,757] {logging_mixin.py:115} INFO - [2023-11-16 13:45:58,757] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:45:58,777] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 13:46:28,863] {processor.py:153} INFO - Started process (PID=18794) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:46:28,864] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:46:28,865] {logging_mixin.py:115} INFO - [2023-11-16 13:46:28,865] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:46:28,915] {logging_mixin.py:115} INFO - [2023-11-16 13:46:28,914] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:46:28,943] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:46:28,963] {logging_mixin.py:115} INFO - [2023-11-16 13:46:28,963] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:46:28,994] {logging_mixin.py:115} INFO - [2023-11-16 13:46:28,994] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:46:29,015] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.156 seconds
[2023-11-16 13:46:59,743] {processor.py:153} INFO - Started process (PID=18861) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:46:59,744] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:46:59,746] {logging_mixin.py:115} INFO - [2023-11-16 13:46:59,746] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:46:59,832] {logging_mixin.py:115} INFO - [2023-11-16 13:46:59,832] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:46:59,873] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:46:59,903] {logging_mixin.py:115} INFO - [2023-11-16 13:46:59,903] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:46:59,977] {logging_mixin.py:115} INFO - [2023-11-16 13:46:59,976] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:47:00,002] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.268 seconds
[2023-11-16 13:47:30,569] {processor.py:153} INFO - Started process (PID=18919) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:47:30,571] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:47:30,573] {logging_mixin.py:115} INFO - [2023-11-16 13:47:30,573] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:47:30,657] {logging_mixin.py:115} INFO - [2023-11-16 13:47:30,657] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:47:30,703] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:47:30,735] {logging_mixin.py:115} INFO - [2023-11-16 13:47:30,734] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:47:30,785] {logging_mixin.py:115} INFO - [2023-11-16 13:47:30,785] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:47:30,813] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.252 seconds
[2023-11-16 13:48:01,465] {processor.py:153} INFO - Started process (PID=18977) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:48:01,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:48:01,469] {logging_mixin.py:115} INFO - [2023-11-16 13:48:01,468] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:48:01,542] {logging_mixin.py:115} INFO - [2023-11-16 13:48:01,542] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:48:01,576] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:48:01,604] {logging_mixin.py:115} INFO - [2023-11-16 13:48:01,604] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:48:01,648] {logging_mixin.py:115} INFO - [2023-11-16 13:48:01,648] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:48:01,677] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 13:48:32,334] {processor.py:153} INFO - Started process (PID=19044) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:48:32,336] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:48:32,338] {logging_mixin.py:115} INFO - [2023-11-16 13:48:32,338] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:48:32,409] {logging_mixin.py:115} INFO - [2023-11-16 13:48:32,409] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:48:32,449] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:48:32,485] {logging_mixin.py:115} INFO - [2023-11-16 13:48:32,485] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:48:32,530] {logging_mixin.py:115} INFO - [2023-11-16 13:48:32,530] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:48:32,555] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.228 seconds
[2023-11-16 13:49:03,076] {processor.py:153} INFO - Started process (PID=19102) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:49:03,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:49:03,079] {logging_mixin.py:115} INFO - [2023-11-16 13:49:03,079] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:49:03,142] {logging_mixin.py:115} INFO - [2023-11-16 13:49:03,142] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:49:03,179] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:49:03,207] {logging_mixin.py:115} INFO - [2023-11-16 13:49:03,207] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:49:03,262] {logging_mixin.py:115} INFO - [2023-11-16 13:49:03,262] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:49:03,288] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.220 seconds
[2023-11-16 13:49:33,643] {processor.py:153} INFO - Started process (PID=19161) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:49:33,645] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:49:33,647] {logging_mixin.py:115} INFO - [2023-11-16 13:49:33,647] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:49:33,726] {logging_mixin.py:115} INFO - [2023-11-16 13:49:33,725] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:49:33,761] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:49:33,795] {logging_mixin.py:115} INFO - [2023-11-16 13:49:33,794] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:49:33,858] {logging_mixin.py:115} INFO - [2023-11-16 13:49:33,857] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:49:33,886] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.249 seconds
[2023-11-16 13:50:03,996] {processor.py:153} INFO - Started process (PID=19227) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:50:03,998] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:50:04,000] {logging_mixin.py:115} INFO - [2023-11-16 13:50:04,000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:50:04,092] {logging_mixin.py:115} INFO - [2023-11-16 13:50:04,091] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:50:04,130] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:50:04,160] {logging_mixin.py:115} INFO - [2023-11-16 13:50:04,160] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:50:04,209] {logging_mixin.py:115} INFO - [2023-11-16 13:50:04,209] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:50:04,242] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.251 seconds
[2023-11-16 13:50:34,514] {processor.py:153} INFO - Started process (PID=19286) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:50:34,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:50:34,519] {logging_mixin.py:115} INFO - [2023-11-16 13:50:34,519] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:50:34,616] {logging_mixin.py:115} INFO - [2023-11-16 13:50:34,616] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:50:34,648] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:50:34,676] {logging_mixin.py:115} INFO - [2023-11-16 13:50:34,675] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:50:34,720] {logging_mixin.py:115} INFO - [2023-11-16 13:50:34,720] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:50:34,746] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.240 seconds
[2023-11-16 13:51:04,895] {processor.py:153} INFO - Started process (PID=19345) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:51:04,897] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:51:04,900] {logging_mixin.py:115} INFO - [2023-11-16 13:51:04,899] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:51:04,984] {logging_mixin.py:115} INFO - [2023-11-16 13:51:04,984] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:51:05,029] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:51:05,088] {logging_mixin.py:115} INFO - [2023-11-16 13:51:05,088] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:51:05,155] {logging_mixin.py:115} INFO - [2023-11-16 13:51:05,155] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:51:05,196] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.307 seconds
[2023-11-16 13:51:35,568] {processor.py:153} INFO - Started process (PID=19410) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:51:35,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:51:35,571] {logging_mixin.py:115} INFO - [2023-11-16 13:51:35,571] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:51:35,661] {logging_mixin.py:115} INFO - [2023-11-16 13:51:35,661] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:51:35,696] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:51:35,727] {logging_mixin.py:115} INFO - [2023-11-16 13:51:35,726] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:51:35,792] {logging_mixin.py:115} INFO - [2023-11-16 13:51:35,792] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:51:35,824] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.262 seconds
[2023-11-16 13:52:06,164] {processor.py:153} INFO - Started process (PID=19468) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:52:06,166] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:52:06,168] {logging_mixin.py:115} INFO - [2023-11-16 13:52:06,167] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:52:06,256] {logging_mixin.py:115} INFO - [2023-11-16 13:52:06,256] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:52:06,290] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:52:06,318] {logging_mixin.py:115} INFO - [2023-11-16 13:52:06,318] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:52:06,376] {logging_mixin.py:115} INFO - [2023-11-16 13:52:06,376] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:52:06,406] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.250 seconds
[2023-11-16 13:52:36,927] {processor.py:153} INFO - Started process (PID=19526) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:52:36,929] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:52:36,931] {logging_mixin.py:115} INFO - [2023-11-16 13:52:36,930] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:52:37,011] {logging_mixin.py:115} INFO - [2023-11-16 13:52:37,010] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:52:37,051] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:52:37,082] {logging_mixin.py:115} INFO - [2023-11-16 13:52:37,082] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:52:37,128] {logging_mixin.py:115} INFO - [2023-11-16 13:52:37,128] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:52:37,154] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.237 seconds
[2023-11-16 13:53:07,258] {processor.py:153} INFO - Started process (PID=19585) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:53:07,260] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:53:07,263] {logging_mixin.py:115} INFO - [2023-11-16 13:53:07,262] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:53:07,357] {logging_mixin.py:115} INFO - [2023-11-16 13:53:07,357] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:53:07,394] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:53:07,422] {logging_mixin.py:115} INFO - [2023-11-16 13:53:07,422] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:53:07,478] {logging_mixin.py:115} INFO - [2023-11-16 13:53:07,476] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:53:07,532] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.284 seconds
[2023-11-16 13:53:37,895] {processor.py:153} INFO - Started process (PID=19652) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:53:37,896] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:53:37,898] {logging_mixin.py:115} INFO - [2023-11-16 13:53:37,898] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:53:37,987] {logging_mixin.py:115} INFO - [2023-11-16 13:53:37,987] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:53:38,021] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:53:38,052] {logging_mixin.py:115} INFO - [2023-11-16 13:53:38,052] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:53:38,108] {logging_mixin.py:115} INFO - [2023-11-16 13:53:38,108] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:53:38,135] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.246 seconds
[2023-11-16 13:54:08,237] {processor.py:153} INFO - Started process (PID=19710) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:54:08,239] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:54:08,242] {logging_mixin.py:115} INFO - [2023-11-16 13:54:08,241] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:54:08,353] {logging_mixin.py:115} INFO - [2023-11-16 13:54:08,353] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:54:08,405] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:54:08,447] {logging_mixin.py:115} INFO - [2023-11-16 13:54:08,447] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:54:08,511] {logging_mixin.py:115} INFO - [2023-11-16 13:54:08,510] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:54:08,550] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.326 seconds
[2023-11-16 13:54:38,648] {processor.py:153} INFO - Started process (PID=19768) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:54:38,650] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:54:38,652] {logging_mixin.py:115} INFO - [2023-11-16 13:54:38,652] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:54:38,735] {logging_mixin.py:115} INFO - [2023-11-16 13:54:38,735] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:54:38,779] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:54:38,812] {logging_mixin.py:115} INFO - [2023-11-16 13:54:38,812] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:54:38,858] {logging_mixin.py:115} INFO - [2023-11-16 13:54:38,857] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:54:38,893] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.254 seconds
[2023-11-16 13:55:09,092] {processor.py:153} INFO - Started process (PID=19834) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:55:09,094] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:55:09,096] {logging_mixin.py:115} INFO - [2023-11-16 13:55:09,095] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:55:09,186] {logging_mixin.py:115} INFO - [2023-11-16 13:55:09,186] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:55:09,224] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:55:09,255] {logging_mixin.py:115} INFO - [2023-11-16 13:55:09,255] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:55:09,296] {logging_mixin.py:115} INFO - [2023-11-16 13:55:09,296] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:55:09,322] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.236 seconds
[2023-11-16 13:55:39,597] {processor.py:153} INFO - Started process (PID=19893) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:55:39,599] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:55:39,601] {logging_mixin.py:115} INFO - [2023-11-16 13:55:39,601] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:55:39,693] {logging_mixin.py:115} INFO - [2023-11-16 13:55:39,693] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:55:39,733] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:55:39,762] {logging_mixin.py:115} INFO - [2023-11-16 13:55:39,762] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:55:39,811] {logging_mixin.py:115} INFO - [2023-11-16 13:55:39,811] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:55:39,836] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.250 seconds
[2023-11-16 13:56:10,142] {processor.py:153} INFO - Started process (PID=19951) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:56:10,144] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:56:10,146] {logging_mixin.py:115} INFO - [2023-11-16 13:56:10,146] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:56:10,266] {logging_mixin.py:115} INFO - [2023-11-16 13:56:10,265] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:56:10,311] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:56:10,344] {logging_mixin.py:115} INFO - [2023-11-16 13:56:10,344] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:56:10,416] {logging_mixin.py:115} INFO - [2023-11-16 13:56:10,415] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:56:10,461] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.327 seconds
[2023-11-16 13:56:41,088] {processor.py:153} INFO - Started process (PID=20009) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:56:41,090] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:56:41,092] {logging_mixin.py:115} INFO - [2023-11-16 13:56:41,091] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:56:41,191] {logging_mixin.py:115} INFO - [2023-11-16 13:56:41,191] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:56:41,254] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:56:41,308] {logging_mixin.py:115} INFO - [2023-11-16 13:56:41,308] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:56:41,381] {logging_mixin.py:115} INFO - [2023-11-16 13:56:41,381] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:56:41,430] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.346 seconds
[2023-11-16 13:57:11,888] {processor.py:153} INFO - Started process (PID=20076) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:57:11,890] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:57:11,892] {logging_mixin.py:115} INFO - [2023-11-16 13:57:11,892] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:57:11,991] {logging_mixin.py:115} INFO - [2023-11-16 13:57:11,991] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:57:12,031] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:57:12,062] {logging_mixin.py:115} INFO - [2023-11-16 13:57:12,062] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:57:12,114] {logging_mixin.py:115} INFO - [2023-11-16 13:57:12,114] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:57:12,140] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.265 seconds
[2023-11-16 13:57:42,287] {processor.py:153} INFO - Started process (PID=20134) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:57:42,290] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:57:42,295] {logging_mixin.py:115} INFO - [2023-11-16 13:57:42,295] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:57:42,410] {logging_mixin.py:115} INFO - [2023-11-16 13:57:42,410] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:57:42,468] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:57:42,505] {logging_mixin.py:115} INFO - [2023-11-16 13:57:42,505] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:57:42,548] {logging_mixin.py:115} INFO - [2023-11-16 13:57:42,548] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:57:42,576] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.300 seconds
[2023-11-16 13:58:12,812] {processor.py:153} INFO - Started process (PID=20192) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:58:12,815] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:58:12,818] {logging_mixin.py:115} INFO - [2023-11-16 13:58:12,817] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:58:12,932] {logging_mixin.py:115} INFO - [2023-11-16 13:58:12,932] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:58:12,988] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:58:13,026] {logging_mixin.py:115} INFO - [2023-11-16 13:58:13,025] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:58:13,082] {logging_mixin.py:115} INFO - [2023-11-16 13:58:13,082] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:58:13,111] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.309 seconds
[2023-11-16 13:58:43,423] {processor.py:153} INFO - Started process (PID=20259) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:58:43,425] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:58:43,426] {logging_mixin.py:115} INFO - [2023-11-16 13:58:43,426] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:58:43,500] {logging_mixin.py:115} INFO - [2023-11-16 13:58:43,500] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:58:43,536] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:58:43,562] {logging_mixin.py:115} INFO - [2023-11-16 13:58:43,562] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:58:43,606] {logging_mixin.py:115} INFO - [2023-11-16 13:58:43,606] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:58:43,636] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.218 seconds
[2023-11-16 13:59:14,224] {processor.py:153} INFO - Started process (PID=20317) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:59:14,226] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:59:14,228] {logging_mixin.py:115} INFO - [2023-11-16 13:59:14,228] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:59:14,333] {logging_mixin.py:115} INFO - [2023-11-16 13:59:14,333] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:59:14,366] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:59:14,393] {logging_mixin.py:115} INFO - [2023-11-16 13:59:14,392] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:59:14,436] {logging_mixin.py:115} INFO - [2023-11-16 13:59:14,436] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:59:14,464] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.250 seconds
[2023-11-16 13:59:44,837] {processor.py:153} INFO - Started process (PID=20376) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 13:59:44,838] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 13:59:44,840] {logging_mixin.py:115} INFO - [2023-11-16 13:59:44,839] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 13:59:44,921] {logging_mixin.py:115} INFO - [2023-11-16 13:59:44,921] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 13:59:44,953] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 13:59:44,984] {logging_mixin.py:115} INFO - [2023-11-16 13:59:44,984] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 13:59:45,036] {logging_mixin.py:115} INFO - [2023-11-16 13:59:45,036] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 13:59:45,057] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.253 seconds
[2023-11-16 14:00:15,912] {processor.py:153} INFO - Started process (PID=20444) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 14:00:15,913] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 14:00:15,915] {logging_mixin.py:115} INFO - [2023-11-16 14:00:15,915] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 14:00:16,046] {logging_mixin.py:115} INFO - [2023-11-16 14:00:16,046] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 14:00:16,095] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 14:00:16,142] {logging_mixin.py:115} INFO - [2023-11-16 14:00:16,141] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 14:00:16,230] {logging_mixin.py:115} INFO - [2023-11-16 14:00:16,229] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 14:00:16,265] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.359 seconds
[2023-11-16 14:00:46,587] {processor.py:153} INFO - Started process (PID=20502) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 14:00:46,590] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 14:00:46,593] {logging_mixin.py:115} INFO - [2023-11-16 14:00:46,592] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 14:00:46,711] {logging_mixin.py:115} INFO - [2023-11-16 14:00:46,711] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 14:00:46,749] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 14:00:46,785] {logging_mixin.py:115} INFO - [2023-11-16 14:00:46,785] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 14:00:46,852] {logging_mixin.py:115} INFO - [2023-11-16 14:00:46,852] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 14:00:46,883] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.305 seconds
[2023-11-16 14:01:17,049] {processor.py:153} INFO - Started process (PID=20560) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 14:01:17,051] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 14:01:17,054] {logging_mixin.py:115} INFO - [2023-11-16 14:01:17,054] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 14:01:17,173] {logging_mixin.py:115} INFO - [2023-11-16 14:01:17,173] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 14:01:17,229] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 14:01:17,275] {logging_mixin.py:115} INFO - [2023-11-16 14:01:17,275] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 14:01:17,338] {logging_mixin.py:115} INFO - [2023-11-16 14:01:17,338] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 14:01:17,372] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.331 seconds
[2023-11-16 14:01:48,061] {processor.py:153} INFO - Started process (PID=20627) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 14:01:48,062] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 14:01:48,064] {logging_mixin.py:115} INFO - [2023-11-16 14:01:48,063] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 14:01:48,136] {logging_mixin.py:115} INFO - [2023-11-16 14:01:48,136] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 14:01:48,168] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 14:01:48,197] {logging_mixin.py:115} INFO - [2023-11-16 14:01:48,197] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 14:01:48,239] {logging_mixin.py:115} INFO - [2023-11-16 14:01:48,238] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 14:01:48,268] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.212 seconds
[2023-11-16 14:02:19,014] {processor.py:153} INFO - Started process (PID=20685) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 14:02:19,016] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 14:02:19,020] {logging_mixin.py:115} INFO - [2023-11-16 14:02:19,019] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 14:02:19,136] {logging_mixin.py:115} INFO - [2023-11-16 14:02:19,136] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 14:02:19,175] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 14:02:19,203] {logging_mixin.py:115} INFO - [2023-11-16 14:02:19,203] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 14:02:19,249] {logging_mixin.py:115} INFO - [2023-11-16 14:02:19,249] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 14:02:19,276] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.274 seconds
[2023-11-16 14:02:49,503] {processor.py:153} INFO - Started process (PID=20743) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 14:02:49,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 14:02:49,511] {logging_mixin.py:115} INFO - [2023-11-16 14:02:49,510] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 14:02:49,672] {logging_mixin.py:115} INFO - [2023-11-16 14:02:49,672] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 14:02:49,713] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 14:02:49,764] {logging_mixin.py:115} INFO - [2023-11-16 14:02:49,764] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 14:02:49,828] {logging_mixin.py:115} INFO - [2023-11-16 14:02:49,828] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 14:02:49,861] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.369 seconds
[2023-11-16 14:03:20,199] {processor.py:153} INFO - Started process (PID=20810) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 14:03:20,201] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 14:03:20,202] {logging_mixin.py:115} INFO - [2023-11-16 14:03:20,202] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 14:03:20,293] {logging_mixin.py:115} INFO - [2023-11-16 14:03:20,293] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 14:03:20,347] {processor.py:651} INFO - DAG(s) dict_keys(['etl_hh']) retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 14:03:20,383] {logging_mixin.py:115} INFO - [2023-11-16 14:03:20,383] {dag.py:2420} INFO - Sync 1 DAGs
[2023-11-16 14:03:20,446] {logging_mixin.py:115} INFO - [2023-11-16 14:03:20,446] {dag.py:2972} INFO - Setting next_dagrun for etl_hh to None, run_after=None
[2023-11-16 14:03:20,479] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.286 seconds
[2023-11-16 14:03:50,719] {processor.py:153} INFO - Started process (PID=20866) to work on /opt/airflow/dags/pipeline.py
[2023-11-16 14:03:50,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/pipeline.py for tasks to queue
[2023-11-16 14:03:50,722] {logging_mixin.py:115} INFO - [2023-11-16 14:03:50,722] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline.py
[2023-11-16 14:03:50,848] {logging_mixin.py:115} INFO - [2023-11-16 14:03:50,848] {base.py:68} INFO - Using connection ID 'my_db_conn' for task execution.
[2023-11-16 14:03:50,874] {logging_mixin.py:115} INFO - [2023-11-16 14:03:50,862] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline.py", line 60, in <module>
    database=pg_db
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "host.docker.internal" to address: Temporary failure in name resolution
[2023-11-16 14:03:50,879] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline.py
[2023-11-16 14:03:50,904] {processor.py:161} INFO - Processing /opt/airflow/dags/pipeline.py took 0.191 seconds
